## Introduction
### Contributions
1. **Trainable Bag-of-Freebies:**
- 검출 정확도를 크게 향상시키면서도 추론 비용을 증가시키지 않는 여러 가지 훈련 가능한 방법을 설계하였습니다. 이는 모델이 학습 과정에서 보다 효과적으로 특징을 추출하고 성능을 끌어올릴 수 있는 방법론입니다.

2. **New Issues in Object Detection:**
- 객체 탐지의 발전 과정에서 새롭게 발견된 두 가지 이슈는 재매개변수화된 모듈이 기존 모듈을 어떻게 대체하는지, 동적 라벨 할당 전략이 어떻게 다른 출력 레이어에 할당을 처리하는지에 관한 것입니다. 논문에서는 이러한 문제들을 해결하기 위한 방법도 제안하고 있습니다.

3. **Extend and Compound Scaling Methods:**
- 실시간 객체 탐지기를 위한 "extend" 및 "compound scaling" 방법을 제안하여, 파라미터와 계산을 효과적으로 활용할 수 있도록 하였습니다. 이는 모델의 크기와 성능을 균형 있게 확장하는 방식입니다.

4. **Efficiency and Accuracy Improvement:**
- 제안된 방법은 최첨단 실시간 객체 탐지기의 약 40% 파라미터와 50% 연산을 줄이면서도, 더 빠른 추론 속도와 높은 검출 정확도를 제공합니다. 이는 효율성과 성능을 동시에 최적화하는 데 있어 중요한 성과입니다.

## Related works
### 2.1 Real-time object detectors

#### YOLO

##### 1. You only look once: Unified, real-time object detection (16.06)
- YOLO는 실시간 객체 탐지기이며, 단일 신경망을 통해 전체 이미지를 한번에 처리하여 객체를 병렬로 예측합니다.

##### 2. YOLO9000: better, faster, stronger (17.07)
- YOLO9000은 더 넓은 범위의 객체를 빠르고 정확하게 탐지하기 위한 개선된 모델로, 다양한 클래스에서도 실시간 성능을 유지합니다.

##### 3. YOLOv3: An incremental improvement (18.04)
- YOLOv3는 이전 YOLO 버전의 성능을 개선하여 작은 객체를 더 잘 탐지할 수 있도록 하여 향상된 정확성을 제공합니다.

#### FCOS

##### 1. FCOS: Fully Convolutional One-Stage Object Detection (19.01)
- FCOS는 앵커 박스 없이 전적으로 합성곱 신경망 기반의 단일 스테이지 객체 탐지 방법을 제안하여 구현의 단순함과 성능을 극대화합니다.

##### 2. FCOS: A simple and strong anchor-free object detector (22.04)
- 이 논문은 자유로운 앵커박스 구조를 가진 효율적이고 강력한 객체 탐지기를 개발하여 구현의 복잡성을 줄이고 성능을 높입니다.

#### Feature Integration Method

##### 1. NAS-FPN: Learning scalable feature pyramid architecture for object detection (19.06)
- NAS-FPN은 신경망 아키텍처 탐색을 활용하여 스케일러블한 피처 피라미드 네트워크를 자동으로 설계하는 방법을 제안합니다.

##### 2. Objects as points (19.06)
- 이 연구는 객체를 앵커 박스 대신 포인트로 취급하여 탐지 작업을 수행하는 새로운 방법론을 제시합니다.

##### 3. Panoptic Feature Pyramid Networks (19.06)
- Panoptic FPN은 객체와 배경을 통합하여 표현하는 파노픽 세그멘테이션을 위한 피라미드 네트워크를 활용합니다.

##### 4. EfficientDet: Scalable and efficient object detection (20.06)
- EfficientDet은 EfficientNet과 BiFPN 피라미드 구조를 기반으로 하여 스케일러블하고 효율적인 객체 탐지기를 제공합니다.

##### 5. DetectoRS: Detecting objects with recursive feature pyramid and switchable atrous convolution (20.10)
- DetectoRS는 재귀 피라미드 구조와 교체 가능한 팽창 합성곱을 사용하여 객체 탐지를 강화합니다.

##### 6. A2-FPN: Attention aggregation based feature pyramid network for instance segmentation (20.12)
- A2-FPN은 주의집중 기반의 피처 피라미드 구조로 인스턴스 분할의 정확성을 향상시킵니다.

##### 7. Dynamic head: Unifying object detection heads with attentions (21.01)
- Dynamic head는 비전 주의집중 메커니즘을 통합하여 객체 탐지 헤드를 단일화하고, 성능을 극대화합니다.

##### 8. Vision transformer adapter for dense predictions (22.05)
- 이 연구에서는 높은 밀도의 예측을 효과적으로 수행하기 위해 비전 트랜스포머 어댑터를 제안합니다.

#### A more accurate detection method

##### 1. FCOS: Fully Convolutional One-Stage Object Detection (19.01)
- FCOS는 앵커가 필요 없는 단순한 구조로 정확한 객체 탐지를 가능하게 합니다.

##### 2. FCOS: A simple and strong anchor-free object detector (22.04)
- 가장 간단하고 강력한 앵커 프리 객체 탐지기를 구현하여 쉽게 적용할 수 있습니다.

##### 3. Sparse R-CNN: End-to-end object detection with learnable proposals (21.02)
- Sparse R-CNN은 학습 가능한 제안을 통해 엔드 투 엔드 방식으로 객체를 탐지하는 구조를 제공합니다.

#### A more robust loss function

##### 1. IoU loss for 2D/3D object detection (19.11)
- 2D 및 3D 객체 탐지의 경계 상자 정확도를 높이기 위해 IoU 기반 손실 함수를 사용합니다.

##### 2. Generalized intersection over union: A metric and a loss for bounding box regression (19.06)
- 기존 IoU를 확장하여 경계 상자 회귀의 성능을 개선하는 일반화된 손실 함수 및 평가 메트릭을 제안합니다.

##### 3. AP-loss for accurate one-stage object detection (20.04)
- AP-Loss는 탐지기의 정확도를 높이기 위해 평균 정밀도를 직접 최적화한 손실 함수입니다.

##### 4. A ranking-based, balanced loss function unifying classification and localisation in object detection (20.09)
- 분류와 위치 지정의 조화를 추구하는 방식으로 객체 탐지 손실을 균형 잡아 최적화합니다.

##### 5. Distance-IoU loss: Faster and better learning for bounding box regression (20.02)
- 경계 상자 회귀에 중심 거리 정보를 추가하여 빠르고 개선된 학습을 지원합니다.

##### 6. Rank & sort loss for object detection and instance segmentation (21.06)
- 탐지와 세그멘테이션 정확도를 고려한 랭킹 기반 손실 함수로, 성능을 향상시킵니다.

#### A more efficient label assignment method

##### 1. AutoAssign: Differentiable label assignment for dense object detection (20.07)
- AutoAssign은 밀집 객체 탐지에서 유연한 라벨 할당이 가능하도록 설계된 차별화된 방법론을 소개합니다.

##### 2. OTA: Optimal transport assignment for object detection (21.01)
- 객체 탐지에 최적화된 전송 문제를 해결하여 효율적인 라벨 할당을 수행합니다.

##### 3. TOOD: Task-aligned one-stage object detection (21.07)
- 과제 정렬 방식의 원스테이지 객체 탐지로 효율적인 라벨 할당 및 탐지 성능을 제공합니다.

##### 4. End-to-end object detection with fully convolutional network (21.03)
- 완전한 합성곱 신경망을 통해 종단간의 객체 탐지를 수행하여 라벨 할당의 효율성을 높입니다.

##### 5. A dual weighting label assignment scheme for object detection (22.01)
- 객체 탐지에서 이중 가중치에 기반한 라벨 할당 기법을 사용하여 성능을 최적화합니다.

### 2.2. Model re-parameterization
#### Model re-parametrization techniques

##### 1. Rethinking the inception architecture for computer vision (16.06)
- 이 논문은 Inception 구조를 재고하며, 더 나은 비전 모델 설계 전략을 탐색합니다.

##### 2. Snapshot ensembles: Train 1, get m for free (17.04)
- Snapshot ensembles는 하나의 훈련 중인 모델로부터 여러 모델을 얻게 해주는 접근 방식으로, 학습 효율성을 높입니다.

##### 3. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results (17.12)
- 이 연구는 평균화된 가중치 일관성 목표가 반지도학습의 결과를 향상시킨다는 점을 설명합니다.

##### 4. Loss surfaces, mode connectivity, and fast ensembling of DNNs (18.12)
- 이 논문은 손실 표면 및 모드 연결성을 분석하여 DNN의 빠른 앙상블 기술을 논의합니다.

##### 5. Averaging weights leads to wider optima and better generalization (18.12)
- 가중치 평균화를 통해 더 넓은 최적화와 일반화 능력이 향상됨을 제시합니다.

##### 6. ACNet: Strengthening the kernel skeletons for powerful CNN via asymmetric convolution blocks (19.02)
- ACNet은 비대칭 합성곱 블록을 사용하여 CNN의 핵심 구조를 강화합니다.

##### 7. Ensemble deep learning in bioinformatics (20.09)
- 이 연구는 생물정보학 분야에서의 딥러닝 모델 앙상블 기법을 탐색합니다.

##### 8. ExpandNets: Linear over-parameterization to train compact convolutional networks (20.12)
- ExpandNets는 선형 초과매개변수를 이용하여 컴팩트한 합성곱 신경망을 훈련시키는 방법을 제안합니다.

##### 9. RepVGG: Making VGG-style convnets great again (21.06)
- RepVGG는 VGG 스타일의 합성곱 신경망을 재구성하여 성능을 높입니다.

##### 10. Diverse branch block: Building a convolution as an inception-like unit (21.06)
- 다양한 분기 블록을 통해 Inception-유사 유닛으로 합성곱을 구현합니다.

##### 11. Reparameterizing your optimizers rather than architectures (22.06)
- 아키텍처가 아닌 옵티마이저를 재구성하여 성능을 개선하는 방법을 다룹니다.

##### 12. Online convolutional re-parameterization (22.06)
- 온라인 합성곱 재구성을 통해 능동적으로 모델 성능을 최적화합니다.

##### 13. Scaling up your kernels to 31x31: Revisiting large kernel design in CNNs (22.06)
- 대형 커널 설계를 재검토하여 CNN의 성능 향상을 목표로 합니다.

##### 14. An improved one millisecond mobile backbone (22.06)
- 단 1밀리초 내에 동작하는 모바일 백본 구조의 개선 방법을 소개합니다.


### 2.3 Model scaling

#### Model scaling

##### 1. EfficientNet: Rethinking model scaling for convolutional neural networks (19.06)
- EfficientNet은 모델 크기의 조정을 통해 신경망의 효율성을 극대화하는 방식을 제안합니다.

##### 2. Designing network design spaces (20.06)
- 네트워크 설계 공간을 구성하고 최적화하는 전략을 제시함으로써 효율적인 모델 설계를 지원합니다.

##### 3. EfficientDet: Scalable and efficient object detection (20.06)
- EfficientDet은 높은 효율성과 확장성을 가진 객체 탐지기를 설계합니다.

##### 4. EfficientNetv2: Smaller models and faster training (21.06)
- EfficientNetv2는 더 작은 모델과 빠른 훈련을 목표로 하여 업데이트된 효율적인 네트워크를 소개합니다.

##### 5. Fast and accurate model scaling (21.06)
- 빠르고 정확한 모델 스케일링 방법들을 탐구하여 성능과 효율성을 동시에 고려합니다.

##### 6. Simple training strategies and model scaling for object detection (21.07)
- 이 논문은 객체 탐지를 위한 간단한 훈련 전략 및 모델 스케일링 기법을 제안합니다.

##### 7. Revisiting ResNets: Improved training and scaling strategies (21.12)
- ResNet의 훈련 및 스케일링 전략을 재평가하여 성능 개선 방안을 모색합니다.

##### 8. Dynamic ViT: Vision transformers with dynamic token sparsification (22.03)
- 동적인 토큰 희소화를 통해 비전 트랜스포머의 효율성을 향상시킵니다.


## References
1. **Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. "Deep residual learning for image recognition." CVPR, 2016.** \[26\]
- ResNet 모델을 제안한 이 논문은 딥러닝 분야 전반에 걸쳐 매우 널리 인용됩니다. ResNet은 많은 컴퓨터 비전 작업의 기본 구축 블록이 되었기 때문에, 많은 연구와 응용에서 언급됩니다.

1. **Joseph Redmon and Ali Farhadi. "YOLO9000: better, faster, stronger." CVPR, 2017.** \[62\]
- YOLO 시리즈는 객체 탐지 분야에서 실시간 성능을 제공하는 대표적 모델로 널리 알려져 있으며, YOLO9000 논문은 이러한 성과를 통합 소개하여 많은 인용을 기록하고 있습니다.

1. **Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. "Going deeper with convolutions." CVPR, 2015.** \[70\]
- 이 논문은 GoogLeNet (Inception 모듈)을 제안하며 네트워크의 깊이와 넓이를 효율적으로 확장하는 기법을 설명합니다. 객체 탐지 및 분류 작업에서 널리 채택되어 여러 관련 연구에서 인용되고 있습니다.