ResourceManager / NodeManager / ApplicationMaster

Container

ClusterManager

SparkContext

Driver / Executor

Driver 한개
- 사용자가 짠 메인 프로그램이 실행된다.
- 스파크 컨텍스트 객체를 만들고, 전체 앱의 실행흐름, 작업 흐름, 텍스트 분배 등을 조율한다.

Executor 여러개
- 워커노드에서 실행된다.
- 드라이버로부터 할당받은 계산 작업을 실행
- 중간 결과를 디스크에 저장, 캐싱

| **계층**                  | **구성 요소**                                         | **역할**                            |
| ----------------------- | ------------------------------------------------- | --------------------------------- |
| **애플리케이션 계층**           | **SparkContext**                                  | 사용자 코드 진입점, 클러스터 매니저에게 작업 요청      |
| **클러스터 매니저 계층**         | **Cluster Manager** (YARN, K8s, Standalone 등)     | 자원(CPU, Memory) 요청 받고 Executor 할당 |
| **리소스 관리 계층 (YARN 기준)** | ResourceManager / NodeManager / ApplicationMaster | 컨테이너 할당 및 실행 관리                   |
| **실행 계층**               | **Driver / Executor** (컨테이너 내부)                   | 실질적인 작업 실행 주체                     |

SparkContext 초기화 -> 클러스터 리소스 확보 -> 작업(Job) 제출 -> 태스크(Task) 실행 -> 결과 수집


![[Pasted image 20251029133711.png]]


## 작업 배포 방식
Spark 애플리케이션에서 Driver와 Executor가 어디에서 실행되는지를 결정하는 방식

### 1. Local Mode
- 단일 머신에서 모든 컴포넌트 실행, 개발 및 테스트에 적합
### 2. Client Mode
- Driver는 로컬, Executor는 클러스터에서 실행, 대화형 분석에 최적화
### 3. Cluster Mode
- Driver와 Executor 모두 클러스터에서 실행, 프로덕션 환경 적합

## 리소스 설정 방식(about ClusterManger)
- 클러스터매니저의 역할
	- Spark 어플리케이션의 자원 할당 및 관리를 담당하는 중요 컴포넌트
	- Driver와 Executor에게 컴퓨팅 리소스르르 제공하고 작업 스케줄링 지원

### 1. Standalone
- Spark 자체 클러스터 관리자, 간단한 구성과 독립적 운영
### 2. YARN
- Hadoop 생태계 통합, 리소스 공유와 다중 워크로드 지원
### 3. Kubernetes
- 컨테이너 기반 오케스트레이션, 클라우드 네이티브 환경 최적화


## Apache Spark v1
| **기능명**                                 | **설명**                                                  |
| --------------------------------------- | ------------------------------------------------------- |
| **RDD (Resilient Distributed Dataset)** | Spark의 핵심 자료구조. 불변, 분산, 장애 복구 가능한 데이터셋                  |
| **In-Memory Computation**               | 중간 결과를 메모리에 저장해 반복 작업 시 성능 향상 (MapReduce 대비 최대 100배 빠름) |
| **Lazy Evaluation**                     | Transformation은 실행을 미루고, Action이 호출될 때 계산 시작            |
| **Lineage (계보)**                        | RDD 생성 과정을 추적해 장애 발생 시 재계산 가능 (복제 없이 복구)                |
| **DAG Scheduler**                       | 연산을 DAG로 구성하고, narrow/wide dependency에 따라 Stage로 나눠 실행  |
| **Standalone Cluster Manager**          | Spark 자체 클러스터 매니저로 YARN 없이 실행 가능 (YARN도 지원함)            |
| **Spark Streaming (DStream)**           | RDD 기반 스트리밍 처리 기능 (마이크로배치 방식)                           |
| **MLlib, GraphX**                       | 머신러닝/그래프 처리용 라이브러리 내장. RDD 기반으로 작동                      |
- Spark v1은 RDD 기반 인메모리 분산 처리 프레임워크
- Lazy Evaluation + Lineage로 효율성과 장애 복구 모두 달성
- DAG 기반 실행 + Stage 분할로 최적화 수행
- DStream으로 마이크로배치 스트리밍 처리 가능
- MapReduce보다 훨씬 빠르고 유연함

- Spark v1: RDD + DStream + 정적 실행 계획
    
- Spark v2: DataFrame/Dataset + Catalyst
    
- Spark v3: Structured Streaming + AQE

## Apache Spark v2

### Catalyst Optimizer
- 쿼리 최적화 엔진으로, 전체 SQL 실행 계획을 최적화한다.
- 쿼리의 논리적/물리적 실행 계획 전체를 리라이팅하고 재배열하는 역할을 한다.

- Catalyst는 여러 소스에서 들어온 쿼리 문장(SQL, DataFrame, Dataset), 복잡한 연산(join, filter, groupBy 등), 다양한 데이터 포맷(Parquet, ORC, Hive 등), 파티션된 테이블, 분산 파일 구조 등을 최적화한다.

1. Analyzing: 구문 분석 + 테이블/컬럼 확인
2. Logic Plan Generation: 쿼리를 논리 연산들의 트리로 변환(예: Filter, Project, Join)
3. Logical Plan Optimization: 불필요한 연산 제거, 조건 재배열, ==파티션/컬럼 프루닝== 등
4. Physical Plan Selection: 실행 가능한 물리적 연산 선택(예: SortMergeJoin vs BroadcastJoin)
5. Code Generation - Java 바이트코드로 컴파일(Whole-stage CodeGen)

### Tungsten 엔진
- 병렬화를 통해 시간 단축 + 자원 활용 극대화를 동시에 추구한다.
- 리눅스 스레드보다 더 최적화된 방식으로 병렬화한다.

Tungsten의 목표
1. 물리 실행 최적화(CPU, 메모리, 캐시 효율성)
2. 하드웨어 친화적 실행(cache-friendly, branch prediction 등)
3. JVM 오버헤드 제거 (GC 최소화, unsafe 연산, off-heap 메모리 등)

Tungsten이 OS-level 스레드를 우회하거나 대체하는 건 아니다.
Spark는 여전히 JVM 위에서 실행되며, 리눅스 스레드(커널 스레드)를 기반으로 작동하는 JVM 스레드를 사용한다.

다만:
- Spark 1.x까지는 표현적/추상적 API 위주로 덜 최적화되어 있었고
- Spark 2.x에서 Tungsten 도입 이후, 코드 생성 + 메모리 최적화 + 파이프라인 처리로 효율을 높였다는 차이가 존재하는 것이다.

### Structured Streaming
- v1에서 Dstream이라는 자료구조가 존재했고, v2에서 이를 개선해서 Structured Stream 자료구조를 만들었다.

- 또한 RDD, Dstreams를 사용하던 v1 기존 방식에서 DataFrame, DataSet, Structured Streaming을 사용하게 됐다.
- RDD 사용은 지양한다.

- Structured Streaming은 DataFrame/DataSet 기반 스트리밍 처리 API이다.
- Catalyst Optimizer, Tungsten 엔진 등 정적 최적화 기술 적용이 가능하다.
- 스트리밍을 일종의 "무한 배치 테이블"처럼 표현

DataFrame, DataSet이 권장되는 이유
- Catalyst Optimizer의 논리/물리 계획 최적화 적용 가능
- Tungsten 엔진의 코드 생성, 메모리 최적화 적용
- SQL 문법과 통합 가능
- 타입 안정성
- 즉, 성능 + 안정성 + 추상화 수준 모두 DataFrame/DataSet이 유리하다.

## Apache Spark v3
### Adaptive Query Execution(AQE)
- 실행 계획을 런타임에 동적으로 최적화
- Catalyst Optimizer와 보완관계
![[Pasted image 20251029132801.png]]

### Dynamic Partition Pruning
- 조인 조건을 기반으로 필요한 파티션만 읽음

### ANSI SQL 호환성 강화
- 더 엄격한 SQL 처리로 안정성 향상

### New UI
- 튜닝/디버깅에 매우 유용함

### Python UDF 성능 개선
- Python 사용자도 빠르게 데이터 처리 가능
- Pandas UDF = 벡터화 처리가 가능해서 성능 좋음

### GPU 및 Kubernetes 지원 강화
- 클라우드/컨테이너 환경 적응력 강화