## 빅데이터
빅데이터 -> 3V
volume velocity variety

volume -> 빅데이터 분산 처리가 필요해짐
velocity -> 빠르게 가치를 뽑아내는게 중요해짐
variety -> 데이터 형태가 다양해짐. 전통적인 RDB의 정형 데이터 말고도, 반정형 데이터, 텍스트, 이미지 등 처리 및 분석이 필요. 현대 데이터의 80%가 반정형, 비정형이다.

Veracity -> 데이터가 아무리 크고 빠르고 다양해도 정확하지 않으면 쓰레기다. 품질이 좋아야 의미가 있다.
value -> 이 모든 과정을 통해 비즈니스 가치나 통찰력을 얻어야한다.

파이프라인: 수집 -> 저장 -> 처리 -> 질의 -> 시각화


## 빅데이터를 다루기 위한 오픈소스
### 하둡
구글 GFS 논문에서 영감을 받음.
-> 이걸 오픈소스로 구현함.

1. 하드웨어 고장은 당연하다 -> 내결함성
2. 수정보단 여러번 읽는 데에 최적화한다.
	-> 네임노드 / 데이터노드

데이터노드 -> 삼중복제 -> Erasing code(저장공간 절약)

대용량 처리엔 좋지만, 작은 파일은 메모리 관리가 어렵다.

저장은 HDFS에서 담당하므로, 이 데이터를 처리하는 기술이 필요했는데, 그게 MapReduce이다.

### MapReduce
구글 논문 기반으로 발명됨. 분산 처리 프로그래밍 모델
데이터 -> 키 밸류 (MAP)
맵 단계 결과 바탕으로 키별로 값을 처리(Reduce)

대용량 데이터 처리 능력이나 노드를 늘리면 성능이 선형적으로 증가.
내결함성

문제는 Map -> Reduce 처리 중간에 값을 디스크에 저장해야해서 대규모 IO때문에 문제가 있었음.
특히 ML에서 반복해서 같은 데이터에 많이 접근해야하는 작업에서 IO 병목 현상은 큰 문제가 됐다.

### YARN
기존 하둡 1.x에서는 HDFS에서 MR만 돌릴 수 있었는데, YARN은 컴포넌트 관리를 독립시켰다.

spark 플링크 테즈같은 데이터 처리 엔진들이 하나의 클러스터를 공유하면서 돌아갈 수 있게 됐다.
-> multi tenancy

YARN은
1. 클러스터 전체를 관리하는 리소스 매니저.
2. 각 노드에서 컨테이너를 관리하는 노드 매니저
3. 개별 앱의 실행을 관리하는 어플리케이션 마스터

YARN을 통해 HDFS가 다양한 엔진이 돌아가는 플랫폼이 됐다.

### Hive
HiveQL로 데이터를 불러오고 분석할 수 있게 해준다.
Hive 자체의 쿼리 속도는 다른 기술에 비해 느릴 수 있지만, 진짜 주목해야할 것은 Hive Meta Store이다.

데이터에 대한 구조정보, 즉 메타데이터를 저장하는 중앙 저장소이다.(MySQL, Postgre 등을 사용)

빅데이터 처리 엔진 대부분이 표준처럼 사용하는 메타데이터 인터페이스로 자리잡았다.
-> 즉, 어떤 엔진을 쓰던지, HMS를 통해 데이터의 스키마 정보를 일관되게 참조할 수 있다.

최근에는 IceBerg같은 차세대 테이블 포맷과 결합되며 DL을 구축하는데 핵심적인 역할을 하며 중요성이 커지고있다.
쿼리 엔진보다 메타데이터 저장소가 더 오래 살아남아서 표준이 된 케이스다.

### Spark
가장 큰 차별점은 속도.
MR에 비해 속도가 매우 빠르다.
ML 처럼 같은 데이터를 반복해서 사용하는 작업은 데이터를 메모리에 저장해서 속도가 훨씬 빠르다.

_Spark의 핵심 장점_: 배치처리, 실시간 스트리밍 처리, SQL 쿼리, Spark QL 등 다양한 작업을 한 엔진 위에서 처리할 수 있다는게 핵심

---
**Q. 작업을 한 엔진 위에서 처리한다는게 무슨 뜻?**
A. 보통 과거에는 각각의 작업마다 다른 시스템을 써야했다.

배치처리 -> Hadoop MapReduce
실시간 스트리밍 -> Apache Storm / Flink
SQL 쿼리 -> Hive, Presto
머신러닝 -> Mahout

즉, 예전엔 서로 다른 프레임워크를 연결해야했는데, Spark는 하나의 공통 엔진(Spark Core) 위에 이 모든 기능을 올려서 통합적으로 처리한다.

---
Q. 각각이 뭐 하는 작업인거야?
A. ==배치 처리==는 "많은 데이터를 한 번에 모아서 일괄로 처리하는 방식"
예를 들어 하루 동안 쌓인 거래 데이터를 밤 12시에 한 번에 정산 한다거나, 
한 달치 로그 데이터를 모아서 주간/월간 보고서를 만든다거나 이런 작업들이 전형적인 패치 처리이다.
-> Spark Core에서 처리

==실시간 스트리밍==은 말 그대로 데이터가 들어오는 즉시 처리되는 방식, 배치 처리와는 정반대 개념이다.
예를 들어, 유튜브 실시간 시청자 수: 시청자들이 접속할 때마다 그 정보(누가, 언제, 어디서 접속했는지)가 바로 서버로 전달되고, 대시보드에 "실시간 시청자 수"가 즉시 업데이트 됨.
카드 결제 데이터가 발생할 때마다 AI 모델이 즉시 분석해서 "이상 거래 여부"를 판단. 의심 거래면 바로 차단 신호를 보냄. -> 지연 없이 "즉시 반응해야 하는" 작업도 스트리밍이다.
-> Spark Streaming에서 처리

==SQL 쿼리 작업==은 다른 저장소(HDFS, S3 등)에 있는 데이터를 SQL처럼 다루게 해주는 추상화 계층이다.
예를 들어 HIVE는 아래처럼 동작한다.
1. HDFS에 저장된 수백 GB짜리 로그 파일이 있다.
2. Hive는 "이 파일을 테이블처럼 보이게" 만들어서 사용자가 SQL로 질의할 수 있도록 함.
3. 사용자가 SELECT 쿼리를 던지면, Hive는 그걸 MapReduce 작업으로 변환해서 실행한다.
-> 즉 "SQL 문법으로 빅데이터를 처리하는 도구"

Presto도 비슷하지만, Hive보다 훨씬 빠른 분산 SQL 엔진이다.
즉, Presto는 여러 데이터 소스(HDFS, MYSQL, Cassandra 등)에 흩어진 데이터를 하나의 SQL로 질의할 수 있게 해주는 중간 계층이다.

MySQL은 데이터 저장과 SQL 실행을 통합해서 해주는 RDBMS인거고, Hive/Presto는 SQL 실행 엔진일 뿐, 데이터 저장은 하지 않는다.

---
![[고급데이터베이스_4주차_0924-87.jpg|400]]
Airbnb는 Airflow를 통해 "작업 스케줄링(언제 어떤 순서로 실행할지)"을 담당하고,
Spark를 통해 "대규모 데이터 처리(ETL, 집계, 머신러닝 등)"를 담당하며,
Hive/Presto를 통해 "SQL 기반 데이터 분석"을 담당한다.

Gold Hive Cluster와 Silver Hive Cluster는 단순히 "Hive 서버 두 개"가 아니라 "데이터의 정제 단계(데이터 품질 수준)"를 구분하기 위한 데이터 레이크 계층 구조이다.
즉, 데이터가 얼마나 가공, 정제되었는가에 따라 나눈 단계라고 보면 된다.

**Q. Hive Cluster란 무엇인가?**
A. Hive는 HDFS 위에 구축된 데이터 웨어하우스 도구이다.
즉, HDFS에 저장된 데이터를 SQL처럼 다루게 해주는 시스템이다. 그래서 "Hive Cluster"는 HDFS 기반의 데이터 저장소 + SQL 질의 엔진(Hive)이 결합된 분산 환경을 의미한다.

**Q. Gold/Silver 계층 구조란 무엇인가?**
A. Airbnb뿐 아니라 대부분의 대규모 데이터 파이프라인에서 데이터 품질을 단계별로 분리한다.
이건 ETL(Extract-Transfrom-Load) 파이프라인의 핵심이다.

|**단계**|**이름**|**특징**|**목적**|
|---|---|---|---|
|**Bronze**|Raw Layer|가공되지 않은 원본 데이터 (로그, 덤프 등)|데이터 보존용, 백업용|
|**Silver**|Cleaned Layer|정제된 데이터 (형식 통일, 오류 제거)|분석·머신러닝 전처리용|
|**Gold**|Curated Layer|완전히 집계·가공된 데이터|대시보드·BI·리포트용|
그림에서 Bronze는 생략되어 있을 뿐이다.

**Q. MySQL Dumps가 무엇인가?**
A. MySQL 데이터베이스의 내용을 파일 형태로 통째로 내보낸(export) 데이터 백업 파일이다.
이 파일은 나중에 다른 시스템(HDFS, Spark, Hive 등)으로 옮기거나, 다시 MySQL로 복구(import)할 수 있다.
이걸 왜 쓰냐면 Airbnb는 실시간 운영 DB(MySQL)에 있는 데이터를 분석용 데이터 레이크(HDFS/Hive)로 옮겨야 한다.
그때 직접 연결해서 가져오면 DB에 부담이 크니까, 
Dump 파일로 백업 -> HDFS에 업로드 -> Hive로 불러오기
이런 식으로 파이프라인을 구성하는 것이다.

이때 Sqoop이라는 도구가 dump된 데이터를 Hadoop(HDFS)으로 옮기는 역할을 한다.

**Q. Sqoop은 뭐 하는 도구인가?**
A. RDBMS와 Hadoop(HDFS, Hive, HBase 등) 사이에서 대용량 데이터를 효율적으로 옮기는(Import/Export) 도구이다.
즉, RDB <-> 분산 파일 시스템 간의 다리 역할을 한다.
Sqoop은 SQL + Hadoop의 합성어로 두 세계를 연결하는 도구라는 뜻이다.

예를 들어, 운영 DB(MySQL, Oracle 등) -> 분석용 데이터(HDFS, Hive) : 데이터를 가져오기(Import)
Hadoop(HDFS, Hive 등) -> RDBMS : 데이터를 내보내기(export)

**Q. Airflow Scheduling은 뭐 하는 도구인가?**
A. 여러 데이터 처리 작업(Spark, Sqoop, Hive, Presto 등)을 순서대로, 정해진 시간에, 자동으로 실행하게 관리하는 워크플로우 스케줄러이다.
즉, "매일 새벽 2시에 MySQL 데이터를 Hive로 옮기고, 그 후 Spark로 집계하고, 완료되면 대시보드를 업데이트하라" 이런 일련의 데이터 처리 흐름을 자동으로 돌리는 시스템이다.

**Q. Hive보다 Presto가 빠르면 Gold Hive Cluster가 아니라 Gold Presto Cluster를 사용하면 되는거 아니야?**
데이터 저장소(Storage) vs 데이터 쿼리 엔진(Query Engine)의 차이를 짚은 질문이다.
실제로 두 도구의 역할이 완전히 다르기 때문에 "Presto Cluster"로 대체할 수는 없다.

Hive는 데이터를 저장,관리하는 시스템(저장소)
Presto는 저장된 데이터를 빠르게 질의하는 시스템(엔진)

Presto는 Hive를 "읽는" 역할을 한다.

Hive는 HDFS 위에 만들어진 데이터 웨어하우스이다.
데이터를 "테이블처럼" 관리하지만, 실제로는 HDFS에 저장된 파일 집합(CSV, Parquet 등)이다.
Hive는 데이터를 "어디에, 어떤 스키마로 저장할지" 정의하는 메타데이터 레이어를 제공한다.
Hive는 /user/hive/warehouse/... 경로에 파일을 저장하고, 그걸 테이블처럼 쿼리할 수 있게 해준다.

Hive Cluster는 "데이터를 모으고, 관리하고, 정제해두는 곳"이다.

Presto는 Hive에 저장된 데이터를 읽기만 한다. Presto 자체는 데이터를 저장하지 않는다.
대신 여러 데이터 소스(Hive, S3, MySQL, Kafka 등)에 연결해서 분산 병렬 SQL 실행을 해주는 "읽기 전용 엔진"이다.
![[Pasted image 20251029000601.png|300]]
여기서 hive.gold.sales_summary는 Hive 테이블이고, Presto는 그걸 병렬로 읽어서 훨씬 빠르게 계산한다.

그래서 Airbnb는 "Gold Hive Cluster" + "Presto Cluster" 조합을 사용한다.
- Gold Hive Cluster
	- ETL이 끝난 최종 정제 데이터(=Gold Layer)가 저장되어 있는 곳 -> 데이터를 보관하고 스키마 관리
	- 데이터가 저장된 창고
	- 도서관
- Presto Cluster
	- 그 데이터를 빠르게 읽어서 SQL 분석 -> 데이터를 조회하고 분석
	- 그 창고 안에 있는 데이터를 빠르게 검색하는 분석 도구
	- 사서

결국 Gold Hive Cluster에서 Hive는 Hive Metastore를 사용하는거다. 
데이터에 대한 구조정보, 즉 메타데이터를 저장하는 것이기 때문이다.
정제된 데이터를 저장하는 곳은 HDFS이고, 그 데이터의 구조(스키마)를 관리하는게 Hive Metastore이다.

Gold Hive Cluster
 ├── HDFS (실제 데이터 저장소)
 │      └── Parquet / ORC / CSV 파일
 │
 └── Hive Metastore (메타데이터 저장소)
        ├── 테이블 이름 (예: gold.sales_summary)
        ├── 컬럼 이름과 타입 (예: region STRING, revenue DOUBLE)
        ├── 파일 포맷 (Parquet, ORC 등)
        ├── 파일 경로 (HDFS 상의 실제 위치)
        └── 파티션 정보 (예: date='2025-10-28')

---
Q. 'Presto'와 'Presto Cluster'의 차이
A. Presto는 SQL 엔진의 이름이고, "Presto Cluster"는 그 엔진이 여러 서버에 분산되어 있는 실제 운영 환경이다.
클러스터의 의미는 서버 여러 대를 묶은 하나의 논리적 시스템이다.
Airbnb처럼 데이터가 수십 테라바이트 이상으로 커질 경우, 하나의 Presto 서버로는 감당이 안되기 때문에 Presto를 여러 대에 분산 배치한다.


인메모리 처리
통합 플랫폼


### RDD
Resilient(회복력있음)
Spark의 가장 기본적인 데이터 추상화 개념
클러스터 전체에 분산되서 저장된 변경 불가능한 데이터 컬렉션

1. 불변성 -> immutability 한 번 만들어진 RDD는 내용을 바꿀 수 없다. (transformation 연산을 적용해서 새걸 만들어야함)
2. 지연평가 -> Map, Filter같은 변환 연산을 적용해도 바로 실행되는게 아니라, 기록만 해뒀다가. 실제로 결과값이 필요한 action 연산이 실행되면, 연산 전체를 최적화된 실행 계획(DAG)에 따라 한 번에 실행한다.
3. 가장 혁신적인 부분 -> 복원성, 계보(데이터 대신 생성과정을 기억해서 복구한다.)
	- Spark는 RDD가 어떤 다른 RDD로부터 어떤 변환 과정을 거쳐 만들어졌는지 생성과정(계보 lineage)를 기억한다.
	- 특정 노드가 특정 노드가 다운되서 노드가 가지고있던 RDD 파티션(데이터 조각) 유실되면 전체 데이터를 다 읽는게 아니라, 계보를 따라 필요한 노드만 찾아와 복원
	- Lineage -> Narrow, Wide

Driver 한개
- 사용자가 짠 메인 프로그램이 실행된다.
- 스파크 컨텍스트 객체를 만들고, 전체 앱의 실행흐름, 작업 흐름, 텍스트 분배 등을 조율한다.

Executor 여러개
- 워커노드에서 실행된다.
- 드라이버로부터 할당받은 계산 작업을 실행
- 중간 결과를 디스크에 저장, 캐싱

- 배포모드
	- client
		- 드라이버 프로세스가 스파크 작업을 제출한 클라이언트 머신(예: 사용자 노트북) 에서 실행
		- 개발, 디버깅 환경에 좋다.
		- 드라이버가 클라이언트 외부에 있어서
		- 머신 꺼지면 작업 전체가 실패할 수 있음
	- cluster
		- 드라이버 프로세스마저 클러스터 내부 워크노드 중 하나에서 실행
		- YARN에서는 애플리케이션 마스터 안에서 돈다
		- 세션 끊겨도 살아서 돌아가니까 안전하다.
		- 운용 환경용이다.

## Spark 버전
