

Q. 빅데이터는 데이터가 큰건데, Spark는 왜 메모리에서 처리하겠다는 건가?
A. Spark는 인메모리 기반이지만 디스크 활용을 완전히 버리지는 않는다.
- .cache() 또는 .persist()를 하면 RDD를 메모리에 캐싱하려고 시도
- 하지만 메모리가 부족하면 자동으로 디스크로 spill(fallback)
- 디스크로 갔더라도 RDD lineage(계보) 덕분에 필요시 재계산도 가능
-> 즉, Spark는 메모리에 못 올리면 죽는 시스템이 아니라 "올릴 수 있으면 빨라지고, 못 올리면 디스크라도 써서 돌아가는 시스템"
Spark가 메모리 부족을 견딜 수 있는 이유는 다음과 같다.
1. 메모리 저장 레벨 선택 가능
	```
	rdd.persist(StorageLevel.MEMORY_ONLY)
	rdd.persist(StorageLevel.MEMORY_AND_DISK)
	```
	-> 메모리에 안 들어가면 디스크에 저장하는 옵션 사용 가능

2. Lazy Evaluation + Lineage 구조
	- 메모리에 저장하지 않더라도, RDD 생성 경로를 기억하고 재계산 가능
	- 즉, 메모리에 없어도 "어떻게 만들었는지"는 기억하고있음

3. 파티셔닝을 통한 분산 처리
	- 전체 데이터를 한 노드에 올리는 게 아니라, 수천 개의 파티션으로 나눠서 여러 노드가 분산 저장

4. 중간 결과만 메모리에 올리는 방식
	- 반복 사용하는 중간 결과만 캐싱
	- 전체 데이터 X -> 핵심 중간 RDD만 O

그럼 왜 Spark가 디스크 기반 MapReduce보다 빠른 걸까?
|**항목**|**MapReduce**|**Spark**|
|---|---|---|
|**중간 결과**|디스크에 저장|메모리에 캐싱|
|**반복 작업**|매번 디스크 IO 발생|중간 RDD 재사용 가능|
|**쿼리 응답 속도**|수십 초~분|수 초 이내도 가능|
|**스트리밍 처리**|구조적으로 어려움|Structured Streaming으로 대응 가능|


| **계층**               | **구성 요소**             | **설명**                                     |
| -------------------- | --------------------- | ------------------------------------------ |
| **Storage Layer**    | **HDFS**              | 여전히 주요한 분산 파일 시스템 (데이터 저장 담당)              |
| **Compute Layer**    | **MapReduce → Spark** | 데이터를 처리하는 계산 엔진. Spark가 주류로 교체됨            |
| **Resource Manager** | **YARN**              | Spark든 MapReduce든, 자원(CPU, 메모리)을 할당해주는 관리자 |


## Part1: Spark의 탄생과 기본 개념
### 1. MapReduce의 한계와 문제 정의
- MR은 배치 처리에는 강하지만, "반복적인 알고리즘"에서는 매 반복마다 디스크 IO가 발생하여 성능 저하
- 쿼리당 수십~수백 초의 지연이 생기며, 탐색적 분석이나 대화형 쿼리에는 부적합
- 데이터를 매번 HDFS에서 읽고 쓰는 구조로 인해, 반복 작업이나 실시간 분석의 병목이 심각
### 2. Spark의 핵심 아이디어와 RDD 초기 개념
- 핵심 아이디어: Working Set을 메모리에 유지하면서 반복 접근 최적화
- RDD(Resilient Distributed Dataset) 도입으로 메모리 기반 반복 연산 가능
- 불변 객체(Immutable)와 지연 평가(Lazy Evaluation)로 설계되어 효율적인 재사용, 장애 복구 가능

### 3. Spark 프로그래밍 모델
- MR과 달리 다양한 연산을 지원하는 함수형 프로그래밍 스타일
- RDD를 생성한 뒤, Transformation(변환)과 Action(실행)을 조합하여 처리 흐름 구성
- Scala 기반의 APi 설계로 높은 추상화 제공
- SQL, 스트리밍, 머신러닝 등을 하나의 통합 엔진에서 실행 가능
### 4. 구체적 예제를 통한 이해

### 5. 초기 성능 평가 결과
- Hadoop 대비 최대 100배 빠른 처리 성능을 기록
- 반복 연산이 많은 워크로드에서 성능 이점이 가장 뚜렷하게 드러남
- Berkeley AMPLab 실험에서 기존 MR로 수백 초 걸리던 작업을 Spark는 수십 초 내로 단축

## Part2: RDD 고급 개념

### 1. 2012년 논문 개요 및 발전 사항
- 논문: "Resilient Distributed datasets: A Fault-Tolerant Abstraction for In-Memory Cluster Computing"
- RDD가 단순 캐시가 아닌, 복원력 있는 계산 단위로 작동하는 이론적 근거를 설명
- RDD의 Lineage 기반 장애 복구 매커니즘을 정형화
### 2. 저자진 확장과 연구 심화
- Matei Zaharia 외에도 Mosharaf... 등 공통 연구
- 이후 이들이 Databricks, Spark Summit 등 Spark 생태계 성장의 주축이 됨
### 3. RDD의 발전된 개념과 이론적 기반
- RDD는 클러스터 전체에 걸쳐 분산되며, 불변하고, 명확한 연산 계보를 가짐
- Lineage DAG를 통해 중간 노드 손실 시에도 연산 경로를 따라 자동 복구 가능
- Transformation은 실행 계획만 정의하고, Action이 호출될 때 평가됨


- RDD의 아이디어는 "데이터 그 자체를 복제하지 말고 그 데이터를 어떻게 만들었는지(연산 그래프)만 저장하자"였다.
- Spark는 각 RDD가 생성될 때 다음 정보를 함께 보관한다.
	1. 데이터 출처(Source) - 예: HDFS파일, textFile() 등
	2. 적용된 연산(Transformation) - 예: map, filter, join 등
	3. 부모 RDD 정보(Dependencies) - 어떤 RDD에서 나왔는가
- 이 모든 걸 합치면 RDD의 Lineage DAG가 만들어진다.

- Spark는 복제 없이도 결정적 연산(Deterministic Transformation) + 불변 데이터 + 계보 추적을 통해 "이론적으로 안정적 복원력(resilience)"을 확보한 셈이다.

### 4. 혁신적인 내결함성 매커니즘
- Checkpoint 없이도 연산 계보만으로 복원 가능(Lineage 기반)
- 기존 시스템은 로그나 복제 기반 도구, Spark는 계산 그래프를 재생성
- 장애 발생 시, 해당 RDD만 다시 계산하고 전체 워크플로우를 다시 실행하지 않음

### 5. 고급 성능 최적화 기법
- RDD Persistence 전략: MEMORY_ONLY, MEMORY_AND_DISK 등 다양한 저장 옵션을 제공하여 리소스 효율 극대화
- 필요에 따라 데이터 캐시 레벨을 조정하여 메모리 압박과 성능 간의 균형을 조절
- 특정 RDD는 unpersist()로 명시적 제거 가능
### 6. 확장된 실험 결과와 검증

### 7. 실제 적용 사례와 영향
- 머신러닝: K-means, SVM 등 반복 연산 알고리즘에 최적
- 로그 분석, 그래프 처리, 스트리밍 분석에 광범위하게 활용됨
- Spark의 설계는 이후, Flink, Beam, Ray 같은 분산 처리 시스템에 영향을 줌
- 2010년대 이후, Hadoop 생태계 중심이 MR에서 Spark로 이동하는 전환점이 됨.


- Narrow Dependency
	- 부모 RDD의 각 파티션이 최대 하나의 자식 파티션에만 영향을 줌
	- map(), filter(), union()

- Wide Dependency
	- 부모 RDD의 각 파티션이 여러 자식 파티션에 영향을 줌
	- groupByKey(), join()

### 8. 파티셔닝 전략 - Hash, Range, Custom
1. Hash Partitioning
	- 키의 해시값을 기준으로 데이터 분배, 균등한 분포가 장점이나 순서 보존이 안된다.

2. Range Partitioning
	- 키의 순서를 보존하여 정렬된 데이터에 효과적, 데이터 편향 가능성 있음

3. Custom Partitioning
	- 특수 요구사항에 맞게 구현 가능, Partitioner 클래스 상속

