
# **10번 자료: 벡터 데이터베이스 기초 (Vector Database Basic)**

  

  

이 자료는 크게 보면

  

> **“임베딩 → 벡터 공간 → 벡터 DB → 실제 검색/활용”**

> 이라는 하나의 흐름으로 구성되어 있습니다.

---

## **1장: Embedding (임베딩)**

  

### **핵심 내용 (2문단)**

  

임베딩은 **단어, 문장, 문단과 같은 비정형 데이터를 고정된 차원의 수치 벡터로 변환**하는 과정이다. 이 벡터는 의미적 유사성이 공간적 거리로 반영되도록 학습되며, 사람의 언어·이미지·특징을 기계가 계산 가능한 형태로 바꾸는 역할을 한다. 중요한 점은 입력 데이터의 길이나 복잡도와 무관하게, **출력 벡터의 차원은 모델에 의해 고정**된다는 것이다.

  

또한 임베딩 벡터가 위치하는 공간은 **Latent Space(잠재 공간)**로, 각 차원은 사람이 직접 정의한 의미가 아니라 **모델이 데이터로부터 학습한 추상적 특징 축**이다. 이 공간에서의 거리(코사인 유사도, L2 등)는 의미적 유사성을 근사하며, 임베딩의 품질은 “얼마나 중요한 정보가 이 제한된 공간에 잘 보존되었는가”로 판단된다.

---

### **핵심 질문**

- **서로 다른 크기와 형태의 데이터(단어/문장/문단)를 왜 같은 차원의 벡터로 표현할 수 있는가?**
    
- 임베딩 차원이 커진다는 것은 **정보량 증가**인가, **표현 능력 증가**인가?
    
- Latent Space에서 “각 차원은 무엇을 의미하는가?”라는 질문이 왜 성립하지 않는가?
    

---

### **시험 문제(예시)**

- 다음 세 가지 “단어”, “문장”, “문단”은 같은 벡터 공간으로 임베딩할 수 있는가?
    
    다시 말해, 이들을 같은 크기의 벡터로 변환할 수 있는가?
    
- all-MiniLM-L6-v2 모델은 384차원, jhgan/ko-sroberta-multitask 모델은 768차원이다.
    
    차원이 2배라는 것은 어떤 의미이며, 각 차원은 어떤 의미를 갖는가?
    

---

## **2장: Vector Database (벡터 데이터베이스)**

  

### **핵심 내용 (2문단)**

  

벡터 데이터베이스는 **임베딩된 벡터를 저장하고, 벡터 간 유사도 기반 검색(Similarity Search)을 수행하는 시스템**이다. 기존 RDB나 키워드 기반 검색과 달리, 정확히 같은 값이 아니라 **의미적으로 가까운 데이터**를 빠르게 찾는 데 목적이 있다. 이를 위해 벡터 DB는 고차원 공간에서의 근접 탐색(ANN: Approximate Nearest Neighbor)을 최적화한다.

  

또한 벡터 DB는 단순 저장소가 아니라, **embedding model, similarity metric, indexing 전략, upsert 방식**과 긴밀히 결합된 시스템이다. 어떤 임베딩 모델을 쓰는지, 차원이 얼마인지, 데이터 규모와 메모리 제약이 무엇인지에 따라 **적절한 DB 구조와 설정이 달라진다**. 따라서 벡터 DB의 선택은 “성능 좋은 DB”의 문제가 아니라 **문제 정의와 시스템 설계의 문제**다.

---

### **핵심 질문**

- 왜 기존 관계형 DB나 키워드 검색으로는 임베딩 검색이 충분하지 않은가?
    
- 벡터 DB에서 “정확 검색”이 아니라 “근사 검색”을 사용하는 이유는 무엇인가?
    
- 임베딩 모델의 차원·성능과 벡터 DB의 메모리/성능은 어떻게 트레이드오프 관계에 있는가?
    

---

### **시험 문제(예시)**

- 임베딩 벡터를 저장하는 데 있어, 기존 데이터베이스 대신 벡터 데이터베이스가 필요한 이유를 설명하라.
    
- 384차원 임베딩과 768차원 임베딩을 사용할 때, 벡터 데이터베이스 관점에서 발생하는 차이점은 무엇인가?
    

---

## **3장: Embedding + Vector DB의 실제 활용 관점 (암묵적 장)**

  

> 이 장은 명시적 제목보다는 **여러 그림과 비교 자료**로 반복 등장합니다.

  

### **핵심 내용 (2문단)**

  

임베딩과 벡터 DB는 단독 기술이 아니라, **검색·추천·RAG·AI 시스템의 기반 인프라**로 사용된다. 실제 시스템에서는 문서를 적절히 분할(chunking)한 뒤 임베딩하고, 이를 벡터 DB에 저장한 후, 사용자 질의를 임베딩하여 유사 문서를 검색한다. 이 과정 전체의 품질은 **가장 약한 단계 하나에 의해 제한**된다.

  

또한 현실적인 제약(메모리, GPU, 응답 시간, 언어 성능)에 따라 “가장 성능 좋은 모델”이 아니라 **“목적에 맞는 모델”을 선택해야 한다**는 점이 반복적으로 강조된다. 즉, 이 자료는 기술 스펙보다 **설계 판단 능력**을 요구한다.

---

### **핵심 질문**

- 임베딩 모델의 성능이 좋아도 검색 품질이 나빠질 수 있는 이유는 무엇인가?
    
- 벡터 DB 성능 문제는 모델 문제인가, 시스템 설계 문제인가?
    
- “한국어 성능이 좋은 임베딩 모델”이라는 말은 무엇을 전제로 하는가?
    

---

### **시험 문제(예시)**

- 임베딩 모델의 성능은 우수하지만 검색 결과의 품질이 낮은 경우, 점검해야 할 요소를 설명하라.
    
- 한국어 임베딩 검색에서 문제가 발생하는 원인과 해결 방향을 설명하라.
    

---

## **10번 자료를 관통하는 한 줄 핵심**

  

> **이 자료는 “벡터 DB가 무엇인가”보다**

> **“왜 임베딩과 벡터 DB를 하나의 시스템으로 사고해야 하는가”를 묻는다.**

---

다음 단계로 바로 이어서 할 수 있는 것:

- **11번 자료(대형언어모델의 이해)**를 **같은 포맷**으로 정리
    
- 또는, **10번 자료의 시험문제(예시) 하나를 A+ 답안 수준으로 같이 작성**
    

  

다음은 **11번부터 바로 갈까요**, 아니면 **10번 시험문제 답안 연습**을 먼저 할까요?