알겠습니다.

아래는 **14번 자료: 「Practical Issues (Actual Problems in Real World)」**를 기준으로, 지금까지 정리한 **10–13번 전체 내용을 ‘현실 검증 단계’에서 재해석**하는 방식으로 장별 핵심 질문을 추출한 결과입니다.

이 장은 교수님이 말한 **“열심히 해도 못 풀 수 있는 문제”**가 가장 자연스럽게 나오는 파트입니다.

---

# **14번 자료: Practical Issues (Actual Problems in Real World)**

  

  

이 자료의 핵심 메시지는 명확합니다.

  

> **“이론적으로 맞는 구조가**

> **실제 환경에서는 왜 그대로 동작하지 않는가?”**



즉, 지금까지 배운 모든 개념을 **현실의 제약 조건 아래에서 다시 생각하게 만드는 장**입니다.

---

## **1장: 임베딩 & 벡터 DB – 현실에서 발생하는 문제들**

  

### **핵심 내용 (2문단)**

  

이론적으로 임베딩과 벡터 DB는 “의미 검색”을 잘 수행해야 하지만, 현실에서는 **언어, 도메인, 데이터 분포 차이**로 인해 기대한 성능이 나오지 않는 경우가 많다. 특히 한국어 환경에서는 임베딩 모델에 따라 검색 성능이 급격히 달라지며, 같은 벡터 DB라도 **모델 선택이 잘못되면 전체 시스템이 실패**한다.

  

또한 데이터 규모가 커질수록, 임베딩 차원·모델 크기·메모리 사용량·검색 속도 사이의 트레이드오프가 현실적인 제약으로 등장한다. 이 장은 “성능이 좋은 모델”보다 **“환경에 맞는 모델”을 선택해야 한다는 점**을 반복적으로 강조한다.

---

### **핵심 질문**

- 이론적으로 좋은 임베딩 모델이 실전에서 실패하는 이유는 무엇인가?
    
- 임베딩 차원 증가가 항상 검색 품질 향상으로 이어지지 않는 이유는 무엇인가?
    
- 벡터 DB 문제는 모델 문제인가, 시스템 문제인가?
    

---

### **시험 문제(예시)**

- 한국어 임베딩 검색에서 문제가 발생하는 원인과 해결 방향을 설명하라.
    
- 임베딩 모델 선택 시 고려해야 할 현실적인 요소를 설명하라.
    

---

## **2장: LLM – 환각(Hallucination)과 신뢰성 문제**

  

### **핵심 내용 (2문단)**

  

LLM은 그럴듯한 답변을 생성하는 데 매우 능숙하지만, **사실 여부를 판단하거나 검증하는 능력은 없다**. 이로 인해 존재하지 않는 정보를 만들어내는 환각(hallucination)이 발생한다. 이는 모델 성능 부족이 아니라, **확률 기반 생성 모델이라는 구조적 특성**에서 비롯된다.

  

이 장에서는 “LLM이 틀릴 수 있다”는 사실보다, **“틀려도 확신에 차 보인다”** 는 점이 실제 서비스에서 얼마나 위험한지를 강조한다. 따라서 LLM을 단독으로 신뢰하는 시스템은 현실에서 사용하기 어렵고, **검증·제약·보완 구조가 필수**가 된다.

---

### **핵심 질문**

- Hallucination은 왜 구조적으로 발생하는가?
    
- LLM의 답변을 신뢰하기 어려운 이유는 무엇인가?
    
- LLM을 ‘지식 시스템’으로 사용하면 안 되는 이유는 무엇인가?
    

---

### **시험 문제(예시)**

- LLM에서 hallucination이 발생하는 구조적 이유를 설명하라.
    
- LLM 단독 사용이 실서비스에서 위험한 이유를 설명하라.
    

---

## **3장: RAG – 기대와 현실의 차이**

  

### **핵심 내용 (2문단)**

  

RAG는 LLM의 한계를 보완하는 강력한 구조이지만, **RAG를 적용한다고 해서 자동으로 정확해지지는 않는다**. 문서 파싱 오류, 부적절한 chunking, 낮은 검색 품질, 과도한 컨텍스트 등은 오히려 답변 품질을 떨어뜨릴 수 있다.



이 장은 RAG를 “만능 해결책”으로 오해하는 태도를 경계하며, **RAG의 성능은 대부분 Retrieval 이전 단계에서 결정된다**는 점을 강조한다. 즉, 문제는 LLM이 아니라 **데이터 준비와 파이프라인 설계**다.

---

### **핵심 질문**

- RAG를 적용했음에도 환각이 발생하는 이유는 무엇인가?
    
- Retrieval 품질이 RAG 전체 성능에 미치는 영향은 무엇인가?
    
- RAG의 실패는 모델 실패인가, 시스템 실패인가?
    

---

### **시험 문제(예시)**

- RAG 시스템에서 발생할 수 있는 현실적인 문제를 설명하라.
    
- RAG의 성능을 개선하기 위해 우선적으로 점검해야 할 요소는 무엇인가?
    

---

## **4장: 시스템 관점의 문제 – 성능, 비용, 운영**

  

### **핵심 내용 (2문단)**

  

현실의 AI 시스템은 정확도뿐 아니라 **비용, 응답 시간, 확장성, 운영 안정성**을 동시에 만족해야 한다. 고성능 임베딩 모델이나 대형 LLM은 비용과 지연(latency)을 증가시키며, 이는 서비스 품질 저하로 이어질 수 있다.

  

따라서 실제 환경에서는 “최고 성능”이 아니라 **“충분히 좋은 성능을 안정적으로 유지하는 구조”**가 중요하다. 이 장은 AI 시스템을 연구 대상이 아니라 **운영 대상 시스템**으로 바라보는 관점 전환을 요구한다.

---

### **핵심 질문**

- 실제 서비스 환경에서 AI 시스템의 성공 기준은 무엇인가?
    
- 성능과 비용 사이의 균형은 어떻게 판단해야 하는가?
    
- AI 시스템을 운영 관점에서 설계해야 하는 이유는 무엇인가?
    

---

### **시험 문제(예시)**

- AI 시스템 설계 시 성능 외에 고려해야 할 요소를 설명하라.
    
- 연구용 모델과 서비스용 모델의 차이를 설명하라.
    

---

## **5장: Practical Issues의 종합 메시지**

  

### **핵심 내용 (2문단)**

  

이 장의 모든 내용은 하나의 메시지로 수렴한다.

**“이론적으로 옳은 구조 ≠ 현실에서 성공하는 시스템”**이다.

현실에서는 데이터 품질, 시스템 제약, 운영 비용, 사용자 행동이 모두 결과를 좌우한다.

  

따라서 좋은 답안은 “기술을 나열하는 답”이 아니라,

**제약을 인식하고, 그 안에서 합리적인 선택을 설명하는 답**이다.

이것이 교수님이 말한 “분별력”의 실체다.

---

### **핵심 질문**

- 이 과목에서 말하는 ‘분별력’이란 무엇인가?
    
- 왜 현실 문제에는 정답이 하나가 아닌가?
    
- 이론과 실무의 간극을 어떻게 설명할 수 있는가?
    

---

### **시험 문제(예시)**

- 실제 환경에서 AI 시스템이 실패하는 주요 원인을 설명하라.
    
- 이론적으로 옳은 AI 구조가 현실에서 그대로 적용되지 않는 이유를 설명하라.
    

---

## **14번 자료를 관통하는 한 줄 핵심**

  

> **이 자료는 “왜 안 되는가”를 묻는 것이 아니라**

> **“안 된다는 사실을 인식한 상태에서 어떻게 설계할 것인가”를 묻는다.**

---

### **지금 상태 정리 (매우 중요)**

  

이제 당신은 이미:

- **10번**: 임베딩·벡터 공간의 본질
    
- **11번**: LLM의 능력과 구조적 한계
    
- **12번**: RAG라는 시스템적 해결
    
- **13번**: Agent·MCP로 확장되는 현대적 설계
    
- **14번**: 현실 제약 속에서의 판단
    

  

👉 **시험에 필요한 ‘개념 지도’는 완성**되었습니다.

  

다음으로 가장 효과적인 단계는 둘 중 하나입니다.

1. **시험문제(예시)를 실제 답안 수준으로 같이 작성**
    
    → “이 정도면 A” 기준 만들기
    
2. **10–14번을 관통하는 ‘한 장짜리 시험용 사고 프레임’ 정리**
    

  

어느 쪽으로 갈지 말씀해 주세요.