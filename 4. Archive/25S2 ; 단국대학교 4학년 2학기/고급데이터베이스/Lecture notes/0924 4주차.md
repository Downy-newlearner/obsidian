Lecture materials: 고급데이터베이스_4주차_0924

## 1. 빅데이터
이제는 RDB로 처리할 수 없는 대규모 데이터셋이다.


## 2. "알파고"의 등장
- 좋은 알고리즘이라도 컴퓨팅 파워가 필요하다.
- 알파고가 등장할 수 있던 이유는 '인프라'다.

- GFS(Google File System)은 오픈소스 하둡 분산 파일 시스템(HDFS)의 기반이 되었다.
- 데이터 청크를 2~4복제를 하여 저장해서 장애에 대비한다.

- 구글의 실수
	- 마스터 서버를 단일로 두었다. 당시엔 괜찮을 줄 알았나보다.
	- 요즘엔 데이터량이 굉장히 많아지면서 단일 마스터로 감당이 안돼서 2중화, 3중화를 한다.

- 알파고 이후에 AI 기술이 크게 변화했다.

p. 28-30 패스

## 3. 빅데이터 진화

- 빅데이터 5V가 되면서 데이터 품질(Veracity, 진실성)과 가치(Value)가 조명받았다.

**Veracity**
- 데이터 품질은 발견하는 시점이 중요하다.
	1. 늦게 발견하면 안됨
	2. 사용자들이 보는 데이터가 특정 DB 단위가 아니고, 그 곳에서 뽑아낸 데이터를 DW, DL로 구축한 후 분석가들이 모델로 분석한 결과를 사용자들이 보는 것이다. 이 과정에서 얼마나 빨리 품질 이슈를 발견하느냐가 중요하다.

**Visualization**
- 인간 두뇌는 이미지를 통한 정보 습득이 표나 숫자보다 훨씬 빠르다.

- 빅데이터 + AI관계는 뗄레야 뗄 수 없다.

- HDFS이 빅데이터의 시초라고 얘기할 수 있다.

- 기업들이 사용자의 데이터를 차곡차곡 수집한다.
- 그 데이터로 모델을 만들어 서비스에 활용한다.

## 4. 빅데이터 처리를 위한 오픈소스 생태계

**Kafka**
- 거대 데이터큐이다.