## 데이터 파이프라인 구축
### Hadoop(Opensource) Ecosystem
데이터 수집 -> 데이터 저장 -> 데이터 처리 -> 질의/분석 -> 시각화/BI


## HDFS란 무엇인가?
하둡의 메인 오픈소스
HDFS는 한 번 쓰고 여러 번 읽는 패턴에 최적화된 파일 시스템
데이터 일관성보다는 높은 처리량(throughput)을 우선시하는 철학을 갖고 있다.
기본적으로 3개의 복제본을 통해 안정성 확보

## Spark는 무엇인가?
MapReduce -> Disk I/O 대량 발생 -> 속도 저하
Spark -> 메모리 기반 처리 -> 속도 향상

## Apache Airflow - 워크플로우 오케스트레이션
Python으로 작성된 DAG를 통해 작업 간의 의존성 관계를 정의함
오퍼레이터를 통해 코딩을하고 파이썬으로 실행 가능

## 중간고사 문제 같이 풀어보기
![[Pasted image 20251105144649.png]]
대용량 데이터 저장: HDFS
	분산 파일 시스템으로 TB/PB급 데이터 저장 가능
	데이터 복자를 통한 내결함성 제공
분산 병렬 데이터 처리: Spark
	메모리 기반 분산 처리로 대용량 데이터 고속 처리
	다양한 분석 라이브러리 제공
데이터 파이프라인 자동화: Airflow
	DAG 기반 워크플로우 스케줄링
	실패 시 재시도
	모니터링 및 알림 기능 제공
### 데이터 플로우
데이터 수집 -> 임시 저장 -> HDFS 업로드 -> 센서 대기(문제 생기면 알림 발생) -> Spark 처리 -> HDFS 결과 -> 검증 & 완료

### 전체 시스템 아키텍처(Airflow)
Airflow server가 파이프라인의 전반적인 지휘자 역할을 수행


## TeraOne
데이터파이프라인을 쉽게 구축할 수 있다.
대시보드를 통해 모니터링이 가능하다.

## Apache Kudu
Fast Analytics on Fast Data를 위한 컬럼기반 스토리지

### 핵심 가치
1. 실시간 변경 데이터에 대한 빠른 분석
2. 정형화된 데이터 구조, 효율적 스캔/압축

### 데이터 모델: Table, Tablet, Schema
1. Table
2. Tablet
	- 테이블을 키 범위로 나눈 파티션
	- 데이터 분산 처리의 기본 단위
	- 하둡에선 블록, Kudu에선 태블릿
3. Schema
	- 각 컬럼의 데이터 타입 명시 필수
	- 반드시 기본키(PK) 정의 필요

### 데이터의 분산 저장 방식
- Kudu는 ==수평 분할(Horizontal Partitioning)==을 한다.
	- 하나의 테이블 -> 여러 Tablet으로 자동 분할
	- 각 Tablet은 서로 다른 서버에 분산 배치

- 복제 및 고가용성
	- 각 Tablet은 기본 3개 복제본 유
	- Raft 합의 알고리즘으로 일관성 및 고가용성 보장

- 중앙 집중 메타데이터 관리
	- 스키마 정보는 Master가 관리
	- 모든 Tablet Server가 동일한 스키마 공유

### 읽기/쓰기 경로와 성능
- 쓰기: 리더가 요청 수신
- 읽기: 컬럼 단위 스캔, 파티션 프루닝으로 범위 최소화

### Raft 합의 알고리즘
- Raft는 리더를 선출하는 무언가.(과반수 커밋 보장)

- 논리 복제(Logical Replication
	- 쓰기 연산을 복제

### Kudu vs HBase vs HDFS(Parquet)
모두 저장하는 역할을 함.

### Kudu 주요 사용 사례
- 실시간 이벤트 분석
- CDC(Change Data Capture, git diff과 같은 느낌) 기반 실시간 분석
- 스트리밍 + 배치 하이브리드
## Apache Impala
### 핵심 가치
- 대화형 분석을 위한 저지연 SQL 쿼리
- MPP 아키텍처로 대규모 병렬 처리
- 다양한 오픈 포맷

Hive를 쓰는데 느려서 Impala를 쓰는 것이다.

### Statestore



## Apache NiFi