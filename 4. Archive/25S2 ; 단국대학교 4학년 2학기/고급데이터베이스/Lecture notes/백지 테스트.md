
Q. HDFS의 네임노드와 데이터노드가 무엇인가? / 마스터-슬레이브 아키텍처가 무엇인가?


Q. SparkContext란 무엇인가?

**1. Hadoop 아키텍처의 발전과 한계 극복**

Hadoop 1.x 아키텍처에서 MapReduce의 중앙 관리자 역할을 했던 **JobTracker**는 자원 관리와 작업 처리를 모두 담당하면서 SPOF(Single Point of Failure), 확장성 제한 등의 문제를 야기했습니다. Hadoop 2.x 버전에서 이러한 한계를 극복하고 다양한 워크로드 지원을 위해 도입된 시스템은 무엇이며, 이 시스템이 도입됨으로써 MapReduce의 역할이 어떻게 변화했는지 설명하시오.

YARN이다. YARN은 JobTracker가 담당했던 자원관리와 애플리케이션 실행 역할을 분리했다. 이로 인해 MapReduce는 자원 관리 역할에서 손을 떼고, 단순한 데이터 처리 엔진으로 전환되어 다양한 처리방식(Spark, Tez)과 공존하는 선택지가 될 수 있었다.




**2. HDFS의 대용량 블록 사용의 이점**

HDFS는 대용량 데이터 처리를 위해 일반 파일 시스템보다 훨씬 큰 블록(Block) 단위를 사용합니다. 이처럼 대용량 블록을 사용하는 것이 **탐색 비용 감소** 외에 가지는 장점 세 가지를 서술하시오. 이 장점 중 MapReduce 작업에 최적화와 관련된 내용을 포함하여 설명해야 합니다.

1. ==네트워크 오버헤드 감소==: 데이터 처리 시 메타데이터 교환 비용이 절감된다.
2. ==관리 단순화==: 수백만 개의 작은 블록보다 수천개의 큰 블록 관리가 효율적이다.
3. ==MapReduce 작업에 최적화==: 대용량 데이터 처리를 위한 병렬 작업 단위로 적합하다.

**MapReduce가 무엇인지 서술하시오**
구글이 대규모 데이터를 분산 처리하기 위해 제안한 프로그래밍 모델로, 데이터를 key, value 형태로 나누어 병렬로 처리한다.
Map 단계에서는 데이터를 분할하여 매핑하고, Reduce 단계에서는 이를 집계하거나 요약한다.
Hadoop에서 이 모델을 구현하여 대용량 배치 처리에 활용되었지만, 중간 결과를 디스크에 저장하는 구조로 인해 반복 작업에는 비효율적이다.
Spark 등 인메모리 기반 시스템의 등장은 MapReduce의 한계를 보완하며 주류 기술을 대체하게 되었다.


**2. Hive MetaStore (HMS)와 Iceberg의 역할**

Hive MetaStore (HMS)는 데이터를 직접 저장하지 않음에도 불구하고 빅데이터 시스템의 **공용 네비게이션** 같은 역할을 수행한다고 설명됩니다. HMS의 핵심 역할은 무엇이며, Spark나 Flink 같은 여러 분석 엔진들이 HMS를 공용으로 사용함으로써 얻는 이점을 설명하시오. 또한, 넷플릭스가 만든 현대식 오픈 테이블 포맷인 **Iceberg**가 HMS와 연계되어 사용될 때, 기존 Hive 관리 방식보다 강력해진 유연성(제공하는 기능) 세 가지를 서술하시오.

HMS의 역할은 데이터의 주소록 및 설명서 역할을 하는 메타데이터 저장소이다.


**3. Spark v2의 핵심 최적화 엔진 두 가지**

Apache Spark v2에서 도입되어 성능을 획기적으로 향상시킨 두 가지 핵심 기술은 **Catalyst Optimizer**와 **Tungsten 엔진**입니다. 이 두 기술이 각각 어떤 주된 목표(예: 논리적/물리적 계획 최적화 vs. 하드웨어 효율성)를 가지고 Spark의 성능을 개선하는지 설명하시오. 특히 Catalyst Optimizer가 실행 가능한 물리적 연산을 선택할 때 결정하는 중요한 최적화 결정의 예시 하나를 제시하시오.

**4. RDD의 의존성 유형과 실행 전략**

RDD의 연산 계보(Lineage DAG)를 구성하는 방식에는 **Narrow Dependency**와 **Wide Dependency** 두 가지 유형이 있습니다. 다음 질문에 답하시오.

1. 두 의존성 유형 중 **부모 RDD의 각 파티션이 여러 자식 파티션에 영향**을 주는 유형은 무엇이며, 이 유형의 대표적인 연산 예시 하나를 제시하시오.

2. 이 유형의 의존성이 발생했을 때, Spark의 DAG Scheduler가 연산 흐름을 **Stage로 분할**하는 주된 이유를 설명하시오.

**5. HDFS의 한계 및 클라우드 환경과의 충돌**

HDFS는 데이터 복제 매커니즘을 통한 안정성과 페타바이트 규모 처리 역량을 제공하지만, 현대의 실시간 분석이나 클라우드 네이티브 환경에서는 몇 가지 근본적인 한계를 보입니다. HDFS가 가지는 기술적 한계점 중 **실시간 데이터 처리 불가** 외에 다른 두 가지를 서술하고, 또한 HDFS가 Kubernetes(K8s)와 상성이 좋지 않은 이유를 **Stateful/Stateless** 개념을 중심으로 설명하시오.