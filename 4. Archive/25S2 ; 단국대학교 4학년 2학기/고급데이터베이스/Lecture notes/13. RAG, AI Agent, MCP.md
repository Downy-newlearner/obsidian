알겠습니다.

아래는 **13번 자료: 「RAG, AI Agent, MCP (Modern AI Trends)」**를 기준으로, 지금까지 정리한 10·11·12번과 **하나의 사고 흐름으로 연결되도록** 장별 핵심 질문을 추출한 내용입니다.

이 자료는 **시험에서 ‘분별력 문제’가 가장 나오기 쉬운 장**입니다.

---

# **13번 자료: RAG, AI Agent, MCP (Modern AI Trends)**

  

  

이 자료의 핵심은 새로운 기술 나열이 아니라,

  

> **“LLM을 단일 모델이 아닌 ‘행동하는 시스템’으로 확장하는 사고 전환”**

> 에 있습니다.

---

## **1장: RAG의 재정의 – In-context Learning 관점**

  

### **핵심 내용 (2문단)**

  

이 장에서 RAG는 단순한 “검색 + 생성” 구조가 아니라, **In-context Learning의 시스템적 확장**으로 재해석된다. 즉, LLM은 파라미터를 업데이트하지 않고도, **컨텍스트로 주어진 정보에 기반해 새로운 문제를 해결**할 수 있다. RAG는 이 특성을 활용해, 외부 지식을 “일시적 기억”처럼 주입하는 구조다.

  

중요한 점은 RAG가 **모델 내부 지식을 바꾸지 않는다**는 사실이다. Retrieval된 정보는 LLM의 가중치가 아니라 입력 컨텍스트로만 작용하며, 이 때문에 RAG는 **빠른 업데이트, 도메인 분리, 보안 측면에서 유리**하다. 반대로, 컨텍스트 길이 제한이라는 새로운 병목도 함께 발생한다.

---

### **핵심 질문**

- RAG는 Fine-tuning과 비교해 어떤 장단점을 가지는가?
    
- In-context Learning이 RAG의 핵심 메커니즘인 이유는 무엇인가?
    
- “일시적 지식”이라는 표현은 무엇을 의미하는가?
    

---

### **시험 문제(예시)**

- RAG를 In-context Learning 관점에서 설명하라.
    
- RAG와 Fine-tuning의 차이를 지식 반영 방식 중심으로 설명하라.
    

---

## **2장: General Knowledge vs Specific Knowledge**

  

### **핵심 내용 (2문단)**

  

LLM은 대규모 공개 데이터로 학습된 **General Knowledge**에는 강하지만, 기업·조직·도메인 고유의 **Specific Knowledge**에는 본질적으로 접근할 수 없다. 이 장에서는 이 두 지식의 성격 차이를 명확히 구분하며, RAG가 필요한 이유를 다시 강조한다.

  

특히 Specific Knowledge는 자주 변경되고, 보안 이슈가 있으며, 모델 학습에 사용될 수 없는 경우가 많다. 따라서 이를 파라미터에 내재화하려는 시도는 비현실적이며, **검색 기반으로 외부에서 주입하는 구조가 합리적**이라는 결론으로 이어진다.

---

### **핵심 질문**

- General Knowledge와 Specific Knowledge의 차이는 무엇인가?
    
- Specific Knowledge를 LLM에 직접 학습시키기 어려운 이유는 무엇인가?
    
- RAG는 어떤 종류의 지식에 특히 적합한가?
    

---

### **시험 문제(예시)**

- LLM이 기업 내부 지식에 취약한 이유를 설명하라.
    
- RAG가 기업 환경에서 중요한 이유를 설명하라.
    

---

## **3장: AI Agent의 개념 – LLM은 도구가 된다**

  

### **핵심 내용 (2문단)**

  

AI Agent는 LLM을 “답변 생성기”가 아니라, **목표를 달성하기 위해 행동하는 주체**로 사용하는 개념이다. 즉, LLM은 스스로 판단하고 실행하는 존재가 아니라, **계획(plan), 판단(decision), 호출(action)** 의 중심에서 오케스트레이션 역할을 수행한다.

  

이 구조에서 중요한 점은 **LLM이 직접 실행하지 않는다**는 것이다. 실제 작업은 외부 도구(API, DB, 서비스)가 수행하며, LLM은 어떤 도구를 언제 호출할지를 결정한다. 따라서 AI Agent의 성능은 모델 성능보다도 **상태 관리, 오류 처리, 제어 구조 설계**에 의해 좌우된다.

---

### **핵심 질문**

- AI Agent에서 LLM의 역할은 무엇인가?
    
- AI Agent는 RAG와 어떻게 결합되는가?
    
- “LLM이 자율적으로 행동한다”는 표현이 왜 부정확한가?
    

---

### **시험 문제(예시)**

- AI Agent의 구조를 설명하고, LLM의 역할을 명확히 하라.
    
- LLM 기반 Agent가 단순 챗봇과 다른 점을 설명하라.
    

---

## **4장: MCP (Model Context Protocol)**

  

### **핵심 내용 (2문단)**

  

MCP는 LLM이 다양한 외부 도구와 **일관된 방식으로 상호작용하기 위한 컨텍스트 인터페이스 개념**이다. 이는 단순한 API 호출 규약이 아니라, **모델이 이해할 수 있는 형태로 컨텍스트를 구조화하는 방식**을 의미한다.

  

이 장의 핵심은 “컨텍스트도 설계 대상”이라는 인식이다. 어떤 정보를, 어떤 형식으로, 어떤 순서로 제공하느냐에 따라 LLM의 판단이 크게 달라진다. MCP는 이러한 문제를 **시스템 레벨에서 표준화하려는 시도**로 이해할 수 있다.

---

### **핵심 질문**

- MCP는 왜 Agent 구조에서 중요한가?
    
- 컨텍스트 설계가 모델 성능만큼 중요한 이유는 무엇인가?
    
- MCP는 모델 성능을 높이는 기술인가, 시스템 안정성을 높이는 기술인가?
    

---

### **시험 문제(예시)**

- MCP의 개념과 필요성을 설명하라.
    
- AI Agent에서 컨텍스트 관리가 중요한 이유를 설명하라.
    

---

## **5장: Modern AI Trends의 공통 메시지**

  

### **핵심 내용 (2문단)**

  

이 자료에서 소개된 RAG, AI Agent, MCP는 서로 다른 기술처럼 보이지만, 공통적으로 **“LLM 단독 사용의 한계를 인정한다”**는 전제에서 출발한다. 더 큰 모델이 아니라, **더 잘 설계된 시스템**이 필요하다는 메시지다.

  

즉, 현대 AI 트렌드는 “모델 경쟁”에서 “아키텍처 경쟁”으로 이동하고 있으며, 이는 데이터베이스·시스템 관점의 사고가 중요한 이유이기도 하다. 이 과목이 고급데이터베이스에서 이 주제를 다루는 이유가 바로 여기에 있다.

---

### **핵심 질문**

- 왜 최신 AI 트렌드는 모델보다 시스템을 강조하는가?
    
- RAG, Agent, MCP는 어떤 공통 문제를 해결하려는가?
    
- 이 흐름에서 데이터베이스의 역할은 무엇인가?
    

---

### **시험 문제(예시)**

- Modern AI Trends의 공통된 특징을 설명하라.
    
- LLM 중심 사고의 한계를 시스템 관점에서 설명하라.
    

---

## **13번 자료를 관통하는 한 줄 핵심**

  

> **이 자료는 “LLM으로 무엇을 할 수 있는가”가 아니라**

> **“LLM을 믿지 않고도 시스템을 설계하는 방법”을 묻는다.**

---

이제 남은 흐름은 매우 깔끔합니다.

- **14번 자료: Practical Issues (Actual Problems in Real World)**
    
    → 지금까지 배운 모든 개념이 **현실에서 왜 그대로 안 되는지**를 다루는 장
    

  

다음으로 **14번 자료로 이어갈까요?**