---
created: 2025-09-15
Question: "'출력이 포화(saturation)'된다는게 무슨 의미야?"
---
좋은 질문이에요 👍 딥러닝에서 **“출력이 포화(saturation)된다”**는 건, **입력 값이 일정 범위를 벗어나면 출력이 거의 변하지 않는 구간에 들어간다**는 뜻이에요.

  

예를 들어:

- **Sigmoid** 함수: 입력이 아주 크면 → 출력은 1에 가까워짐, 입력이 아주 작으면 → 출력은 0에 가까워짐. 이 두 영역에서는 기울기(gradient)가 거의 0이 돼요.
    
- **Tanh** 함수: 입력이 크면 → 출력은 1, 입력이 작으면 → 출력은 -1 근처에서 멈춰버림. 역시 기울기가 0에 가까워짐.
    

  

즉, 입력이 커지거나 작아질수록 **출력이 “평평한 구간”에 갇히는 현상**이 바로 포화(saturation)입니다.

  

👉 이렇게 되면 역전파(Backpropagation)할 때 gradient가 0에 가까워져서, **학습이 느려지거나 거의 멈춰버리는 문제(gradient vanishing)**가 발생합니다.

---

한 줄 요약:

출력이 포화된다는 건 **출력 값이 더 이상 변하지 않고 고정된 상한·하한에 수렴해, 기울기가 0이 되는 상태**를 말해요.

  

혹시 제가 이걸 **Sigmoid, Tanh 곡선 그림 위에 gradient까지 표시해서** 시각적으로 설명해드릴까요?