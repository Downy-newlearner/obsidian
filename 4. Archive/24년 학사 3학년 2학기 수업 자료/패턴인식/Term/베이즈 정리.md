---
created: 2024-11-29
tags: 
aliases:
  - baysian rule
reference:
---
## 1. 사건에 대한 사전 정보
예를 들어, 질병에 걸린 사람들의 확률을 알고 싶을 때, 이 질병의 발생률(예: 1%의 사람만 이 질병에 걸린다)이 prior probability이다. 이 확률은 데이터나 새로운 정보 없이도 알고 있는 정보에 기반한 확률이다.

## 2.  베이즈 정리
베이즈 정리는 주어진 사전 확률(prior probability)로 후행 확률(posterior probability)를 계산한다.

$P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)}$

여기서:

- $P(θ)$는 prior probability이다.
- $P(D | θ)$는 주어진 파라미터 θ에서 데이터 D가 발생할 확률이다.
- $P(θ | D)$는 posterior probability로, 데이터 D를 고려한 후의 확률이다.
- $P(D)$는 데이터 D가 발생할 전체 확률이다.

### 요약:

- **사전에 알고 있는 정보**:
    - $P(\theta)$ (Prior Probability): 모델 파라미터 $\theta$에 대한 사전 정보
    - $P(D | \theta)$ (Likelihood): 주어진 $\theta$에서 데이터 $D$가 발생할 확률 (사전 지식)
- **베이즈 정리 후에 알게 될 정보**:
    - $P(\theta | D)$ (Posterior Probability): 새로운 데이터 $D$를 반영하여 갱신된 모델 파라미터 $\theta$에 대한 확률
    - $P(D)$ (Evidence): 데이터 $D$가 발생할 전체 확률 (베이즈 정리의 계산에서 필요한 값)

## 3. 예시:

- **질병 A**에 걸린 사람들의 확률을 추정하려고 합니다.
- 질병 A에 걸릴 확률이 **5%** 라고 합니다.
- 어떤 사람이 **질병 A의 증상**을 보였다는 증거가 주어졌을 때, 이 사람이 실제로 질병 A에 걸렸을 확률을 구하는 것이 목표입니다.

---

### 1. **P(θ) - Prior Probability (사전 확률)**

- **사전에 알고 있는 정보**:
    - θ는 질병 A에 걸린 확률입니다.
    - 예를 들어, 우리가 질병 A에 걸릴 확률이 **5%**라고 알고 있다면, 이것이 바로 **prior probability**입니다. 이는 데이터나 증거와 관계없이 기존에 알고 있는 정보입니다.
    - **Prior probability**: $P(\theta) = 0.05 \quad \text{(질병 A에 걸릴 확률)}$

---

### 2. **P(D∣θ) - Likelihood (우도)**

- **사전에 알고 있는 정보**:
    - **D**는 "이 사람이 질병 A의 증상"을 보였다는 정보입니다.
    - **P(D∣θ)** 는 **질병 A에 걸렸을 때** 증상이 나타날 확률입니다. 예를 들어, 질병 A에 걸린 사람이 증상을 보일 확률이 **80%** 라면, **likelihood**는 0.8입니다.
    - **Likelihood**: $P(D | \theta) = 0.8 \quad \text{(질병 A에 걸린 사람이 증상을 보일 확률)}$

---

### 3. **P(θ∣D) - Posterior Probability (후행 확률)**

- **베이즈 정리 후에 알게 될 정보**:
    - 이제 우리가 **증거 D**(즉, "이 사람이 질병 A의 증상"을 보였다는 데이터)를 고려하여, 질병 A에 걸릴 확률을 **posterior probability**로 갱신합니다.
    - P(θ∣D)는 "이 사람이 질병 A에 걸렸을 확률"을 **증상 D를 고려하여 계산**한 값입니다.
    - **Posterior probability**는 베이즈 정리로 계산됩니다: $P(\theta | D) = \frac{P(D | \theta) P(\theta)}{P(D)}$
    - 이 값은 **증상 D**가 주어진 상황에서 **질병 A에 걸릴 확률**을 반영한 후행 확률입니다.

---

### 4. **P(D) - Evidence (증거)**

- **베이즈 정리에서 알게 될 정보**:
    - **P(D)** 는 데이터 D가 발생할 **전체 확률**을 나타냅니다. 이는 "이 사람이 질병 A의 증상"을 보일 확률입니다. 하지만 이 값은 우리가 직접적으로 알 수 없고, **베이즈 정리**에서 계산되는 값입니다.
    - **P(D)** 는 모든 가능한 **질병 A에 걸린 사람**과 **걸리지 않은 사람**에 대해 증상이 나타날 확률을 종합한 것입니다.
    - 이 값은 **normalization constant** 역할을 하며, 후행 확률을 정규화하는 데 사용됩니다. 계산은 다음과 같습니다: $P(D) = P(D | \theta) P(\theta) + P(D | \neg \theta) P(\neg \theta)$
    - 여기서 **$P(D | \neg \theta)$** 는 **질병 A에 걸리지 않은 사람**이 증상을 보일 확률이며, **$P(\neg \theta)$** 는 **질병 A에 걸리지 않은 확률**입니다.

---

### 요약:

- **사전에 알고 있는 정보**:
    - P(θ) (Prior Probability): 질병 A에 걸릴 확률 (예: 5%)
    - P(D∣θ) (Likelihood): 질병 A에 걸린 사람이 증상을 보일 확률 (예: 80%)
- **베이즈 정리 후에 알게 될 정보**:
    - P(θ∣D) (Posterior Probability): 질병 A에 걸릴 확률을 증상 D를 고려하여 갱신한 확률
    - P(D) (Evidence): 데이터 D가 발생할 전체 확률 (질병 A에 걸린 사람과 걸리지 않은 사람에 대해 증상 D가 나타날 확률의 합)

---

이 예시에서, 베이즈 정리를 사용하여 **prior probability**와 **likelihood**를 결합하고, 이를 통해 **posterior probability**를 계산하게 됩니다. **Evidence**는 그 계산에 필요한 값으로, 후행 확률을 정규화하는 역할을 합니다.