## 2.1 들어가는 글
의미 의미 기반 검색 트랜스포머 마켓 대처를 기반으로 무엇을 구축 할 수 있는지 배운다
AI 회사들을 제공하는 가장 다양하게 활용 가능한 솔루션 중 하나는 강력한 의료 흐름을 기반으로 텍스트 매직 텍스트인 배딩을 생성 하는 기능이다
텍스트 인 패딩 > 단어나 구문을 수치 백터로 표현
만약 두 구몬이 유사 하다면 그 구문들이 나타내는 벡터들은 유클리드 거리와 같은 측정 치러 볼 때 서로 가까워야 한다. 그 반대의 경우도 마찬가지다.
이 텍스트에서 백프로의 대응은 일종의 해시로 생각할 수 있다
단지 100 터는 다시 텍스트로 되돌릴 순 없지만 인코딩 된 상태에서 점수를 비교 할 수 있는 추가적인 이점을 가진 텍스트의 표현이다


## 2.2 작업

### 2.2.1 비대칭적 의미 기반 검색
- 의미 기반 검색 시스템
	- 사용자 쿼리의 의미와 맥락을 이해하고, 이를 검색 가능한 문서의 의미 및 맥락과 대조할 수 있다.
	- 정확한 키워드나 n-gram 일치에 의존하지 않고도 DB에서 관련된 결과를 찾아낼 수 있다.
	
- 비대칭적 의미 기반 검색에서 *비대칭*은 입력 쿼리의 의미 정보 - 검색 시스템이 검색해야하는 문서/정보 사이에 불균형이 있다는 사실을 의미한다.
- 사용자가 정확한 쿼리를 입력하지 않더라도 괜찮은 검색 결과를 얻을 수 있다.

- 의미 기반 검색의 단점
	- ![[Pasted image 20250123221545.png]]

## 2.3 솔루션 개요
1. 문서 저장
	- 텍스트를 임베딩하여 DB에 저장
	- ![[Pasted image 20250123221729.png]]
2. 문서 검색
	- 사용자의 쿼리를 임베딩하여 이전에 저장된 문서와 비교한다.
	- 필요한 경우 재순위화한다.
	- 사용자에게 결과 반환
	- ![[Pasted image 20250123221827.png]]

## 2.4 구성 요소

### 2.4.1 텍스트 임베더
- 의미 기반 검색 시스템의 핵심이다.
- 텍스트 문서나 단어 또는 구문 -> 벡터로 반환
- 이 벡터는 구문의 맥락적 의미를 포착해야한다.

- 오픈소스 또는 클로즈드 소스 임베딩 제품이 존재한다.

**무엇이 텍스트를 '유사'하게 만드는가**
![[Pasted image 20250123222403.png|500]]
- 텍스트 조각끼리 서로 '유사'한지 여부를 파악하기 위해 *코사인 유사도*를 사용한다.
	- 두 벡터 사이의 *각도*가 중요하고 벡터의 크기는 중요하지 않다.
		- 같은 방향: 1
		- 수직: 0
		- 반대 방향: -1

- OpenAI의 임베딩 제품은 벡터의 크기를 기본적으로 1로 정규화하므로 다음 이점이 있다.
	- 코사인 유사도의 결과 = 내적의 결과
	- 코사인 유사도와 유클리드 거리는 동일한 순위의 결과를 가져온다.
### 2.4.2 문서 청킹
*큰 문서를 단일 벡터로 임베딩하는 것은 실용적이지 않다.* > **문서 청킹**을 사용하여 해결

- 문서 청킹은 큰 문서를 임베딩하기 위해 더 작고 관리 가능한 청크로 나누는 것을 의미한다.

#### 최대 토큰 범위 분할
- 주어진 최대 크기의 청크로 문서를 나눈다.
- 그런데 이 과정에서 문맥이 잘려버릴 수 있으므로 청크 끝 부분은 앞뒤 청크와 각각 공유하여 보관한다.

- 단점
	- 중복을 사용하므로 청크의 수가 증가한다.
	- 또한 문서의 자연스러운 구조를 고려하지 않아. 정보가 청크 사이에 나누어질 수 있거나 중복된 정보가 있는 청크가 발생할 수 있다.
	- 이러한 현상은 검색 시스템을 혼란스럽게 할 수 있다.

#### 맞춤형 구분 기호 찾기
- 청크를 나누는 기준으로 공백 등을 식별해서 구분기호를 찾아 구분한다.
	- 가장 흔한 구분기호는 연속된 두개의 개행 문자이다.

- ![[Pasted image 20250124151750.png]]

- 청크를 구성하는 방식에 있어서 *머신 러닝*을 활용할 수도 있다.

#### 클러스터링을 사용하여 의미 기반 문서 생성하기
- 의미적으로 유사한 작은 정보 청크를 결합하여 새로운 문서를 생성한다.(클러스터링)
- 단점
	- 내용의 일부가 주변 텍스트와 맥락에서 벗어나는 단점이 있다.

#### 청크로 나누지 않고 전체 문서 사용하기
- 별로다

![[Pasted image 20250124153548.png|600]]

### 2.4.3 벡터 데이터베이스
- LLM에 의해 생성된 임베딩을 저장한다.
- 최근접 이웃 탐색을 효율적으로 수행할 수 있다.

### 2.4.4 파인콘
- 무료 벡터 데이터베이스이다.

### 2.4.5 오픈 소스 대안
- 다른 벡터 DB의 선택지가 있다.

### 2.4.6 검색 결과 재순위화
- 벡터 DB에서 유사도 비교로 결과 후보들을 검색한 후, 사용자에게 가장 관련된 결과를 제시할 수 있도록 다시 지정하는 것이 필요하다.
- 결과 재순위화(re-ranking)하는 한 가지 방법은 크로스 인코더(Cross-Encoder)를 사용하는 것이다.

![[Pasted image 20250124155857.png|500]]

- 검색 결과를 재순위화하기 위한 또 다른 옵션은 [[BM25]]와 같은 전통적인 모델을 사용하는 것이다.

### 2.4.7 API

#### FastAPI
- 빠르게 파이썬으로 API를 구축하기 위한 웹 프레임워크이다.
	- Pydantic 데이터 검증 라이브러리를 사용하여

## 2.5 통합

### 2.5.1 성능

## 2.6 클로즈드 소스 구성 요소의 비용

## 2.7 마치며