![[Ch5_Clustering_page-0001.jpg]]
그룹을 어떻게 지을 것인가? -> 클러스터링



## Hierarchical Clustering(Agglomerative Clustering)
![[Ch5_Clustering_page-0002.jpg]]



![[Ch5_Clustering_page-0003.jpg]]

## Single-Linkage Algorithm
두 집안에서 가장 친한 사람들의 거리를 두 집안의 거리라고 함
![[Ch5_Clustering_page-0005.jpg]]

![[Ch5_Clustering_page-0006.jpg]]

![[Ch5_Clustering_page-0007.jpg]]

![[Ch5_Clustering_page-0008.jpg]]

![[Ch5_Clustering_page-0009.jpg]]

## Complete-Linkage Algorithm
두 집안에서 가장 안 친한 사람들의 거리를 두 집안의 거리라고 함
![[Ch5_Clustering_page-0010.jpg]]

![[Ch5_Clustering_page-0011.jpg]]

![[Ch5_Clustering_page-0012.jpg]]

![[Ch5_Clustering_page-0013.jpg]]



## Average-Linkage Algorithm
두 집안의 친한 정도를 평균내어 그것을 두 집안의 거리로 함
![[Ch5_Clustering_page-0014.jpg]]

![[Ch5_Clustering_page-0015.jpg]]

![[Ch5_Clustering_page-0016.jpg]]

![[Ch5_Clustering_page-0017.jpg]]



## Ward's Method
두 집단을 묶었을 때 그 묶음의 분산을 계산해서, 그 분산이 최대한 작도록 클러스터링 함.
![[Ch5_Clustering_page-0018.jpg]]
클러스터 구하고 mean을 구함 
mean으로부터 variance를 구함
variance가 작아지도록 클러스터링을 하는 방식이다.

![[Ch5_Clustering_page-0019.jpg]]

![[Ch5_Clustering_page-0020.jpg]]

![[Ch5_Clustering_page-0021.jpg]]

![[Ch5_Clustering_page-0022.jpg]]
계산량이 상당히 많다는 것을 알 수 있다.
대신 클러스터링 결과는 준수하다.

![[Ch5_Clustering_page-0023.jpg]]

## Partitional Clustering
![[Ch5_Clustering_page-0024.jpg]]
k개의 클러스터 값(시드)을 정하고 시작한다.
	데이터 중 k개를 고를 수도 있고
	그냥 랜덤으로 k개의 깃발을 꽂을 수도 있다.
첫 샘플이 시드 중 어디에 가장 가까운지 계산 후 그 곳으로 포함시킨다.
이후 시드의 위치를 업데이트한다.

![[Ch5_Clustering_page-0025.jpg]]

![[Ch5_Clustering_page-0026.jpg]]

![[Ch5_Clustering_page-0027.jpg]]

## k-means Algorithm
![[Ch5_Clustering_page-0028.jpg]]
샘플이 하나 들어갈 때 마다 centroid(샘플의 평균 위치)가 업데이트 된다.
훨씬 빠르게 클러스터링이 가능하다.

![[Ch5_Clustering_page-0029.jpg]]

![[Ch5_Clustering_page-0030.jpg]]

![[Ch5_Clustering_page-0031.jpg]]

![[Ch5_Clustering_page-0032.jpg]]


## 변형된 k means algorithm
기존은 2번만 centroid를 recompute
변현된 알고리즘은 mean의 변화가 없을 때까지 centroid를 reconpute
![[Ch5_Clustering_page-0033.jpg]]
기존의 kmeans는 두 번만 계산
변형된 kmeans는 끝까지 계산한다는 차이가 있다.