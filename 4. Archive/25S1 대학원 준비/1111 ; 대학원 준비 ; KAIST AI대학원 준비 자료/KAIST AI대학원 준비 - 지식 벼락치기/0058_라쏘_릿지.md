# 라쏘 릿지

## 형식적 답

리지 - L2  변수선택 불가, 변수 상관관계 높은 상황 좋은 예측, 크기큰 변수를 우선 줄임
라쏘 _ L1 변수선택 가능, 변수상관관계 높은 상황에서 릿지보다는 떨어짐,

## AI 답변

Ridge 회귀(Ridge Regression)와 Lasso 회귀(Lasso Regression)는 모두 선형 회귀 모델에 정규화(regularization) 기법을 적용한 방법입니다. 정규화는 모델의 복잡도를 제한하여 과적합(overfitting) 문제를 해결하고 일반화 성능을 향상시키는 데 도움이 됩니다.

1. Ridge 회귀(Ridge Regression):
Ridge 회귀는 비용 함수(cost function)에 L2 정규화 항(L2 regularization term)을 추가합니다. L2 정규화는 모든 가중치(weight)의 제곱 합을 최소화하여 가중치의 크기를 작게 만듭니다. 이를 통해 다중공선성(multicollinearity) 문제를 완화하고, 모델의 복잡도를 제한할 수 있습니다.

비용 함수: J(θ) = (1/2m) * Σ(y_hat - y)^2 + α * Σ(θ_j)^2

여기서 α는 정규화 강도를 조절하는 하이퍼파라미터(hyperparameter)입니다.

2. Lasso 회귀(Lasso Regression):
Lasso 회귀는 비용 함수에 L1 정규화 항(L1 regularization term)을 추가합니다. L1 정규화는 모든 가중치의 절대값 합을 최소화하여, 일부 가중치를 정확히 0으로 만듭니다. 이를 통해 특징 선택(feature selection)이 가능하며, 모델의 해석력을 높일 수 있습니다.

비용 함수: J(θ) = (1/2m) * Σ(y_hat - y)^2 + α * Σ|θ_j|

여기서 α 또한 정규화 강도를 조절하는 하이퍼파라미터입니다.

Ridge 회귀와 Lasso 회귀의 주요 차이점은 다음과 같습니다:

- Ridge 회귀는 가중치를 작게 만들지만, 정확히 0으로 만들지는 않습니다. Lasso 회귀는 일부 가중치를 0으로 만들어 특징 선택을 수행합니다.
- Ridge 회귀는 다중공선성 문제를 완화하는 데 효과적입니다. Lasso 회귀는 특징 선택에 유용합니다.
- Ridge 회귀는 연속적인 가중치 값을 가지므로, 해석이 어려울 수 있습니다. Lasso 회귀는 0이 아닌 가중치만 남기므로, 해석이 용이할 수 있습니다.

두 방법 모두 정규화 강도를 조절하는 하이퍼파라미터 α를 적절히 선택하는 것이 중요합니다. 이를 통해 모델의 복잡도와 일반화 성능을 조절할 수 있습니다.

