# 1. 오버피팅의 정의
- 근데 오버피팅이 일어났는지 어떻게 판단하지?
2. 오버피팅의 원인
3. 오버피팅을 완화할 수 있는 방법들을 나열해보시오
4. 독립일 때 E[XY]=E[X]E[Y] 증명하시오
5. 독립과 uncorrelated 와의 차이?
6. PCA로 차원축소 하는 과정을 설명하시오

## 정답 링크

https://www.youtube.com/watch?v=wPbvzMGkNPg&list=PL_iJu012NOxdt7VSZK0sE2YvltT7NOlHH&index=13

## AI 답변

1. 오버피팅(Overfitting)의 정의
오버피팅은 기계학습 모델이 훈련 데이터에 지나치게 최적화되어 새로운 데이터에 대한 일반화 능력이 낮아지는 현상을 말합니다. 모델이 훈련 데이터의 특성이나 잡음까지도 학습하여 과도하게 복잡해지면서 발생합니다.

- 오버피팅이 일어났는지 판단하는 방법
1) 훈련 데이터와 검증 데이터의 성능 차이가 크면 오버피팅 의심
2) 학습 곡선(learning curve) 관찰: 훈련 데이터 성능은 높고 검증 데이터 성능은 일정 수준 이상 증가하지 않으면 오버피팅 의심

2. 오버피팅의 원인
- 모델의 복잡도가 너무 높음
- 훈련 데이터의 크기가 작음
- 데이터의 노이즈가 많음
- 정규화(regularization)가 부족함

3. 오버피팅을 완화할 수 있는 방법
- 더 많은 훈련 데이터 확보
- 데이터 증강(Data Augmentation)
- 특징 선택(Feature Selection) 또는 차원 축소(Dimensionality Reduction)
- 정규화(Regularization) 기법 적용 (L1, L2, Dropout 등)
- 교차 검증(Cross-Validation)을 통한 하이퍼파라미터 튜닝
- 앙상블 학습(Ensemble Learning) 기법 사용

4. 독립일 때 E[XY] = E[X]E[Y] 증명
확률변수 X와 Y가 독립이면, 결합확률밀도함수 f(x, y) = f(x)f(y)가 성립합니다.
E[XY] = ∫∫xyf(x, y)dxdy (독립이므로 f(x, y) = f(x)f(y))
       = ∫x(∫yf(y)dy)f(x)dx
       = ∫xE[Y]f(x)dx
       = E[Y]∫xf(x)dx
       = E[Y]E[X]

5. 독립(Independent)과 uncorrelated의 차이
- 독립(Independent): 두 확률변수의 결합확률밀도함수가 개별 확률밀도함수의 곱으로 나타낼 수 있을 때 독립이라고 합니다. 즉, 한 변수의 값이 다른 변수의 값에 전혀 영향을 미치지 않습니다.
- Uncorrelated: 두 확률변수의 공분산이 0일 때 uncorrelated라고 합니다. 이는 선형적인 관계가 없음을 의미합니다. 하지만 비선형 관계가 존재할 수 있습니다.

독립은 uncorrelated보다 강한 조건입니다. 두 확률변수가 독립이면 uncorrelated이지만, uncorrelated라고 해서 반드시 독립인 것은 아닙니다.

6. PCA(Principal Component Analysis)로 차원 축소하는 과정
1) 데이터 전처리: 데이터 정규화, 중심화 등
2) 공분산 행렬(covariance matrix) 계산
3) 공분산 행렬의 고유값(eigenvalues)과 고유벡터(eigenvectors) 계산
4) 고유값을 내림차순으로 정렬하고, 상위 k개의 고유벡터를 선택(k는 목표 차원 수)
5) 원본 데이터에 선택된 고유벡터를 투영(projection)하여 새로운 k차원 데이터 생성

이 과정을 통해 데이터의 차원을 축소하되, 가능한 한 많은 분산(variability)을 보존할 수 있습니다.

