# 🧐 Cross Validation이란?

## 정답 링크

https://www.youtube.com/watch?v=k4mZS-YWpdk

## 형식적 답

**Cross Validation(교차 검증)**은 모델의 일반화 성능을 평가하기 위해 데이터를 여러 번 나누어 훈련과 검증을 반복하는 방법입니다. 이 방법은 주어진 데이터를 효율적으로 사용하여 모델이 새로운 데이터에 대해 얼마나 잘 작동하는지 평가하는 데 중요한 역할을 합니다. 특히, 데이터셋이 작거나, 특정 데이터 분할에 따라 모델 성능이 크게 달라질 수 있는 경우에 유용합니다.

1. 왜 Cross Validation을 사용하는가?
모델의 성능을 평가할 때, 단순히 Train-Validation-Test로 데이터를 나누어 검증하는 방법은 데이터의 분할 방법에 따라 성능이 달라질 수 있다는 단점이 있습니다. Cross Validation은 이러한 문제를 줄이기 위해 데이터를 여러 번 나누어 검증을 반복하여 모델의 신뢰할 수 있는 성능 평가를 제공합니다.

일관된 평가: 데이터의 특정 분할에 의존하지 않고, 모델의 일반화 성능을 더 일관되게 평가할 수 있습니다.
데이터 효율성: 전체 데이터를 더 효율적으로 사용하여, 특히 데이터가 적을 때 모델 성능을 더 정확하게 평가할 수 있습니다.
2. K-Fold Cross Validation
K-Fold Cross Validation은 가장 널리 사용되는 교차 검증 방법입니다. 데이터셋을 K개의 폴드로 나누고, 각 폴드가 한 번씩 검증 세트로 사용되며 나머지 폴드가 훈련 세트로 사용됩니다. 이 과정은 K번 반복되며, K번의 반복으로 얻은 성능 지표의 평균이 최종 성능으로 간주됩니다.

단계:

데이터를 K개의 폴드로 나눕니다.
각 폴드를 검증 세트로 사용하고, 나머지 폴드를 훈련 세트로 사용하여 모델을 학습합니다.
각 폴드에 대해 모델 성능을 평가합니다.
K번의 성능 평가 결과를 평균내어 최종 성능을 도출합니다.
예시:


데이터셋의 각 데이터를 검증 세트로 사용하고, 나머지 데이터를 훈련 세트로 사용하여 모델을 학습합니다.
모든 데이터에 대해 이 과정을 반복하여 모델 성능을 평가합니다.
특징:

4. Stratified K-Fold Cross Validation
Stratified K-Fold Cross Validation은 K-Fold Cross Validation의 한 변형으로, 각 폴드가 원래 데이터셋의 클래스 비율을 유지하도록 하는 방법입니다. 이는 특히 불균형 데이터셋에서 각 폴드가 원래의 클래스 비율을 반영하게 하여, 더 신뢰할 수 있는 성능 평가를 가능하게 합니다.

특징:
불균형한 클래스 분포를 가진 데이터셋에서 유용합니다.
각 폴드가 클래스의 비율을 유지하므로, 특정 클래스에 대해 과적합하거나 과소평가되는 문제를 줄일 수 있습니다.
5. Cross Validation의 장점
일관된 모델 평가: 특정 데이터 분할에 의존하지 않고, 모델의 성능을 일관되게 평가할 수 있습니다.
과적합 방지: 여러 폴드에 걸쳐 성능을 평가함으로써, 모델이 특정 데이터에 과적합되는 것을 방지할 수 있습니다.
모델 선택: 여러 모델을 비교할 때 Cross Validation을 사용하여, 데이터 분할에 의존하지 않는 공정한 성능 비교를 할 수 있습니다.
6. Cross Validation의 단점
계산 비용: 특히 LOOCV와 같은 방법은 계산 비용이 매우 크며, 대규모 데이터셋에서는 실행 시간이 길어질 수 있습니다.
복잡성: K-Fold Cross Validation을 잘못 사용할 경우, 모델 성능 평가에 혼란을 줄 수 있습니다. 또한, 교차 검증의 결과를 해석하는 데 주의가 필요합니다.
결론적으로:

**Cross Validation(교차 검증)**은 모델의 일반화 성능을 더 정확하게 평가하기 위해 데이터를 여러 번 나누어 검증하는 방법입니다.
K-Fold Cross Validation은 가장 일반적인 방법으로, 데이터를 K개의 폴드로 나누고, 각 폴드를 검증에 사용하며 성능을 평가합니다.
Leave-One-Out Cross Validation은 데이터셋이 작을 때 유용하지만, 계산 비용이 큽니다.
Stratified K-Fold Cross Validation은 불균형한 데이터셋에서 클래스 비율을 유지하여 더 신뢰할 수 있는 평가를 제공합니다.

## 내가 이해한 정답

편향된 벨리데이션 데이터가 좋지 않으니, 데이터를 쪼개서 학습과 검증을 하자. 그리고 평균 로스값을 구하고 이런 평균 로스값이 가장 적은 하이퍼파라미터 셋을 고르는데도 사용가능,

## AI 답변

Cross Validation(교차 검증)은 머신러닝 모델의 일반화 성능을 평가하고 과적합(overfitting)을 방지하기 위해 사용되는 기법입니다. 주요 개념은 다음과 같습니다:

1. 데이터 분할: 전체 데이터 세트를 훈련 데이터와 검증 데이터로 나눕니다. 일반적으로 80%는 훈련 데이터로, 20%는 검증 데이터로 할당합니다.

2. 반복 실행: 데이터 세트를 k개의 폴드(fold)로 나눈 뒤, k번의 반복 실행을 진행합니다. 각 반복에서 하나의 폴드를 검증 데이터로, 나머지 폴드들을 훈련 데이터로 사용합니다.

3. 평가 지표 계산: 각 반복에서 훈련된 모델을 검증 데이터로 평가하여 성능 지표(정확도, F1 점수 등)를 계산합니다.

4. 최종 성능 평균화: 모든 반복에서 계산된 성능 지표의 평균을 내어 최종 모델 성능을 평가합니다.

Cross Validation을 사용하면 전체 데이터를 효율적으로 활용하고, 모델의 일반화 성능을 보다 신뢰성 있게 추정할 수 있습니다. 또한 과적합 문제를 완화하고 모델의 성능을 개선할 수 있습니다.

