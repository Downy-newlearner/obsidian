# 🧐 Gradient Descent란 무엇인가?

## 정답 링크

https://velog.io/@jhlim2993/Deep-Learning-%EA%B8%B0%EC%B4%88-%EB%82%B4%EC%9A%A9-%EC%A0%95%EB%A6%AC

## 형식적 답

Gradient Descent의 개념:
Gradient Descent는 모델의 손실 함수의 기울기(gradient)를 계산하고, 이 기울기의 반대 방향으로 파라미터를 조정해 나가는 과정을 반복하여 손실을 최소화하는 방법입니다. 기울기는 함수의 증가 또는 감소 방향을 나타내므로, 기울기의 반대 방향으로 이동하면 손실이 줄어들게 됩니다.

## AI 답변

Gradient Descent(경사하강법)은 기계학습 모델을 최적화하는 데 널리 사용되는 알고리즘입니다. 이 알고리즘은 모델의 성능을 측정하는 손실 함수(loss function)를 최소화하는 모델 매개변수(parameter)의 값을 찾는 것을 목표로 합니다.

구체적으로 설명하면 다음과 같습니다:

1. 모델의 초기 매개변수 값을 임의로 설정합니다.

2. 현재 매개변수에 대한 손실 함수 값을 계산합니다.

3. 손실 함수를 매개변수에 대해 편미분하여 그래디언트(gradient)를 구합니다. 그래디언트는 손실 함수가 가장 작아지는 방향을 가리킵니다.

4. 학습률(learning rate)에 그래디언트를 곱한 값만큼 현재 매개변수 값을 조정합니다.

5. 2~4 과정을 반복하면서 점차 최적의 매개변수 값에 수렴하게 됩니다.

이 과정에서 학습률은 매개변수를 조정하는 정도를 결정합니다. 학습률이 너무 작으면 수렴 속도가 느리고, 너무 크면 발산할 수 있습니다.

Gradient Descent는 간단하면서도 강력한 알고리즘이지만, 지역 최소값(local minimum)에 수렴할 수 있다는 단점이 있습니다. 이를 극복하기 위해 다양한 변형 기법들이 연구되고 있습니다.

