
## LLM 시대의 시작

모델 크기, 데이터량, 성능의 관계 정립으로 LLM 트랜드를 촉발
GPT-3이 어떻게 LLM 시대의 중심이 되었는지 확인해야함.

- 흐름
	- "Scaling Laws for Neural Language Models" 논문에서는 스케일링 법칙을 제안하고, 모델의 크기, 학습 데이터의 양, 컴퓨팅 비용이 증가할 때 성능이 향상될 수 있다고 설명한다.
	- GPT-3는 이를 충실히 따르는 사례로, 그 결과로 높은 성능을 보였다.
	- 이것이 방대한 데이터와 많은 매개변수를 가진 LLM의 시대를 열었다.

GPT-3가 LLM 시대의 중심이 되었다고 평가받는 근거는 다음과 같습니다:

1. **매개변수의 규모:** GPT-3은 1750억 개의 매개변수를 보유하며, 이는 당시 다른 모델들에 비해 압도적으로 큰 규모였습니다.
2. **다양한 태스크 수행 능력:** GPT-3은 추가적인 미세 조정 없이도 다양한 태스크(예: 번역, 질문 응답, 글쓰기 등)를 수행할 수 있는 능력을 보여주었습니다.
3. **범용성:** 다른 기존의 모델들과 달리 특정 태스크에 구애받지 않고, 광범위한 어플리케이션 영역에서 활용될 수 있었습니다.
4. **자연어 처리(NLP) 발전 촉진:** GPT-3의 등장으로 인해 NLP 분야에서 대규모 언어 모델의 중요성이 부각되었으며, 이는 이후 연구 및 상용 서비스에서 큰 영향을 미쳤습니다.

GPT-3의 논문: "**Language Models are Few-Shot Learners**"

### 검증해야하는 내용
1. "Scaling Laws for Neural Language Models"에서 언급한 내용들을 나열
2. 이 논문이 전달하고자 하는 핵심 파악
3. GPT-3이 위 4가지 기여를 한 것이 맞는지 "**Language Models are Few-Shot Learners**" 논문 확인


## 멀티모달 학습의 시작

내 첫 질문들
1. 멀티모달의 원리는 무엇인가?
2. CLIP은 어떻게 작동하는가?
3. Flamingo는 CLIP과 다른 역할을 하는 것인가? 아니라면 CLIP의 어떤 한계점을 개선했는가?
4. 마찬가지로 Gato는 이전 모델들의 어떤 한계점을 개선했는가?
5. Gato에서 언급하는 '범용 멀티모달 모델의 가능성'이란 무엇인가?
6. Gemini는 어떻게 처음부터 멀티모달로 설계됐는가?
7. Gemini와 Gato는 어떻게 다른가?


아래는 멀티모달 학습의 주요 원리 및 관련 논문 4편에 대한 답변입니다. 순차적으로 읽어도 되고, 각 질문별로 따로 읽어도 괜찮습니다.

---

### 1. 멀티모달의 원리는 무엇인가?
멀티모달 학습은 서로 다른 형태의 데이터를 하나의 모델에서 통합하여 처리하는 것을 의미합니다. 보통 시각(이미지), 언어(텍스트), 청각(음성) 등의 modality가 함께 사용됩니다.
이를 위해 다음이 중요합니다:
- 공통 표현 공간: 서로 다른 modality를 동일한 표현 공간에 매핑해야 합니다.
- 정렬: 예를 들어, 텍스트 "cat"과 고양이 이미지가 의미적으로 같은 것을 알아야 합니다.
- 합성: 두 modality 간의 정보를 통합해 새로운 결론을 내릴 수 있어야 합니다.

클립(Clip), 플라밍고(Flamingo), 제미니(Gemini) 같은 모델은 각각 다른 구조로 이를 실현합니다.

---

### 2. CLIP은 어떻게 작동하는가?
CLIP는 이미지와 텍스트를 동일한 임베딩 공간으로 매핑하여 이미지-텍스트 쌍의 의미적 유사도를 측정할 수 있는 모델입니다.

- 이미지 인코더: ==ResNet 또는 Vision Transformer 사용== -> 무슨 원리? 이미지를 임베딩하는 것인가?
- 텍스트 인코더: Transformer 기반
- 학습 목표: 대규모 인터넷 이미지와 텍스트 쌍을 사용해 대조 학습 수행
이렇게 학습된 CLIP은 텍스트 기반의 분류기처럼 동작하며, 다양한 이미지 분류 작업에 zero-shot으로 적용됩니다.

Q1. 이미지 인코더로 ResNet 또는 Vision Transformer를 사용한다고 하는데 이는 무슨 원리인가?  
A. ResNet은 이미지의 계층적 특징을 학습하도록 설계된 잔차 네트워크로, 이미지의 레이어별 학습을 통해 인식 성능을 향상합니다. Vision Transformer는 이미지를 패치 단위로 나누고, 각 패치를 토큰으로 처리하여 Transformer 구조에서 다루는 방식으로 이미지의 패턴을 학습합니다.

Q2. 대규모 인터넷 이미지와 텍스트 쌍을 데이터셋으로 사용하는 것 같은데, 이런 데이터는 어떻게 만드는 것인가?  
A. 이러한 데이터셋은 주로 웹 크롤링을 통해 다양한 이미지와 해당 텍스트 설명을 모은 뒤, 데이터 정제 및 필터링 과정을 거쳐 생성됩니다. 이미지와 설명의 유의미한 쌍을 형성하는 알고리즘적 과정도 포함됩니다.


---

### 3. Flamingo는 CLIP과 다른 역할을 하는가?
CLIP과는 다른 목적과 구조:
- CLIP: 이미지-텍스트 쌍의 유사도 계산(분류 중심)
- Flamingo: 이미지/비디오 + 텍스트를 입력받고, 자연어를 출력(생성 작업에 적합)

Flamingo는 Perceiver Resampler + Cross-Attention Layer를 사용하여 다양한 멀티모달 작업을 수행할 수 있습니다.

Q1. Perceiver Resampler가 무엇인가?
A. Perceiver Resampler는 입력 데이터를 더 작은 형태로 샘플링하여 처리하는 메커니즘으로, 다양한 입력 데이터를 효과적으로 요약하여 모델의 계산 부담을 줄입니다. 이는 특히 멀티모달 입력을 다룰 때 유용합니다.

Q2. Cross-Attention Layer가 무엇인가?
A. Cross-Attention Layer는 서로 다른 두 세트의 입력 간의 상호작용을 학습하는 레이어입니다. 한 세트의 정보가 다른 세트의 정보에 어떻게 관련되는지를 학습하여, 보다 풍부한 표현을 가능하게 합니다. 이는 멀티모달 모델에서 서로 다른 modality 간의 정보를 통합하는 데 사용됩니다.

---

### 4. Gato는 이전 모델들의 한계점을 어떻게 개선했는가?
Gato는 범용 멀티모달 에이전트를 지향합니다:
- 특정 task나 modality에 최적화된 기존 모델과 다르게, Gato는 다양한 입력을 하나의 시퀀스로 토큰화하여 처리합니다.
- 하나의 가중치 집합으로 604개의 다양한 작업을 수행할 수 있게 되었습니다.

Q1. 여기서 '시퀀스'가 뭐야?
A. '시퀀스'는 입력 데이터를 순차적으로 배열한 형태를 의미합니다. Gato 모델의 경우, 텍스트, 이미지, 행동 등의 다양한 입력 데이터를 모두 하나의 토큰 시퀀스로 변환하여 통합적으로 처리합니다. 이를 통해 여러 modality의 데이터를 단일 모델로 다룰 수 있게 됩니다.

---

### 5. Gato에서 '범용 멀티모달 모델의 가능성'은 무엇인가?

범용 멀티모달 모델은 하나의 모델이 다양한 작업과 입력 형태를 모두 처리할 수 있다는 개념입니다.
- 모든 modality를 하나의 토큰 시퀀스로 직렬화
- 다양한 작업을 하나의 transformer로 처리
이는 멀티태스킹 + 멀티모달 + few-shot 가능성을 동시에 제시합니다.

---

### 6. Gemini는 어떻게 처음부터 멀티모달로 설계됐는가?

Gemini 1.5는 멀티모달 학습을 위한 데이터와 구조로 설계된 LLM입니다.
- 데이터: 웹 문서, 코드, 이미지, 오디오, 비디오 등 포함
- 구조: 10M tokens의 긴 context 처리 가능
- 아키텍처: Sparse MoE 기반

즉, Gemini는 복합 modality를 동시 처리하고 상호작용하도록 설계된 모델입니다.

Q1. Sparse MoE가 뭐야?
A. Sparse MoE (Mixture of Experts)는 모델의 여러 전문가 네트워크 중 일부만 활성화하여 계산을 수행하는 방법입니다. 이는 필요한 계산량을 줄이면서도 모델의 표현력을 향상시킵니다. 즉, 각 입력에 대해 가장 적합한 전문가들만 선택적으로 사용되어 효율성을 높입니다.

---

### 7. Gemini와 Gato는 어떻게 다른가?
| 항목    | Gato                                        | Gemini 1.5                                            |
| ----- | ------------------------------------------- | ----------------------------------------------------- |
| 목적    | 범용 멀티태스킹 에이전트                               | 고성능 멀티모달 LLM                                          |
| 입력 처리 | 모든 modality를 flat sequence로 직렬화             | modality interleaving + MoE architecture              |
| 맥락 길이 | 약 1,024 tokens                              | 최대 10 million tokens                                  |
| 학습 방식 | supervised learning + imitation learning 중심 | 대규모 pretrain + instruction tuning + preference tuning |
| 주요 응용 | 로봇 제어, 게임, VQA 등 실시간 제어                     | 코드베이스 QA, 비디오 이해 등                                    |
Gato는 "물리적 환경과 상호작용하는 일반 에이전트"로, Gemini는 "거대 멀티모달 context reasoning에 최적화된 모델"입니다.
이제 멀티모달에 대한 큰 흐름이 보일 것입니다. 필요할 경우 플라밍고와 제미니의 구조를 비교하거나 성능 그래프를 정리하는 것도 추천합니다.


## Flamingo
![[Pasted image 20250523045536.png]]


## PaLI
Pathways Languages and Image model
