## 확률적 경사 하강법(SGD)
![[Source/Untitled 16.png|Untitled 16.png]]
$\eta$﻿: 학습률
$\frac{\partial L}{\partial W}$﻿: 매개변수가 손실함수에 미치는 영향(매개변수에 대한 손실함수의 기울기) 또는 손실함수에 대한 가중치의 민감도
  
### SGD의 단점
![[Source/Untitled 1 10.png|Untitled 1 10.png]]
![[Source/Untitled 2 8.png|Untitled 2 8.png]]
- 이 예시를 SGD, 모멘텀 등에 적용해보자.
![[Source/Untitled 3 8.png|Untitled 3 8.png]]
비등방성 함수(방향에 따라 성질, 즉 여기서는 기울기가 달라지는 함수)에서는 탐색 경로가 비효율적이다.
이를 보완하는 기법인 모멘텀, AdaGrad, Adam 기법이 존재한다.
  
### 모멘텀
![[Source/Untitled 4 7.png|Untitled 4 7.png]]
![[Source/Untitled 5 7.png|Untitled 5 7.png]]
- x축의 힘은 아주 작지만 방향은 변하지 않아서 한 방향으로 일정하게 가속한다.
- 반면 y축의 힘은 크지만 위아래로 번갈아 받아서 상충하여 y축 방향의 속도는 안정적이지 않다.