### 000. Rf + XGB + LGB + Cat
---
```Python
rf_model = RandomForestClassifier(n_estimators = 167, max_depth = 25, min_samples_split = 2, min_samples_leaf = 1, class_weight={0: 1, 1: 20}, random_state=42)
xgb_model = XGBClassifier(n_estimators = 103, max_depth = 12, learning_rate = 0.2561812018689393, subsample = 0.5012981738869065, colsample_bytree = 0.7246170036518641, gamma = 0.0771247083256541, min_child_weight = 8, scale_pos_weight = 13, reg_alpha = 3.1573952824390017, reg_lambda = 6.092690349845058, random_state=42)
lgbm_model = LGBMClassifier(n_estimators = 275, max_depth =  19, learning_rate = 0.258046820755702, subsample =  0.9515313124634932, colsample_bytree = 0.847039277545349, num_leaves = 78, min_child_samples = 4, scale_pos_weight = 8, random_state=42)
cat_model = CatBoostClassifier(n_estimators = 296, max_depth = 11, learning_rate = 0.09718790309757624, l2_leaf_reg = 0.019329627715986786, random_state=42)
# 소프트 보팅 앙상블 모델 생성
voting_model = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('xgb', xgb_model),
    ('lgbm', lgbm_model),
    ('catboost', cat_model)
], voting='soft')
# 모델 학습
voting_model.fit(X_train_smote, y_train_smote)
# 검증 데이터에 대한 예측
y_val_pred = voting_model.predict(X_val)
# 분류 리포트 출력
print(classification_report(y_val, y_val_pred))
```
![[Source/image 96.png|image 96.png]]
![[Source/image 1 33.png|image 1 33.png]]