## 오늘 한 이야기💡
  
## 오늘부터 해야할 것☑️
#### 딥러닝&파이썬 용어 정리
|책 이름|챕터/날짜|이름|설명|
|---|---|---|---|
|세미나|07.25|[[Operation Study]]|Operations Study는 특정 시스템이나 프로세스의 효율성을 평가하고 향상시키기 위한 연구. 시뮬레이션, 최적화 기법, 보고서 작성을 포함하며 주로 논문 Operation Study 해봤어? 라고 물으면 수학적 근거가 부족한 논문 등에서 실제로 실험을 해봤냐는 의미로 쓰인다.|
|세미나|07.25|[[Context Vector]]|자연어 처리 모델의 구조 중 하나인 인코더-디코더 구조에서 인코더가 입력 시퀀스를 처리하여 생성하는 고정된 길이의 벡터이다. 이 벡터는 입력 시퀀스의 중요한 정보를 요약하여 디코더에 전달합니다.|
|세미나|07.25|[[Convolution]]|CNN에서 C. 합성곱이라는 뜻이다.|
|세미나|07.25|[[Backbone]]|신경망에서 주로 특징 추출을 담당하는 기본 네트워크 구조이다. 특징 추출과 전이 학습의 역할을 한다.|
|세미나|07.25|[[Interpolate]]|주어진 데이터 포인트들 사이의 빈 공간을 채워서 연속적인 값을 추정하는 과정이다.|
|세미나|07.25|[[인코더-디코더 구조]]|설명 참고|
|세미나|07.25|[[Attention 메커니즘]]|기존 인코더-디코더 구조에서 정보 손실이 발생할 수 있는 문제를 해결한 개선안.(자세한 내용은 설명 참고)|
|세미나|07.25|[[ResNet]]|Backbone 아키텍처 중 하나이다.|
|세미나|08.01|[[그래픽스 파이프라인]]|3D 장면을 렌더링하여 2D 이미지로 변환하는 과정에서 거치는 일련의 단계를 의미한다.|
|세미나|08.01|[[Adaptive Density Control(ADC)]]|3D 그래픽스와 비전 관련 분야에서 사용하는 기술로, 장면의 밀도를 동적으로 조절하여 렌더링 품질과 효율성을 개선하는 방법|
|세미나|08.01|[[Fast Differentiable Rasterization]]|컴퓨터 그래픽스와 인공지능 분야에서 사용되는 기법으로, 그래픽스 파이프라인의 라스터화 단계에서 미분 가능성을 제공하는 방법이다.|
|세미나|08.01|[[Volume density]]|파티클의 투명도. Ray가 오브젝트를 통과하는 중 파티클의 위치하는데 그 순간 파티클의 투명도를 의미한다. 예를 들어 통과하는 중인 파티클은 오브잭트 내부라서 투명도가 낮다.|
|세미나|08.01|[[SfM]]|Structure from Motion, 여러 장의 2D 이미지의 정보를 통해 전체적인 3D 구조와 카메라 pose를 추정하는 기법|
|세미나|08.01|[[NeRF]]|Neural Radiance Fields는 3D 장면을 효율적으로 표현하고 렌더링하기 위한 딥러닝 기술이다. NeRF는 주로 2D 이미지 시퀀스를 입력으로 받아들여, 장면의 3D 구조와 재질을 학습하여 새로운 시점에서 이미지를 생성하는 능력을 가지고 있다.|
|세미나|08.01|[[Plenoptic]]|진정한 의미의 홀로그램이 완성되기 전에 사람들이 홀로그램처럼 콘텐츠를 감상할 수 있도록 입체 영상을 촬영, 처리, 영사하는 기술이다.|
|세미나|07.25|[[제프리 힌튼]]|영국의 컴퓨터 과학자이다. 1986년의 다층 퍼셉트론과 (오차)역전파 [알고리즘](https://namu.wiki/w/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)을 증명, 2006년의 심층신뢰 신경망 발표로 [딥러닝](https://namu.wiki/w/%EB%94%A5%EB%9F%AC%EB%8B%9D)을 [인공신경망](https://namu.wiki/w/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D) 방법론의 대세로 굳히고 [GPU](https://namu.wiki/w/GPU)를 통한 병렬연산을 업계에 대중화시킨 선구자이다.|
|세미나|08.01|[[Domain generalization]]|머신러닝 및 컴퓨터 비전 분야에서의 기법으로, 모델이 특정 학습 도메인에서 학습한 후, 보지 못한 새로운 도메인에서도 잘 일반화할 수 있도록 하는 접근입니다.|
|세미나|08.22|[[lightweight decomposition model]]|가벼운 분할 분석 모델|
|세미나|08.22|[[Intrinsic dimension]]|데이터나 공간의 본질적인 차원 수를 나타내는 개념입니다. 이는 데이터가 본래 지니고 있는 정보의 구조를 반영하며, 데이터가 놓여 있는 고차원 공간에서 얼마나 적은 차원으로 이 데이터를 설명할 수 있는지를 나타냅니다.|
|세미나|24.08.28|[[anchor box & bouding box]]|Detection에서 사용되는 기본 틀이 Anchor box이고 실제 디텍션해낸 결과가 바운딩 박스이다.|
|세미나|24.08.28|[[sliding window]]||
|세미나|24.08.28|[[RPN]]|Region Proposal Network|
|세미나|24.08.28|[[DSA-LSTM]]||
|세미나|24.08.28|[[ROI Pooling]]||
|세미나|24.09.13|[[knowledge distillation]]||
|세미나|24.09.20|[[Landmark detection]]||
|세미나|24.09.20|[[Triangulation]]||
|세미나||[[MBW]]||
|세미나|24.09.20|[[RAFT]]||
|세미나|24.09.20|[[4D Correleation Volumes]]||
|세미나|24.09.20|[[GRU]]||
|세미나|24.09.20|[[LSTM]]||
|세미나|24.09.20|[[Multi-view NRSfM]]||
|세미나|24.09.20|[[$psi$(프사이)]]||
|세미나|24.09.20|[[HRnet]]||
|세미나|24.09.20|[[카메라 Calibration]]||
  
  
## Segmentation Classification
Segmentation에는 Semantic, Instance가 있다.
그 목적과 작동 방식에는 차이가 있다.
  
Semantic Segmentation은 이미지를 픽셀 단위로 분류하여 각각의 픽셀이 속한 클래스를 예측합니다. 예를 들어, 도로 장면에서는 차, 사람, 도로, 나무 등의 각 클래스가 있습니다. 여기서 중요한 점은 동일한 클래스에 속하는 모든 객체가 동일한 레이블을 공유한다는 것입니다.
Instance Segmentation은 Similar Segmentation과는 달리 객체의 개별 인스턴스를 구분하여 픽셀 단위로 분할합니다. 즉, 동일한 클래스에 속하더라도 각 객체가 개별적으로 인식되고 분할됩니다.
  
픽셀 클래시피케이션은 하나의 로스
마스크 —는 두 개의 로스를 가진다
1. 마스크 로스
2. 픽셀 로스
  
### 여기서 클래스란?
Segmentation에서 언급되는 "클래스"는 이미지나 비디오 내에서 식별하고 분류하고자 하는 객체나 영역의 범주(Category)를 의미합니다. 이 범주는 모델이 특정 픽셀, 객체 또는 영역을 속하는 것으로 예측하거나 레이블링하는 특정 그룹입니다.
### 예시
- **자동차, 사람, 나무가 있는 장면**:
    - 클래스 = 자동차, 사람, 나무
    - Semantic Segmentation: 이미지의 모든 픽셀은 이 세 가지 클래스 중 하나로 분류됩니다.
    - Instance Segmentation: 자동차, 사람, 나무에 속하는 각 개별 인스턴스가 분리되어 레이블링됩니다.
  
  
## 그래서 mask classification이 무엇인가?
  
### 트랜스포머에 query를 넣는데 여기에 구멍을 넣는다. 이것이 마스크 classification?
트랜스포머는 self attention - cross attention 그런데 이것의 위치를 바꿈으로써 마스크 클래시피케이션의 성능 향상이 있었다.
  
**포인트랜드**: 원래 전체 픽셀에 대해서 로스값을 구하는데, 포인트랜드는 배치를 만들듯이, 일부 픽셀만 뽑아서 로스값을 구한다.
  
백본이란 무엇인가?
  
## 선요약정리
1. MaskFormer란 무엇인가?
2. 논문의 흐름은 어떻게 되는가?
  
  
![[TalkFile_Mask2Former.pdf_page-0002.jpg]]
![[TalkFile_Mask2Former.pdf_page-0003.jpg]]
![[TalkFile_Mask2Former.pdf_page-0004.jpg]]
![[TalkFile_Mask2Former.pdf_page-0005.jpg]]
![[TalkFile_Mask2Former.pdf_page-0006.jpg]]
![[TalkFile_Mask2Former.pdf_page-0007.jpg]]
![[TalkFile_Mask2Former.pdf_page-0008.jpg]]
![[TalkFile_Mask2Former.pdf_page-0009.jpg]]
backbone은 무엇인가?
![[TalkFile_Mask2Former.pdf_page-0010.jpg]]
Convolution은 무엇인가?
![[TalkFile_Mask2Former.pdf_page-0011.jpg]]
![[TalkFile_Mask2Former.pdf_page-0012.jpg]]
덕프로덕트가 무엇인가?
F는 feature이다.
![[TalkFile_Mask2Former.pdf_page-0013.jpg]]
![[TalkFile_Mask2Former.pdf_page-0014.jpg]]
M: mask
Q: query
K: key
키-밸류? 인코더, 디코더? + 이 페이지에 나온 모든 용어 정리하기.
![[TalkFile_Mask2Former.pdf_page-0015.jpg]]
람다는 하이퍼파라미터 튜닝을 할 수 있게 해준 것이다.
저 세 개를 한 뭉텅이로 본다.
디코더는 3의 배수로 증가한다.
maskformer - mask2former의 차이점
1. 연결시키는 피처들이 포인트랜드로 뽑게 되는데, resolution(stride)별로…
2. 포인트랜스값을 구할 떄 사용된다.
![[TalkFile_Mask2Former.pdf_page-0016.jpg]]
![[TalkFile_Mask2Former.pdf_page-0017.jpg]]
![[TalkFile_Mask2Former.pdf_page-0018.jpg]]
![[TalkFile_Mask2Former.pdf_page-0019.jpg]]
![[TalkFile_Mask2Former.pdf_page-0020.jpg]]
논문에서 수학적 근거는 제시하지 않았다, 그렇다면 직접 실험을 해서 비교를 해봐야하는 것이다.
  
![[TalkFile_Mask2Former.pdf_page-0001.jpg]]