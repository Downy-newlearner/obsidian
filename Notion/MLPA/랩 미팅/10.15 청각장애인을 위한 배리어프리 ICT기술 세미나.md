## 최용근 교수님
수어 영상을 3D 모델링을 함
  
![[Source/image 7.png|image 7.png]]
  
이에 필요한 다양한 과제가 있음
![[Source/image 1 2.png|image 1 2.png]]
text2Gloss는 성능이 좋아서 체크해볼 필요가 있음
  
## 박한무 박사: 인공지능 기반 수어 번역 기술
한국 수어는 문법체계가 완전히 달라서 별개의 외국어라고 이해하는 것이 권장됨.
  
청각장애인을 위한 통역 서비스를 인공지능 Agent를 사용하려는 시도를 함
![[Source/image 2 3.png|image 2 3.png]]
  
해당 기술을 이용하여 농인의 수어를 청인에게 TTS 등으로 전달하는 방식을 사용한다.
  
### 학습데이터 취득
![[Source/image 3 3.png|image 3 3.png]]
하나의 한국어 단어가 수어에서는 여러 방식으로 표현될 수 있음
농인마다 수어 스타일이 조금씩 다를 수 있음
지역마다 방언도 존재함, 하지만 수어는 표준어가 존재하지 않는다.
이것이 어려운 부분임.
  
한국어 내용을 수어 표현으로 번안하기 위해 위원회를 꾸리는 등 노력함.
  
- 데이터 취득 시스템
![[Source/image 4 2.png|image 4 2.png]]
  
- 수어 인식 프레임워크 구조
![[Source/image 5 2.png|image 5 2.png]]
  
결과는 미흡하지만 그래도 작동함을 확인함
  
이 시스템을 공항에 적용하여 수어 인식 키오스크를 설계함.
키오스크에 수어를 보여주면 공항 시설 및 길 안내를 수행함.
  
- 프레임 단위 수어 형태소 정보 병합 기술
![[Source/image 6 2.png|image 6 2.png]]
![[Source/image 7 2.png|image 7 2.png]]
프레임별로 형태소를 추출하고 최종 문장을 합성하여 결과를 도출한다.
  
![[image 8.png]]
  
## 이인구 대표:
  
홀로 렌즈를 사용해 아바타 수어 번역 기술 적용.
농인이 착용하는 디바이스에 문장이 인식되면 해당 문장을 홀로그램으로 수어 표현을 한다.
  
수어 학습데이터셋은 음성언어 번역용 대비 300배 이상의 시간과 비용이 필요하다.
이 작업이 가능한 사람은 한국어와 수어에 모두 능통한 사람이어야한다.
인력이 부족한 실정이다.
하지만 4조원 지원을 받아 세계 1등 분량의 데이터셋을 만들어냈다.