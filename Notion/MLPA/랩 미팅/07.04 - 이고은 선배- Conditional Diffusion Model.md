## 오늘 한 이야기💡
- Ground truth
    
    기계 학습에서 "Ground Truth"는 모델을 학습시키고 평가하는 데 사용되는 "정답" 또는 "참값"을 의미합니다. 이는 모델의 예측이 얼마나 정확한지를 판단하는 기준이 되며, 다양한 감지, 분류, 회귀 및 다른 예측 작업에서 필수적인 요소입니다. 올바른 Ground Truth 데이터는 모델의 성능을 보장하고, 잘못된 Ground Truth 데이터는 모델 성능을 저하시킬 수 있습니다.
    
    ### Ground Truth의 역할
    
    1. **모델 학습**: 기계 학습 모델은 Ground Truth 데이터를 사용하여 방대한 양의 학습 데이터를 통해 패턴을 학습합니다. 이를 통해 모델은 입력 데이터에 대해 올바른 출력을 예측할 수 있도록 조정됩니다.
    2. **모델 평가**: 훈련 후에는 모델의 정확도, 정밀도, 재현율 등 다양한 성능 지표를 평가하기 위해 Ground Truth가 필요합니다. 이를 통해 모델의 예측 성능을 검증하고, 개선해야 할 부분을 식별할 수 있습니다.
    3. **모델 튜닝**: 하이퍼파라미터 최적화, 피처 선택, 정규화 등 다양한 모델 튜닝 작업에서도 Ground Truth가 사용됩니다. 이를 통해 모델 예측의 신뢰성과 일관성을 높일 수 있습니다.
    4. **성능 비교**: 다양한 모델 또는 알고리즘 간의 성능을 비교할 때도 Ground Truth를 기준으로 사용합니다. 동일한 Ground Truth를 기반으로 여러 모델의 성능을 평가하면 각 모델의 상대적 우수성을 판단할 수 있습니다.
    
    ### 예
    
    - **이미지 분류**: 이미지를 다양한 카테고리로 분류하는 작업에서 각 이미지가 어떤 카테고리에 속하는지에 대한 Ground Truth 레이블이 필요합니다.
    - **객체 탐지**: 객체 탐지 모델은 이미지에서 특정 객체의 위치를 예측합니다. 각 객체의 정확한 위치와 크기에 대한 Ground Truth 정보가 필요합니다.
    - **음성 인식**: 음성 데이터를 텍스트로 변환하는 작업에서 각 음성 샘플이 무엇을 말했는지에 대한 Ground Truth 텍스트가 필요합니다.
    
    ### 주의사항
    
    Ground Truth 데이터는 가능한 한 정확하고 신뢰할 수 있어야 합니다. 잘못된 Ground Truth 데이터는 모델 학습을 왜곡할 수 있으며, 이는 결국 모델의 예측 성능에 부정적인 영향을 미칠 수 있습니다. 따라서 Ground Truth 데이터를 수집하고 검증하는 데 철저한 주의를 기울이는 것이 중요합니다.
    
    요약하면, 기계 학습에서 Ground Truth는 모델의 성능을 학습하고 평가하는 데 핵심적인 역할을 하는 참값 또는 정답이라고 할 수 있습니다.
    
  
![[Source/Untitled 8.png|Untitled 8.png]]
- Seg GT - Seg pred 차이
    
    ### Seg GT (Segmentation Ground Truth)
    
    - **설명**: Segmentation Ground Truth(GT)는 이미지 분할 작업에서 "참값" 또는 "정답"을 의미합니다. 이는 사람이 직접 레이블링하거나 신뢰할 수 있는 방법으로 생성된 분할 결과로, 각 픽셀이 어느 클래스에 속하는지를 정확히 나타냅니다.
    - **생성 방법**: 일반적으로 사람이 수작업으로 라벨을 붙여 생성하거나, 다른 신뢰할 수 있는 방법(예: 표준 데이터셋)을 통해 얻습니다.
    - **용도**: 모델의 학습 및 평가에 사용됩니다. 모델이 예측한 결과와 비교하여 모델의 성능을 평가하는 기준이 됩니다.
    
    ### Seg pred (Segmentation Prediction)
    
    - **설명**: Segmentation Prediction(pred)은 학습된 모델이 입력 이미지를 기준으로 예측한 분할 결과를 의미합니다. 이는 모델이 각 픽셀이 어떤 클래스에 속한다고 예측한 결과입니다.
    - **생성 방법**: 기계 학습 모델(예: 딥러닝 모델)이 입력 이미지를 처리하여 각 픽셀의 클래스를 예측합니다.
    - **용도**: 실제 애플리케이션에서 이미지 분할 작업을 수행할 때 사용됩니다. 예측 결과가 Ground Truth와 얼마나 일치하는지를 기준으로 모델의 성능을 평가합니다.
    
      
    
    ### Seg GT와 Seg pred의 차이점
    
    1. **구분 기준**:
        - **Seg GT**: 참값, 수작업 또는 신뢰할 수 있는 방법으로 생성된 라벨.
        - **Seg pred**: 모델에 의해 예측된 값.
    2. **생성 방식**:
        - **Seg GT**: 사람이 직접 라벨링하거나 가공된 데이터셋을 사용.
        - **Seg pred**: 기계 학습 모델이 입력 데이터에 기반하여 예측.
    3. **용도**:
        - **Seg GT**: 모델 학습과 평가의 기준.
        - **Seg pred**: 실제 예측 결과로서 모델의 성능 평가.
    
      
    
    ### 예시로 살펴보기
    
    ### Segmentation 작업 예시:
    
    - **입력 이미지**: 고양이와 강아지가 포함된 사진.
    - **Seg GT**: 사람이 직접 모든 픽셀에 대해 고양이, 강아지, 배경 등의 라벨을 붙인 이미지.
    - **Seg pred**: 모델이 입력 이미지를 기반으로 예측한 각 픽셀의 라벨. 예를 들어, 고양이 영역은 고양이, 강아지 영역은 강아지로 예측.
    
    ### 비교 방법:
    
    1. **모델 평가**: Seg GT와 Seg pred를 비교하여 모델의 예측이 얼마나 정확한지 평가합니다. 주로 사용하는 평가 지표는 IoU(Intersection over Union), F1 스코어, 픽셀 정확도 등입니다.
    2. **시각적 비교**: 예측 결과와 Ground Truth 이미지(라벨링된 이미지)를 시각적으로 비교하여 모델의 성능을 확인합니다.
    
      
    
  
- PCA(Principle Component Analysis, 주성분 분석)
    
    PCA(Principal Component Analysis, 주성분 분석)는 고차원의 데이터를 저차원으로 변환하는 데 사용되는 통계 기법입니다. PCA는 데이터의 차원을 줄이면서도 최대한 많은 정보, 특히 분산을 유지하려고 합니다. 이 방법은 데이터 압축, 시각화, 노이즈 제거, 그리고 기계 학습에서의 차원 축소 등 다양한 용도로 활용됩니다.
    
## 세미나 - 이고은 선배☑️
![[Classifier-Free_Guidance.pdf]]
- 리버스는 노이즈가 얼마나 추가됐는지를 확인하는 과정
    
    → $\mu$﻿ 값을 확인하면 된다.
    
### Conditional Diffusion Model
- Diffusion 모델은 fidelity가 낮은 반면 Conditional Diffusion Model은 높은 fidelity를 보인다.
- GAN은 Truncation에 용이한 반면 CDM은 Truncation이 쉽지 않고 모델이 복잡한 구조를 가진다.
- 또한 CDM은 새로운 condition이 있다면 컨디션 추가 후 다시 학습해야한다는 불편한 점이 있다.
  
### Classifier Guidance Diffusion Model
- //DDPM
    
    - **Denoising Diffusion Probabilistic Model**의 약자로, 확률론적 소음 제거 확산 모델을 의미합니다.
    - 이 모델은 주로 생성 모델(generative model)로 사용되며, 이미지와 같은 데이터의 생성 및 복원 작업에 사용됩니다.
    
      
    
### Classifier-Free Guidance Diffusion Model
![[Source/Untitled 1 2.png|Untitled 1 2.png]]
위와같은 Classifier Guidance Diffusion Model의 단점때문에, Classifier-Free Guidance Diffusion Model을 사용한다.
  
- $\epsilon$﻿은 노이즈를 의미한다.
  
- discrete, continuous의 의미
    
    "Classifier-Free Guidance Diffusion Model"에서 "discrete"와 "continuous"라는 용어는 주로 시간 스텝과 확산 과정에서의 노이즈 스케쥴링 방식에 따라 사용됩니다. 이러한 용어는 확산 모델의 시간 단계를 어떻게 관리하는지, 그리고 노이즈를 추가하고 제거하는 방법을 설명합니다.
    
    ### 1. Discrete (이산)
    
    **이산(discrete)** 확산 모델은 시간 스텝이 명확히 구분되며, 각 단계는 명확한 점으로 정의됩니다. 즉, 시간은 연속적인 값이 아닌 고정된 단계로 나누어집니다. 각 단계에서 일정한 양의 노이즈가 추가되거나 제거됩니다.
    
    - **특징**:
        - **명확한 시간 스텝**: \( t = 1, 2, \ldots, T \)와 같이 명확히 정의된 단계.
        - **고정된 노이즈 스케쥴**: 각 단계에서 일정한 양의 노이즈를 추가하거나 제거합니다.
        - **간단한 구현**: 계산 및 구현이 상대적으로 간단합니다.
    - **예**:
        - **알고리즘**: 알고리즘 2의 \( t = 1, \ldots, T \) 루프는 이산화된 시간 스텝을 사용합니다.
        - **절차**: 각 정해진 시간 스텝 \( t \)에서 노이즈를 샘플링하고 제거한 결과를 기반으로 합니다.
    
    ### 2. Continuous (연속)
    
    **연속(continuous)** 확산 모델은 시간 스텝이 연속적인 값으로 표현되며, 각 단계는 실수로 정의됩니다. 이는 연속적인 시간 도메인에서 확산 과정이 발생하며, 노이즈 스케일링이 연속 함수로 표현됩니다.
    
    - **특징**:
        - **연속적인 시간 표현**: \( t \)는 연속적인 값으로, 예를 들어 \( t \in \mathbb{R} \)로 표현됩니다.
        - **연속 노이즈 스케쥴링**: 노이즈의 스케일링이 연속 함수로 표현되며, 일반적으로 미분이 가능합니다.
        - **정교한 구현**: 일관되게 미세한 시간 스텝을 사용할 수 있어, 더 정교한 노이즈 모델링과 제어가 가능합니다.
    - **예**:
        - **연속적인 노이즈 함수**: 확산 모델에서 시간 스케일링이 분수 시간 동안 부드럽게 변화할 수 있습니다.
        - **연속 상태 변화**: 상태 변화가 연속적으로 발생하며, \(\lambda\)와 같은 매개변수가 연속적으로 변화합니다.
    
    ### 알고리즘 적용 예시
    
    - **Algorithm 1 (Joint training a diffusion model with classifier-free guidance)**:
        - **비연속적 속성**: 일반적으로 트레이닝 단계에서 시간 스텝이 이산적으로 처리됩니다. \(\lambda\)이 특정 시간 스텝에서 샘플링됩니다.
        - **구성**:  
            \[  
            z_\lambda = \alpha_\lambda x + \sigma_\lambda \epsilon  
            \]  
            여기서 \(\lambda\)는 특정 이산 값.  
            
    - **Algorithm 2 (Conditional sampling with classifier-free guidance)**:
        - **이산적 시간 스텝**: \( t = 1, \ldots, T \) 범위에서 이산적인 시간 스텝을 따릅니다.
        - **구성**:  
            \[  
            \tilde{\epsilon}  
            _t = (1+w) \epsilon_\theta(z_t, c) - w \epsilon_\theta(z_t)  
            \]  
            각 시간 스텝에서의 계산이 이산적 단계에서 수행됩니다.  
            
    
    ### 요약
    
    - **Discrete (이산)** 확산 모델: 고정된 이산 시간 단계와 명확한 노이즈 스케쥴링을 사용합니다. 계산이 간단하고 명확하게 정의된 단계로 진행됩니다.
    - **Continuous (연속)** 확산 모델: 연속적인 시간 표현과 노이즈 스케쥴링을 사용합니다. 시간과 노이즈의 변화가 연속함수로 표현되며, 더 정교한 제어가 가능하지만 구현이 조금 더 복잡할 수 있습니다.
    
    이 모델들은 각각의 시간 도메인과 정의에 따라 확산 과정을 다루며, 다양한 데이터 유형과 복잡성에 적응할 수 있는 유연성을 제공합니다.
    
  
- 평가지표: FID, Inception Score(IS)
    
    FID(Frechet Inception Distance)와 Inception Score(IS)는 두 가지 생성 모델(GANs 등)을 평가하는 데 주로 사용되는 품질 척도입니다. 각각의 지표는 특정한 방식으로 생성된 이미지의 품질을 평가하며, 서로 다른 특성과 목적을 가지고 있습니다.
    
    ### Frechet Inception Distance (FID)
    
    **FID**는 생성된 이미지와 실제 이미지 사이의 분포 차이를 측정하는 지표입니다. 이는 생성된 이미지가 얼마나 실제 이미지와 유사한지를 평가하는 데 사용됩니다.
    
    ### 계산 방법:
    
    1. **특징 추출**: Inception V3 모델을 사용하여 실제 이미지와 생성된 이미지의 특징 벡터를 추출합니다. 일반적으로, 2048차원 풀링(Pooling) 레이어의 출력을 사용합니다.
    2. **특징 분포 비교**: 실험에서 실제 이미지의 특징 분포 $((\mu_r,\Sigma_r))$﻿와 생성된 이미지의 특징 분포 $((\mu_g,\Sigma_g))$﻿를 각각 계산합니다.
    3. **거리를 계산**: 두 분포 사이의 Frechet 거리 (Wasserstein-2 거리)를 계산합니다. 이는 다음과 같이 정의됩니다:  
          
        여기서  
        $(\text{Tr})$﻿는 행렬의 대각합(trace)을 의미합니다.
        
        $$
        
    
    ### 특징:
    
    - **장점**:
        - 실제 이미지와 생성된 이미지의 특징 분포를 비교하므로, 더 실제적인 평가를 할 수 있습니다.
        - 낮은 FID 값은 생성된 이미지가 실제 이미지와 매우 유사함을 의미합니다.
    - **단점**:
        - 계산이 복잡하고 느릴 수 있습니다.
        - 생성 이미지의 다양성을 충분히 반영하지 못할 수 있습니다.
    
    ### Inception Score (IS)
    
    - **Inception Score (IS)**는 생성된 이미지가 어느 정도 다양하고, 품질이 높은지를 평가하는 지표입니다. 이 방법은 이미지가 잘 분류되는지와 동시에 이미지의 다양성도 평가합니다.
    
    ### 계산 방법:
    
    1. **이미지 평가**: Inception V3 모델을 사용하여 생성된 이미지 각각을 분류합니다.
    2. **조건부 확률 \( p(y|x) \)**: 각 생성 이미지 \( x \)가 특정 클래스 \( y \)로 분류될 확률을 계산합니다. 여기서 \( y \)는 이미지의 클래스 레이블을 나타냅니다.
    3. **마가(Marginal) 분포 \( p(y) \)**: 다양한 이미지가 골고루 생성되는지 확인하기 위해, 모든 생성 이미지에 대한 마가 확률을 계산합니다. 이는 \( p(y|x) \) 평균으로 계산됩니다.
    4. **점수 계산**: Inception Score는 다음과 같이 계산됩니다:
        
        $$
        
        여기서 $( D_{KL} )$﻿는 Kullback-Leibler 다이버전스를 나타내며, $( p(y|x) )$﻿가 $( p(y) )$﻿로부터 얼마나 떨어져 있는지를 측정합니다. 다이버전스가 클수록, 생성된 이미지의 다양성이 높다는 의미입니다.
        
    
    ### 특징:
    
    - **장점**:
        - 이미지 품질과 다양성을 동시에 평가할 수 있습니다.
        - Inception 모델을 사용하므로, 사전 훈련된 강력한 분류기의 성능을 활용할 수 있습니다.
    - **단점**:
        - 실제 이미지와의 비교 없이 생성된 이미지 자체만을 평가하므로, 절대적인 품질 평가가 어려울 수 있습니다.
        - 생성된 이미지의 다양성을 과대평가할 가능성이 있습니다.
    
    ### 요약
    
    - **Frechet Inception Distance (FID)**: 실제 이미지와 생성된 이미지 간의 특징 분포의 차이를 평가하여 이미지의 현실성을 평가합니다. 낮을수록 좋은 FID를 의미하며, 현실적인 이미지를 생성하는 모델을 나타냅니다.
    - **Inception Score (IS)**: 생성된 이미지의 품질과 다양성을 동시에 평가합니다. IS 점수가 높을수록, 고품질이며 다양한 이미지를 생성함을 의미합니다.
    
    두 지표 모두 생성 모델의 성능을 평가하는 데 중요한 역할을 하며, 각 지표의 평가 방식과 목적에 따라 생성된 이미지의 품질을 종합적으로 평가할 수 있습니다.