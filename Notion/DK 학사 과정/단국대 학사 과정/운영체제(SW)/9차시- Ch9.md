---
## Ch.9 Scheduling: Proportional Share
  
---
  
**Proportional Share(비례 지분)**
CPU의 몇 퍼센트를 샀는지에 따라 지분을 보장해주는 방식이다.
종류는 **Lottery Scheduling, Stride scheduling**이 있다.
  
**Lottery Scheduling**
복권은 많이 살 수록 당첨 확률이 높아진다.
복권을 티켓으로 표현하는데, 티켓은 CPU 자원에 대한 지분이다.
난수의 승자가 스케쥴링 된다.
이 방식은 확률에 기반한다.
클라우드 환경에서 매우 유연하게 사용가능하다.(실제로 클라우드환경에서 많이 사용하는 스케쥴링이다.)
Ticket currency
지역 통화 global 통화, 2가지가 제공된다.
통용되는 글로벌 통화를 분배하지만 글로벌 통화에 관계없이 currency ticket을 한 프로세스 안에서 나눈다.
다시 종합할 때에는 글로벌 통화를 고려하여 currency ticket의 가치를 계산한다.
|   |   |   |   |   |
|---|---|---|---|---|
|Global Tickets for Process|Process(num of jobs)|Jobs|Distributed own Tickets|Global Tickets for jobs|
|100|A(2)|A1|500|50|
|||A2|500|50|
|100|B(1)|B1|10|100|
  
Ticket transfer
어떤 잡이 다른 잡에게 일시적으로 티켓을 줄 수 있다.
client/server 환경에서 유용하다.
  
Ticket Inflation
일시적으로 티켓의 수를 높이거나 낮출 수 있다.(로컬 티켓)
  
장점
구현이 매우 간단하다.
fairness 보장
unfairness analysis라는 metric이 있다.
두개의 Job이 있는데 같은 티켓수, 같은 run time이다.
두 Job의 종료 시간을 각각 C1, C2라고 한다.(C1이 먼저 끝나는 Job의 종료시간이다.)
$U = C1 / C2$﻿로 계산한다.
$U = 0.5$﻿일 때 최악, $U=1$﻿일 때 최선이다.
$U=0.5$﻿라는 것은 먼저 끝나는 Job이 완전히 수행되어 종료된 후 나중에 끝나는 Job이 수행되기 시작한다는 것이다.
$U=1$﻿이라는 것은 두 Job이 최대한 Fair하게 스케줄링 되어 거의 동시에 종료된다는 것이다.
  
단점
Deterministic하지 않다.(확률에 기반한다.)
  
**Stride scheduling**
deterministic한 스케줄링이다.
Stride라는 컨셉을 사용한다.
Stride는 tickets수의 역수이다.
pass value가 가장 적은 잡을 스케쥴링한다.
pass value는 stride만큼 증가한다.
  
![[Source/Untitled 41.png|Untitled 41.png]]
1. 각 프로세스의 Pass value는 0부터 시작한다.
2. 가장 낮은 Pass value를 갖고있는 프로세스를 스케줄링하고, 그 프로세스의 Pass value를 Stride만큼 증가시킨다.
3. 프로세스가 끝날 때까지 1,2를 반복한다
→Pass value는 Stride의 영향을 받아 증가하는 Stride가 클 수록 스케줄링이 적게 된다.(즉 Tickets이 적을 수록 스케줄링이 적게 된다.)
  
$Stride\propto PassValue \propto 1/Tickets$﻿
  
$Stride = CommonMultiple/Tickets$﻿
  
리눅스에서 CFS라는 이름으로 사용된다.
---
## Ch.10 Multiprocessor Scheduling
  
---
**Multiprocessor**
멀티 프로세서가 있는 시스템
여러 개의 독립적인 CPU를 갖춘 시스템
높은 수준의 병렬 처리를 요구하는 환경에 적합하다.
**Multicore**
멀티코어가 있는 칩
단일 CPU 내에 여러 실행 코어를 갖는 구조
전력 소비와 열 관리를 최적화하면서도 처리 능력을 향상시킬 수 있는 방법이다.
  
코어 개수가 많아지면, ‘여러 코어를 모두 사용할 수 있는 프로그램을 만들어야겠다(병렬 프로그램)’ 또는 ‘여러 개의 프로세스를 여러 CPU에 잘 분산시켜 실행하는 부하 균등(load balancing)’을 고민한다.
---
p.33 10.1 Background
**CPU cache**
L1, L2, LLC(Last Level Cache)가 있다.
캐시는 지역성에 기반한다.
시간적 지역성, 공간적 지역성이 있다.(둘은 프로그램에 내제되어있다.)
  
이점은 Cache hit, Delayed write(지연 쓰기)가 있다.
  
**Issues on Multiprocessor**
**Cache affinity(캐시의 밀접 관련성)**
이전에 프로세스를 실행했던 프로세서에서 다시 실행하는 것이 유리하다.
  
==→포인트는 지역성때문에 프로세스가 이전에 썼던 코어로 다시 스케줄링 되는 것이 유리하다는 것이다.==
---
p.35
**SQMS(Single-Queue Multiprocessor Scheduling)**
코어 개수에 상관없이 큐를 1개 사용하면 Single-Queue, 코어 개수에 맞도록 큐를 하나씩 두면 Multi-Queue라고 한다.
장점
단순함
단점
cache affinity를 지원하기 위해서는 복잡한 매카니즘이 필요하다.
확장성(scalability)이 좋지 않다.
lock에 대한 충돌이 발생한다.(노드를 제거하고 삽입할 때는 lock을 걸어야한다.)
  
**MQMS(Multi-Queue Multiprocessor Scheduling)**
총 코어의 수만큼의 큐를 사용한다.
목적은 멀티코어 프로세서 환경에서 각 코어가 독립적으로 작업을 처리할 수 있도록 하는 것이다.
장점
cache affinity
less lock contention
  
단점
load balancing(놀고 있는 코어가 있다면 일을 분배해주는 것)을 고려해야한다.
---
p. 37
리눅스의 스케줄러
O(1) scheduler
작업을 뽑을 때 O(1)이라는 뜻.
  
CFS(Complete Fair Share Scheduler)
stride 스케줄링 방식이다.
레드블랙 트리로 구현되어있다.
트리 노드의 값은 pass value이다.
  
BF Scheduler
아직 메인스트림에 들어오지는 않았다.
---
p. 38 Summary
**배운 것**
스케줄링 메카니즘
Time sharing
여러 사용자나 여러 작업이 컴퓨터 시스템의 처리 능력을 공유할 수 있도록 하는 운영 체제의 기술입니다.
이 시스템은 CPU 시간을 작은 단위로 나누어 각 작업에 할당함으로써, 동시에 여러 작업을 처리하는 것처럼 보이게 합니다.
이 방식은 사용자 각각이 독립적인 컴퓨터를 사용하는 것 같은 경험을 제공합니다.
Context switch
컨텍스트 스위치는 CPU가 한 작업에서 다른 작업으로 전환할 때 발생하는 과정입니다.
이 과정에서 현재 실행 중인 작업(프로세스나 스레드)의 상태(컨텍스트)를 저장하고, 다음에 실행할 작업의 상태를 불러오는 작업이 포함됩니다.
컨텍스트 스위치는 운영 체제의 스케줄러에 의해 관리되며, 멀티태스킹 환경에서 필수적인 기능입니다.
Timer interrupt
타이머 인터럽트는 컴퓨터의 하드웨어 타이머가 설정된 시간 간격마다 발생하는 인터럽트입니다.
이 인터럽트는 운영 체제가 시간을 추적하고 시분할 시스템에서 작업 간에 전환하는 데 사용됩니다.
예를 들어, 타이머 인터럽트는 현재 실행 중인 작업의 CPU 시간 할당이 끝났음을 운영 체제에 알리고, 컨텍스트 스위치를 통해 다음 작업으로 전환할 수 있도록 합니다.
Handler
**핸들러는 특정 이벤트나 인터럽트가 발생했을 때 실행되는 함수나 루틴을 의미합니다.**
**예를 들어, 타이머 인터럽트 핸들러는 타이머 인터럽트가 발생했을 때 호출되어 해당 인터럽트를 처리하는 코드를 실행합니다.**
**핸들러는 운영 체제나 응용 프로그램에서 다양한 종류의 이벤트나 인터럽트에 대응하기 위해 사용됩니다.**
Policy
FCFS, SJF, RR, MLFQ, Lottery, Stride, Multiprocessor
  
**스케줄링 방식을 비교하는 방법은?**
Analytic models(분석 모델)
deterministic하게 계산
Queueing theory(큐 이론)
확률로 계산
Simulation(시뮬레이션)
real한 implementation이 아니지만 여전히 어려운 방법이다.
Implementation(구현)
아래로 갈 수록 어려워진다.
  
---
p.41 appendix 1
Workload에서 수행시간은 어떻게 알 수 있는가?
![[Source/Untitled 1 29.png|Untitled 1 29.png]]
  
1. 사용자가 명세한다.
2. OS가 예측한다.
    
    Exponential moving average