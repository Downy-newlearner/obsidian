## Abstract
![[Pasted image 20250327142633.png|300]]
자기회귀 모델(ARMs)은 대형 언어 모델(LLMs)의 핵심으로 널리 인식되고 있습니다. 우리는 이 통념에 도전하며, 사전 학습과 지도 미세조정(SFT) 패러다임 하에서 처음부터 학습된 확산 모델인 **LLaDA**를 소개합니다.  
LLaDA는 순방향 데이터 마스킹 과정과 역방향 과정을 통해 분포를 모델링하며, 마스킹된 토큰을 예측하기 위해 일반적인 트랜스포머(Transformer)를 사용합니다. 가능도 경계(likelihood bound)를 최적화함으로써, 확률적 추론을 위한 원칙적인 생성 방식을 제공합니다.  
다양한 벤치마크에서 LLaDA는 뛰어난 확장성을 보이며, 우리가 직접 구축한 ARM 기반 모델들을 능가했습니다. 특히 **LLaDA 8B**는 **LLaMA3 8B**와 같은 강력한 LLM들과 인컨텍스트 학습에서 경쟁할 정도이며, SFT 이후에는 다중 턴 대화 등 사례 연구에서 인상적인 지시 따르기 능력을 보여줍니다.  
또한, LLaDA는 **반전의 저주(reversal curse)** 문제를 해결하며, **GPT-4o**보다 뛰어난 반전 시 완성 성능을 보여주었습니다. 우리의 연구 결과는 확산 모델이 ARM을 대체할 수 있는 유망한 대안임을 입증하며, 앞서 언급한 핵심 LLM 능력들이 반드시 ARM에 의존하지 않는다는 기존의 가정을 뒤흔듭니다.

- ARMs(Autoregressive models)
	- 자기 회귀 모델
	- 이전 단어들을 기반으로 다음 단어를 하나씩 예측하는 방식의 언어 모델. GPT 시리즈가 대표적.

- cornerstone
	- 초석
	- 어떤 개념이나 시스템의 가장 중요한 핵심 요소입니다.

- forward data masking process
	- 순방향 데이터 마스킹 과정
	- 입력 데이터를 점진적으로 가려서 모델이 예측하도록 만드는 전처리 단계입니다.
	- BERT에서 사용하는 MLM(Masked Language Modeling)과 비슷하게 문장의 일부 토큰을 MASK로 가리고, 이를 맞추도록 모델을 학습시킨다.
	- 하지만 MLM과 다른 점은, forward data masking process는 단순히 한 번에 일부를 마스킹하는 것이 아니라, 여러 단계에 걸쳐 점점 더 많은 정보를 제거해 가며 학습하는 방식이다.
	
- likelihood bound
	- 실제 데이터가 나올 확률(가능도)을 직접 계산하기 어려울 때, 그 확률을 **하한선 또는 근사치로 제한**하여 최적화하는 값입니다.
	- 요약하면, likelihood를 계산하기 어려워서 likelihood bound를 계산하는 것이다.

- scalability
	- 확장성
	- 모델 크기나 데이터량이 커져도 성능이 안정적으로 향상되는 능력입니다.
	- '확장성이 좋다'는 말은 결국 실험 결과를 통해 확인된 평가이다.
	- "해보니까 확장성이 좋더라!"가 맞는 표현이다.
	- ![[Pasted image 20250327144318.png|400]]

- ARM baselines
	- 성능 비교를 위해 사용하는 기존 자기회귀 기반 모델들입니다.

- multi-turn diaglogue
	- 여러 번의 질문과 응답이 오가는 연속적인 대화입니다.

- reversal poem completion task
	- 단어 순서가 뒤바뀐 시를 주고 이를 올바르게 완성하는 언어 모델 평가 과제입니다.



## 1. Introduction
### LLM의 핵심은 자기회귀 패러다임이 아니라 생성 모델링 원칙(Generative modeling principles이다.
- 기존 autoregressive model(ARM)이 사용한 "다음 토큰 예측 방식(next-token prediction paradigm)":
- ![[Pasted image 20250327145925.png]]
	- $x$는 길이가 $L$인 시퀀스이며, $x_i$는 $i$번째 토큰을 의미한다.
- 이 방식은 굉장히 효율적이라고 증명됐고, 현재 LLMs의 foundation이다.
- 하지만 해결되지 않은 질문이 있다.
	- Is the autoregressive paradigm the only viable path to achieving the intelligence exhibited by LLMs?
		- 자기회귀 패러다임은 대형 언어 모델(LLM)이 보여주는 지능을 달성하기 위한 유일한 실현 가능한 경로인가요?
->아니다

![[Pasted image 20250327171401.png]]
- 위 [[생성 모델링 원칙]]이 LLM의 필수 속성을 근본적으로 뒷받침하는거지, Autoregressive formulation이 LLM의 필수 속성을 뒷받침하는게 아니다.
-> 자기 회귀 방식보다 더 효율적인 방식이 있지 않을까 고민을 시작하게 만듦.

### 자기 회귀 특성의 이점인 줄 알았으나 다른 이유에서 나온 이유였던 것들
- 하지만 LLM의 내제되어있는 특정 한계는 자기 회귀 특성에서 나온다.
	1. 확장성
		- ARM이 확장성이 높다고 평가되는데 사실 이게 ARM 덕분이라기보다는 아래 요소 간 상호작용의 영향이 더 크다.
			- 트랜스포머
			- 모델 및 데이터 크기
			- 식 (1)에 기반한 생성 원리가 유도하는 [[Fisher Consistency]]
		- 시각 데이터에서 디퓨전 트랜스포머가 성공한 사례들이 주장을 뒷받침한다. [[Scalable Diffusion Models with Transformers.pdf]]
	2. 지시 따르기(instruction-following)와 인컨텍스트 학습(in-context learning) 능력은 자기회귀 모델(ARM)의 고유한 장점이 아니라,  구조적으로 일관된 언어 과제에서 적절한 조건부 생성 모델이라면 본질적으로 가질 수 있는 속성으로 보입니다.

### LLM의 자기회귀적 특성이 제시하는 주목할 만한 과제
1. 순차적 토큰별 생성은 높은 개산 비용을 초래한다
2. 왼쪽에서 오른쪽으로의 모델링은 역전 추론 과제에서 효과를 제한한다.

위 이슈들을 LLaDA(Large Language Dissufion with mAsking)을 통해 해결하고자 한다.

### LLaDA의 기여
- 13만 GPU 시간을 사용하여 2.3조 토큰에서 처음부터 사전학습함.
- 그 다음에 4.5백만 쌍에서 SFT가 수행됨.

- **확장성(Scalability):** LLaDA는 10²³ FLOPs의 계산 자원까지 효과적으로 확장되며, 동일한 데이터로 학습된 자체 구축한 ARM 기준 모델들과 6개 과제(MMLU, GSM8K 등)에서 유사한 성능을 달성한다.
    
- **문맥 내 학습(In-Context Learning):** 주목할 만하게도, LLaDA 8B는 15개의 표준 zero-shot 및 few-shot 학습 과제 대부분에서 LLaMA2 7B(Touvron et al., 2023)를 능가하며, LLaMA3 8B(Dubey et al., 2024)와는 비슷한 성능을 보인다.
    
- **명령어 따르기(Instruction-Following):** LLaDA는 SFT 이후 명령을 따르는 능력이 크게 향상되었으며, 특히 다중 턴 대화(multi-turn dialogue)와 같은 사례 연구에서 그 효과가 입증되었다.
    
- **역방향 추론(Reversal Reasoning):** LLaDA는 역방향 저주(reversal curse) 문제를 효과적으로 극복하며, 순방향 및 역방향 과제 모두에서 일관된 성능을 보인다. 특히, 시 완성 과제에서 GPT-4o보다 뛰어난 성능을 보여준다.




기존의 방식은 생성 모델의 기본 원칙(즉, 데이터의 분포를 학습하여 새로운 샘플을 생성하는 방식)을 따르면서 주로 Autoregressive 방식(예: GPT)을 활용했어. 하지만 이 논문에서는 동일한 생성 원칙을 따르되, 그 대안으로 Diffusion 기반 방법을 도입한 거야.

즉, 핵심은 Autoregressive 방식(ARM)이 아닌 Diffusion을 활용해 conditional generation을 수행했다는 점이야. 이 방식은 예측 정확도 향상과 다양한 조건에서의 유연한 생성 능력을 확보하는 데 초점이 있어.

## 2. Approach
### 2.1. Probabilistic Formulation(확률적 정의)

- LLaDA는 순방향 과정과 역방향 과정을 통해 모델 분포 $p_\theta(x_0)$를 정의한다.
- 순방향 과정(Forward process
	- 입력 $x_0$의 토큰들을 점진적으로 마스킹해 나가며, 최종적으로 t = 1에서 모든 토큰이 마스킹된 상태가 된다.


![[Pasted image 20250328015943.png]]
- LLaDA의 핵심은 마스크 예측기(mask predictor)인 파라메트릭 모델 pθ​(⋅∣xt​)이다.
- x0​는 학습 데이터에서 샘플링
- t는 구간 [0, 1]에서 균일하게 샘플링
- $x_t$​는 순방향 과정을 통해 생성된다.
	- xt​는 **시간 t**에서의 **부분적으로 마스킹된 시퀀스**를 의미해.
	- 요약하자면, xt​는 원본 $x_0$​을 확률 $t$로 마스킹한 결과이며, 이는 순방향 과정(forward process)에서 만들어진다.

- 지시 함수 $1[\cdot]$는 손실 계산이 마스킹된 토큰에만 적용되도록 한다.
	- 지시 함수(indicator function)는 조건이 참이면 1, 거짓이면 0을 반환하는 함수지.
	- ![[Pasted image 20250328021128.png|300]]

- 학습이 완료되면, 마스크 예측기로 파라미터화된 역방향 과정을 시뮬레이션할 수 있으며
- t=0에서 유도된 주변 분포(marginal distribution)를 통해 모델 분포 $p_\theta(x_0)$를 정의할 수 있다.
- 특히, 식 (3)에서의 손실은 모델 분포에 대한 음의 로그우도(negative log-likelihood)에 대한 상한(upper bound)임이 입증되었다
- 이러한 이유로 식 (3)은 생성 모델링을 위한 원칙적인(principled) 목적 함수로 간주된다.
- ![[Pasted image 20250328020626.png|300]]


- LLaDA는 마스킹 비율을 0과 1 사이에서 **무작위로 변화**시키는 반면, 기존의 마스킹 언어 모델들(예: BERT; Devlin, 2018)은 **고정된 마스킹 비율**을 사용한다.
- 이 미묘한 차이는 특히 모델 규모가 커질수록 큰 의미를 가진다.
-  =='마스킹 비율이 무작위' 라는 것의 의미==
	1. 다양한 마스킹 상황에 적응하도록 학습된다.
		- LLaDA는 매 학습 예제마다 마스킹 비율 t를 \[0,1\] 안에서 무작위로 샘플링한다.
		- 0은 마스킹을 안한다는 의미이고, 1은 모든 토큰을 마스킹한다는 의미이다.
		- 다양한 정보량 상황에 대응하는 능력을 자연스럽게 익히게 된다.
	2. 문맥 내 학습(In-Context Learning) 능력과 연결된다.
		- LLaDA는 마스킹이 적은 상태(프롬프트가 풍부한 상황)부터 마스킹이 거의 전부인 상태(생성 초기 단계)까지 모두 학습한다.
		- 이것이 결국 '주어진 프롬프트만 보고도 적절히 다음을 생성'하는 LLM 특유의 능력과 이어진다.
		- 자연스럽게 LLM 처럼 문맥 내 학습 능력을 갖추게 된다.
	3. 결론
		- 무작위 마스킹은 모델에게 '다양한 정보 조건에서 예측하는 법'을 학습시켜서, 특히 크고 강력한 모델이 문맥을 잘 활용하고 생성 능력을 자연스럽게 갖추도록 도와주는 방식이다.

## 2.2 Pre-training
- LLaDA는 마스크 예측기(mask predictor)로 Transformer(Vaswani, 2017)를 사용(기존의 대형 언어 모델(LLM)들과 유사)
- 그러나 LLaDA는 전체 입력을 볼 수 있는 구조이기 때문에 **causal mask**는 사용하지 않는다.

- LLaDA는 1B와 8B 크기의 두 가지 모델로 학습되었으며, LLaMA3 8B와 비교를 위해 구조를 요약하고 세부 내용은 부록 B.2에 제시됨.
- 대부분의 하이퍼파라미터는 유지하되, 몇 가지 필요한 변경이 적용됨.
- LLaDA는 KV 캐싱과 호환되지 않기 때문에 **grouped query attention** 대신 **vanilla multi-head attention**을 사용함.
- 이 변경으로 attention 레이어의 파라미터 수가 증가했고, 모델 크기를 맞추기 위해 **FFN 차원은 축소**함.
- 데이터에 맞게 조정된 토크나이저를 사용하여, 어휘 크기(vocabulary size)는 기존 모델과 약간 다름.

