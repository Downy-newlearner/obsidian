---
created: 2024-11-20
tags: 
aliases: 
reference: https://python.langchain.com/docs/tutorials/chatbot/
---
## LLMì„ ì´ìš©í•˜ì—¬ ëŒ€í™” ì‹œì‘í•˜ê¸°
```
import getpass
import os

os.environ["OPENAI_API_KEY"] = getpass.getpass()

from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-3.5-turbo")

from langchain_core.messages import HumanMessage

model.invoke([HumanMessage(content="Hi! I'm Bob")])

model.invoke([HumanMessage(content="What's my name?")])
```
ëª¨ë¸ì€ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ì§€ ëª»í•˜ë¯€ë¡œ, ê³„ì†í•´ì„œ ì´ì „ ëŒ€í™”ë“¤ì„ ëª¨ë‘ ì…ë ¥í•´ì¤˜ì•¼í•œë‹¤.

```
from langchain_core.messages import AIMessage

model.invoke(
    [
        HumanMessage(content="Hi! I'm Bob"),
        AIMessage(content="Hello Bob! How can I assist you today?"),
        HumanMessage(content="What's my name?"),
    ]
)
```

## ë©”ì‹œì§€ ì§€ì†ì„±
*LangGraph*ëŠ” ë‚´ì¥ëœ Persistence Layer(ë°ì´í„° ìœ ì§€ ê³„ì¸µ)ë¥¼ ì œê³µí•˜ì—¬, ì—¬ëŸ¬ ëŒ€í™”(turns)ë¥¼ ì§€ì›í•˜ëŠ” ì±„íŒ… ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì— ì í•©í•œ ë„êµ¬ì…ë‹ˆë‹¤.
	LangGraphë¥¼ ì´ìš©í•˜ì—¬ ë©”ì‹œì§€ ê¸°ë¡ì„ ìë™ìœ¼ë¡œ ì €ì¥í•  ìˆ˜ ìˆì–´, ìœ„ì˜ ì½”ë“œ ì˜ˆì œì²˜ëŸ¼ ì´ì „ ëŒ€í™”ë“¤ì„ ëª¨ë‘ ì…ë ¥í•˜ì§€ ì•Šì•„ë„ ë˜ì–´ ê°œë°œì„ ê°„ì†Œí™” í•  ìˆ˜ ìˆë‹¤.

LangGraphëŠ” ëŒ€í™”í˜• ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ë©”ì‹œì§€ ê¸°ë¡ì„ ìœ ì§€í•˜ê³ , ê°„ë‹¨í•œ ì²´í¬í¬ì¸íŠ¸ ê¸°ëŠ¥ì„ ì§€ì›í•˜ì—¬ ê°œë°œ í¸ì˜ì„±ì„ ë†’ì—¬ì£¼ëŠ” ë„êµ¬ì…ë‹ˆë‹¤. SQLite ë˜ëŠ” Postgresì™€ ê°™ì€ ì €ì¥ì†Œì™€ë„ í†µí•© ê°€ëŠ¥í•˜ë‹¤.

### configì„ ì´ìš©í•œ ìŠ¤ë ˆë“œ ì´ìš©
```
from langgraph.checkpoint.memory import MemorySaver
from langgraph.graph import START, MessagesState, StateGraph

# Define a new graph
workflow = StateGraph(state_schema=MessagesState)


# Define the function that calls the model
def call_model(state: MessagesState):
    response = model.invoke(state["messages"])
    return {"messages": response}


# Define the (single) node in the graph
workflow.add_edge(START, "model")
workflow.add_node("model", call_model)

# Add memory
memory = MemorySaver()
app = workflow.compile(checkpointer=memory)
```
ìš°ì„  LangGraphë¥¼ ì´ìš©í•˜ì—¬ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ì–´ì£¼ì—ˆë‹¤.

```
config = {"configurable": {"thread_id": "abc123"}}

query = "Hi! I'm Bob."

input_messages = [HumanMessage(query)]
output = app.invoke({"messages": input_messages}, config)
output["messages"][-1].pretty_print()  # output contains all messages in state

query = "What's my name?"

input_messages = [HumanMessage(query)]
output = app.invoke({"messages": input_messages}, config)
output["messages"][-1].pretty_print()
```
ì´ë ‡ê²Œ ìŠ¤ë ˆë“œë¥¼ ìƒì„±í•´ì„œ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆê³ , ë‹¤ë¥¸ ìŠ¤ë ˆë“œë¥¼ ë§Œë“¤ì–´ì„œ ìƒˆë¡œìš´ ëŒ€í™”ë¥¼ í•  ìˆ˜ ìˆë‹¤.

```
config = {"configurable": {"thread_id": "abc234"}}

input_messages = [HumanMessage(query)]
output = app.invoke({"messages": input_messages}, config)
output["messages"][-1].pretty_print()
```
`==================================[1m Ai Message [0m==================================`
`I'm sorry, but I don't have access to personal information about you unless you provide it. How can I assist you today?`

