### 페이지 요약 및 단계별 설명
### 1. 첫 번째 페이지(p.6)
**이 페이지에서 다루는 것은 무엇인가?**
- 왜 페이징을 사용해야 하는지에 대한 설명 제공
**페이지 내용 번역 및 간단한 설명**
- **Why paging?**
    - 두 가지 일반적인 비연속적 관리 접근 방식:
        - **가변 크기: 세그멘테이션**
            - 공유, 보호 지원
            - 주소 변환: 세그먼트 테이블(segement table) 사용
            - 그러나 메모리가 단편화(external fragmentation)되어 할당이 시간이 지남에 따라 어려워짐
        - **고정 크기: 페이징**
            - 외부 단편화 없음, 하드웨어 지원 용이 (예: TLB)
    - **페이징 용어**
        - 가상 메모리: 고정 크기의 단위(page)로 나뉨
        - 물리 메모리: 고정 크기의 단위(page frame)로 나뉨
        - 주소 변환: 페이지 테이블(page table) 사용
**페이지 내용 요약**
- 이 페이지는 비연속적 메모리 관리 방식을 소개하며, 세그멘테이션과 페이징 두 가지 방식을 설명합니다. 페이징은 외부 단편화 문제를 피하고 하드웨어 지원이 용이함을 강조합니다.
- 다이어그램은 가상 메모리와 물리 메모리 간의 페이지 테이블을 통한 변환 과정을 시각적으로 보여줍니다.
### 2. 두 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이징의 간단한 예시와 개요 설명
**페이지 내용 번역 및 간단한 설명**
- **Example of Paging**
    - **Virtual memory**
        - 프로세스의 작은 주소 공간: 총 크기 64B, 페이지 크기: 16B (주소 공간에 총 4 페이지)
    - **Physical memory**
        - 작은 물리적 메모리: 128B, 페이지 프레임 크기: 16B (총 8 프레임)
        - 프레임 0은 OS용
        - 프레임 2, 3, 5, 7은 프로세스용 (연속적이지 않음)
        - 나머지 프레임은 프리 리스트로 관리
**페이지 내용 요약**
- 이 페이지는 페이징의 간단한 예제를 통해 가상 메모리와 물리 메모리의 관계를 설명합니다. 특히 각 페이지의 크기와 할당 방식을 포함한 예시를 제공하며, 다이어그램을 통해 주소 공간과 실제 메모리 간의 매핑을 시각적으로 보여줍니다.
### 3. 세 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이지 테이블과 주소 변환 설명
**페이지 내용 번역 및 간단한 설명**
- **Page table**
    - 각 페이지가 물리 메모리의 어느 위치에 들어가는지 기록하는 데이터 구조(세그먼트 테이블과 같은 역할)
    - 프로세스별 데이터 구조
    - 주소 변환에 사용
        - 가상 주소: 4 -> 물리 주소: 3 x 16B + 4 = 52
        - 가상 주소: 44 -> 물리 주소: 5 x 16B + 12 = 92
        - 가상 주소: 21 -> 물리 주소: 7 x 16B + 5 = 117
**페이지 내용 요약**
- 이 페이지는 페이지 테이블의 역할과 그것이 주소 변환에 어떻게 사용되는지 간단한 예시를 통해 설명합니다.
- 다이어그램은 페이지 테이블을 사용하여 특정 가상 주소가 물리 메모리 내에서 어떻게 변환되는지를 시각적으로 보여줍니다.
  
  
### 페이지 요약 및 단계별 설명
### 4. 네 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 주소 변환의 형식적인 설명
**페이지 내용 번역 및 간단한 설명**
- **Address translation in formal**
    - **Address size**
        - 주소 공간 크기: 64B -> 가상 주소 크기: 6-bit (2^6 = 64B)
        - 물리 메모리 크기: 128B -> 물리 주소 크기: 7-bit (2^7 = 128B)
    - **Virtual address**: VPN(Virtual Page Number) 과 offset으로 구성
        - 페이지(및 프레임) 크기: 16B -> offset 크기: 4-bit. 결과적으로 남은 2비트는 VPN이 됨 (총 4 페이지 존재)
        - VPN은 페이지 테이블 검색에 사용: VPN -> PFN (Physical Frame Number)
    - **Physical address**
        - PFN x 페이지 크기 + offset (VPN은 변환, offset은 변환되지 않음)
    - **Example**
        - 가상 주소: 21 -> bit: 01 0101 -> VPN: 01, offset: 0101 -> PFN: 111 -> 111*16B + 0101 -> 물리 주소: 117
**페이지 내용 요약**
- 이 페이지는 주소 변환의 형식적 개념, 가상 주소와 물리 주소의 구성 및 변환 과정을 설명합니다.
- 다이어그램은 가상 주소(VPN과 offset)를 통해 물리 주소를 계산하는 과정을 시각적으로 보여줍니다.
### 5. 다섯 번째 페이지(p.10)
**이 페이지에서 다루는 것은 무엇인가?**
- 주소 변환 요약
**페이지 내용 번역 및 간단한 설명**
- **Address translation summary**
    - **주소 변환 요약**
        1. 가상 주소는 두 부분으로 나누어짐: 페이지 번호(p)와 오프셋(d)
            - 페이지 번호: 페이지 테이블의 인덱스로 사용 (VPN으로도 알려짐)
            - 오프셋: 프레임 내 물리 주소를 찾는 데 사용
        2. 각 페이지 테이블 엔트리(PT)는 프레임의 시작 주소(PFN)를 담고 있음
        3. 시작 주소와 오프셋을 조합 -> 물리 주소
**페이지 내용 요약**
- 이 페이지는 가상 주소에서 물리 주소로의 변환 과정을 요약합니다.
- 다이어그램은 CPU가 가상 주소를 물리 주소로 변환하는 과정을 시각적으로 보여줍니다.
### 6. 여섯 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이지 테이블의 관리 위치
**페이지 내용 번역 및 간단한 설명**
- **How to manage page table?**
    - 프로세스별 데이터 구조
    - 커널 공간의 PCB(또는 PCB와 연결된 별도의 데이터 구조)에 저장 -> 메모리에 저장됨
**페이지 내용 요약**
- 이 페이지는 각 프로세스의 페이지 테이블이 어디에 저장되며, 어떻게 관리되는지 설명합니다.
- 다이어그램은 PCB 및 페이지 테이블이 커널의 다른 데이터 구조와 어떻게 연관되는지를 시각적으로 보여줍니다.
### 7. 일곱 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이지 테이블 관리가 CPU가 아닌 메모리에서 이루어지는 이유
**페이지 내용 번역 및 간단한 설명**
- **Why in memory? (instead of CPU)**
    - 기본/한계 레지스터가 CPU에 있음
    - 페이지 테이블이 너무 크기 때문에:
        - 32-bit CPU, 페이지: 4KB -> 오프셋: 12-bit, VPN: 20-bit
        - PTE (Page Table Entry): 보통 4B
        - 2^20 엔트리 * 4B = 4MB 크기 (너무 커서 CPU에 다 들어갈 수 없음)
        - 100개의 프로세스 가정 시 -> 400MB 필요 -> 메모리에 배치해야 함
    - **두 가지 문제**
        1. 각 메모리 접근은 주소 변환을 요구 -> 페이지 테이블 액세스 요구 -> 페이지 테이블이 메모리에 있음
            - 각 메모리 접근이 두 번의 메모리 접근을 필요로 하는가? -> TLB (Translation Lookaside Buffer)로 해결
        2. 페이지 테이블이 커서 많은 매핑 정보가 필요 -> 다단계 페이지 테이블 또는 역 페이지 테이블로 해결
**페이지 내용 요약**
- 이 페이지는 페이지 테이블이 CPU가 아닌 메모리에 저장되는 이유와 그로 인한 문제와 해결 방법을 설명합니다.
### 8. 여덟 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이지 테이블의 실제 구성 요소
**페이지 내용 번역 및 간단한 설명**
- **Page table**
    - PTE(Page Table Entries)로 구성, 각 PTE는 페이지를 페이지 프레임에 매핑 (가상 주소를 물리 주소로 매핑)
    - 각 엔트리는 VPN으로 인덱싱됨
    - **추가 정보 비트**
        - P (Present bit): 해당 페이지가 물리 메모리에 있는지 디스크에 있는지
        - R/W (읽기/쓰기 비트): 쓰기가 허용되는지
        - U/S (사용자/감독자 비트): 사용자 모드 프로세스가 페이지에 접근할 수 있는지
        - A (접근 비트): 교체용
        - D (더러운 비트): 페이지가 수정되었는지
        - 기타 비트 (HW 캐싱 동작 방식 결정, 유효/유휴 여부, 보호 비트)
**페이지 내용 요약**
- 이 페이지는 페이지 테이블의 구조와 각 PTE가 포함하는 다양한 정보 비트에 대해 설명합니다.
- 다이어그램은 PTE의 구조를 이해하는 데 도움을 줍니다.
### 9. 아홉 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 메모리 접근 시 주소 변환 과정의 속도 문제
**페이지 내용 번역 및 간단한 설명**
- **To access memory (e.g. mov 21, %eax)**
    1. PTE 주소 찾기
    2. PTE 가져오기 /* 메모리에 접근 */
    3. 비트 체크
    4. 물리 주소 가져오기 /* 메모리에 다시 접근 */
**페이지 내용 요약**
- 이 페이지는 메모리 접근 시 주소 변환 과정이 어떻게 이루어지는지를 설명합니다.
- 다이어그램과 코드 예시는 주소 변환 과정의 상세 단계를 보여줍니다.
  
### 페이지 요약 및 단계별 설명
### 10. 열 번째 페이지(p.15)
**이 페이지에서 다루는 것은 무엇인가?**
- 메모리 트레이스 (Memory Trace)의 개요
**페이지 내용 번역 및 간단한 설명**
- **High-level viewpoint**
    
    ```C
    int array[1000];
    ...
    for (i = 0; i < 1000; i++)
        array[i] = 0;
    ```
    
- **Assembly viewpoint**
    
    ```Plain
    1024 movl $0x0, (%edi,%eax,4)
    1028 incl %eax
    1032 cmpl $0x03e8,%eax
    1036 jne  0x1024
    ```
    
- **Memory trace**
    - **Assumption**
        - 페이지/프레임 크기: 1KB (1024B)
        - 코드: VPN:1, PFN:4 (PA = 4*1024)
        - 배열: VPN:39, PFN:7 (PA = 7*1024)
        - PT: PA 1024에 위치
    - **Figure 18.7: 첫 번째 5번의 루프**
        - PT[1]은 명령어 주소용
        - 명령어 가져오기
        - PT[39]는 데이터 주소용
        - 데이터 가져오기
        - 각 루프 당 10번의 메모리 접근 발생 (4번은 명령어, 1번은 데이터, 5번은 PT)
**페이지 내용 요약**
- 이 페이지는 메모리 트레이스를 통해 코드 실행과 관련된 메모리 접근을 설명합니다.
- 다이어그램은 루프 실행 동안 발생하는 가상 및 물리 메모리 접근을 시각적으로 보여줍니다.
### 11. 열한 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- TLB(Translation Lookaside Buffer)를 통한 빠른 주소 변환
**페이지 내용 번역 및 간단한 설명**
- **TLB (Translation Lookaside Buffer)**
    - MMU (Memory Management Unit)의 일부로서 빠른 변환을 위해 사용
    - 최근 사용된 PTE를 캐시 (일반적으로 가상-물리 쌍) -> 주소 변환 캐시 역할
    - **변환 단계**
        1. 하드웨어가 먼저 TLB를 검사
        2. (히트 시) 빠른 변환, PT를 참조할 필요 없음
        3. (미스 시) PT 접근, PTE 갱신하여 TLB에 캐싱
**페이지 내용 요약**
- 이 페이지는 TLB의 역할과 주소 변환 과정을 설명하며, TLB를 사용하여 메모리 접근 시간을 줄이는 방법을 설명합니다.
- 다이어그램은 TLB와 페이지 테이블 간의 관계를 보여줍니다.
### 12. 열두 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- TLB의 기본 알고리즘
**페이지 내용 번역 및 간단한 설명**
- **How HW might handle an address translation?**
    - **히트** -> 한 번의 메모리 접근만 필요 (7번 라인)
    - **미스** -> 두 번의 접근 필요, 하나는 PTE용(12번 라인), 나머지는 데이터 접근용 (7번 라인 통해 19번 라인) + TLB 업데이트 (18번 라인)
    - **지역성**: 대부분의 접근은 TLB에서 히트
```Plain
1  VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2  (Success, TlbEntry) = TLB_Lookup(VPN)
3  if (Success == True) // TLB Hit
4      if (CanAccess(TlbEntry.ProtectBits) == True)
5          Offset = (VirtualAddress & OFFSET_MASK)
6          PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7          Register = AccessMemory(PhysAddr)
8      else
9          RaiseException(PROTECTION_FAULT)
10 else // TLB Miss
11     PTEAddr = PTBR + (VPN * sizeof(PTE))
12     PTE = AccessMemory(PTEAddr)
13     if (PTE.Valid == False)
14         RaiseException(SEGMENTATION_FAULT)
15     else if (CanAccess(PTE.ProtectBits) == False)
16         RaiseException(PROTECTION_FAULT)
17     else
18         TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
19         RetryInstruction()
```
**페이지 내용 요약**
- TLB 히트 시 한 번의 메모리 접근만으로 주소 변환이 이루어지며, 미스 시 두 번의 메모리 접근이 필요합니다.
- 코드 예시는 TLB 히트 및 미스 처리 과정을 보여줍니다.
  
### 페이지 요약 및 단계별 설명
### 13. 열세 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 배열 접근 시 예시 코드
**페이지 내용 번역 및 간단한 설명**
- **Example code**
    
    ```C
    int a[10];  // 4B x 10
    ```
    
    - 페이지 크기: 16B -> 최대 4개의 배열 항목
    - **Memory access behavior**
        - `a[0]` 접근 시 -> TLB 미스 -> 두 번의 메모리 접근
        - `a[1], a[2]` 접근 시 -> TLB 히트 -> 한 번의 메모리 접근
        - `a[3], a[7]` 접근 시 -> TLB 미스
        - `a[4], a[5], a[6], a[8], a[9]` 접근 시 -> TLB 히트
        - TLB 히트 비율: 70% (일반적으로는 > 99%)
```C
int sum = 0;
for (i = 0; i < 10; i++)
    sum += a[i];
```
**페이지 내용 요약**
- 페이지는 TLB 히트 및 미스를 설명하며, 예제 코드를 통해 배열 접근 시 각 메모리 접근이 어떻게 이루어지는지 설명합니다.
- 다이어그램은 배열 접근의 메모리 레이아웃을 시각적으로 보여줍니다.
### 14. 열네 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 캐싱의 중요성과 활용 방법
**페이지 내용 번역 및 간단한 설명**
- **Use caching when possible**  
    캐싱은 컴퓨터 시스템에서 가장 기본적이고 중요한 성능 기법 중 하나로, 데이터와 명령어 참조의 지역성을 이용.  
    - **Temporal locality**: 최근에 접근한 데이터나 명령어가 가까운 미래에 다시 접근될 가능성
    - **Spatial locality**: 특정 메모리 주소에 접근 후 그 근처 주소에 다시 접근할 가능성
    - 하드웨어 캐시는 작고 빠른 온칩 메모리를 사용하여 지역성을 이용.
    - 캐시가 빠를수록 비용이 높고, 필연적으로 제한된 크기의 캐시만이 실현 가능.
**페이지 내용 요약**
- 이 페이지는 캐시 이용의 중요성과 하드웨어 캐시가 프로그램의 지역성을 어떻게 이용하는지 설명합니다.
- 하드웨어 캐시의 한계와 그로 인한 성능 향상 방안을 강조합니다.
### 15. 열다섯 번째 페이지(p.20)
**이 페이지에서 다루는 것은 무엇인가?**
- TLB 미스의 처리 방안
**페이지 내용 번역 및 간단한 설명**
- **Two approaches**
    - **HW-managed TLB**
        - 하드웨어가 TLB 업데이트 포함 TLB 조작 로직을 가짐
        - 정확한 PT 형식 및 주소 형식을 알아야 함
        - 예: Intel CPU (CISC)
    - **SW-managed TLB**
        - 하드웨어가 단순히 예외를 발생
        - OS가 TLB를 명시적으로 관리 (TLB 트랩 핸들러)
        - 유연성 증가
        - 예: MIPS, Sun SPARC v9 (RISC)
```Plain
1  VPN = (VirtualAddress & VPN_MASK) >> SHIFT
2  (Success, TlbEntry) = TLB_Lookup(VPN)
3  if (Success == True) // TLB Hit
4      if (CanAccess(TlbEntry.ProtectBits) == True)
5          Offset = (VirtualAddress & OFFSET_MASK)
6          PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
7          Register = AccessMemory(PhysAddr)
8      else
9          RaiseException(PROTECTION_FAULT)
10 else // TLB Miss
11     PTEAddr = PTBR + (VPN * sizeof(PTE))
12     PTE = AccessMemory(PTEAddr)
13     if (PTE.Valid == False)
14         RaiseException(SEGMENTATION_FAULT)
15     else if (CanAccess(PTE.ProtectBits) == False)
16         RaiseException(PROTECTION_FAULT)
17     else
18         TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
19         RetryInstruction()
```
**페이지 내용 요약**
- 페이지는 하드웨어와 소프트웨어가 TLB 미스를 처리하는 두 가지 주요 접근 방식을 설명합니다.
- 코드 예시와 다이어그램은 각각의 접근 방식에서 TLB 미스가 발생할 때의 프로세스를 보여줍니다.
  
### 페이지 요약 및 단계별 설명
### 16. 열여섯 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- TLB 엔트리의 내용
**페이지 내용 번역 및 간단한 설명**
- **A TLB entry**
    - **구성 요소**
        - VPN + PFN + bits (32, 64 또는 128 비트)
    - **Bits**
        - 유효 비트(valid bit): 번역이 유효한지 아닌지
        - 보호 비트(protection bits): 읽기/쓰기/실행(R/W/E)
        - 기타 비트: ASID (Address-Space IDentifier), 더러운 비트(dirty bit)
    - **완전 연결형(Fully-associative)**
        - 어떤 엔트리도 배치 가능
    - **병렬 검색 가능(Search in parallel)**
**페이지 내용 요약**
- 이 페이지는 TLB 엔트리의 구성과 의미 있는 비트들을 설명합니다.
- 다이어그램은 TLB가 가상 주소를 물리 주소로 매핑하는 방법을 보여줍니다.
### 17. 열일곱 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 컨텍스트 스위칭 시 TLB 문제
**페이지 내용 번역 및 간단한 설명**
- **TLB**
    - 가상-to-물리 매핑을 포함
    - 현재 실행 중인 프로세스에 대해서만 유효
    - 컨텍스트 스위치 시 TLB 엔트리를 무효화하거나 구분 필요
    - **예시**
        - P1: VPN 10 -> PFN 100, P2: VPN 10 -> PFN 170
        - P1 실행 시 VPN 10 접근, P1에서 P2로 컨텍스트 스위칭(CS), P2 접근 시 문제 발생
        - **해결책**
            1. CS 전에 TLB 플러시 (모든 유효 비트를 0으로 설정)
            2. ASID 사용하여 구분
**페이지 내용 요약**
- 이 페이지는 TLB가 컨텍스트 스위칭 중 발생할 수 있는 문제와 그 해결책을 설명합니다.
- 예시와 다이어그램을 통해 문제 상황을 시각적으로 설명합니다.
### 18. 열여덟 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 페이지 테이블의 크기와 이를 줄이는 방법
**페이지 내용 번역 및 간단한 설명**
- **Page table**
    - **메모리에 위치**
        1. 메모리 접근 횟수 증가 -> TLB 사용 (19장에서 설명)
        2. 공간 오버헤드 -> 본 장 설명
    - **크기**
        - 32비트 주소 공간 (2^32), 4KB 페이지 크기 (2^12) -> PTE는 PT에 2^20개
        - PTE 크기: 4B -> PT 크기: 4MB
        - PT는 프로세스별로 관리 -> 100개의 프로세스가 있을 경우 400MB 필요 -> 메모리 부족 유발 가능
    - **작게 만드는 방법**
        - 더 큰 페이지 사용 (페이지 크기: 4KB -> 2MB, 이를 표시하여 높은 페이지)
        - 하이브리드 접근: 세그멘테이션 + 페이징
        - 다단계 페이지 테이블
        - 역 페이지 테이블
**페이지 내용 요약**
- 이 페이지는 페이지 테이블의 크기에 대해 논의하고, 이를 줄이는 다양한 방법을 제안합니다.
- 다단계 페이지 테이블과 역 페이지 테이블을 소개합니다.
  
### 페이지 요약 및 단계별 설명
### 19. 열아홉 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 더 큰 페이지를 사용하는 간단한 해결책 (선택사항)
**페이지 내용 번역 및 간단한 설명**
- **Bigger pages**
    - **32-bit 주소 공간 (2^32), PTE당 4B**
        - 4KB 페이지 크기 (2^12) -> PT의 PTE들은 2^20 -> PT 크기: 4MB
        - 8KB 페이지 크기 (2^13) -> PT의 PTE들은 2^19 -> PT 크기: 2MB
        - 4MB 페이지 크기 (2^22) -> PT의 PTE들은 2^10 -> PT 크기: 4KB
    - **장점**: 간단하고, TLB 히트에 긍정적인 효과
    - **단점**: 내부 단편화 (메모리 낭비), 로딩 시간 증가
    - **다양한 페이지 크기 지원**:
        - 동시에 4KB, 16KB, 4MB 지원 (예: 인텔의 큰 페이지 + 기본 페이지)
        - **장점**: 유연성, 더 적은 내부 단편화
        - **단점**: OS 복잡성 (진행 중)
**페이지 내용 요약**
- 이 페이지는 더 큰 페이지를 사용하는 방법과 그 장단점을 설명합니다. 또한 여러 크기의 페이지를 동시에 지원하여 유연성을 높이는 방안을 제안합니다.
### 20. 스무 번째 페이지(p.25)
**이 페이지에서 다루는 것은 무엇인가?**
- 하이브리드 접근: 페이징과 세그멘테이션 (선택사항)
**페이지 내용 번역 및 간단한 설명**
- **Hybrid approach**
    - **아이디어**: 세그먼트 내 정보 제한을 통해 PT 크기 축소
    - **간단한 예제**: 16KB 주소 공간, 1KB 페이지 크기
        - 4 페이지 사용 (코드 1, 힙 1, 스택 2)
        - 페이지 프레임 10, 23, 28, 4에 각각 배치
    - **페이징만**: Fig. 20.2 - 16 PTE, 대부분 무효
    - **하이브리드 접근**
        - 코드: base = 0, limit = 1K -> 1 PTE
        - 힙: base = 4K, limit = 5K -> 1 PTE
        - 스택: base = 14K, limit = 16K -> 2 PTE
        - 한계 레지스터가 유효한 페이지 추적
**페이지 내용 요약**
- 이 페이지는 하이브리드 접근 방식을 사용하여 페이지 테이블 크기를 줄이는 방법을 설명합니다. 예제를 통해 비연속적인 메모리 배치를 설명합니다.
### 21. 스물한 번째 페이지
**이 페이지에서 다루는 것은 무엇인가?**
- 하이브리드 접근법: 페이징과 세그멘테이션 (선택사항)
**페이지 내용 번역 및 간단한 설명**
- **Hybrid approach**
    - **Intel CPU 예시**
        - 가상 주소 -> 세그멘테이션 -> 선형 주소
        - 선형 주소 -> 페이징 -> 물리 주소
**페이지 내용 요약**
- 이 페이지는 Intel CPU의 하이브리드 접근 방식을 설명합니다. 세그멘테이션 단계를 거쳐 선형 주소를 얻고, 이를 다시 페이징하여 물리 주소로 변환하는 과정을 다룹니다.
  
### 1. 이 페이지에서 다루는 것은 무엇인지 짧게 요약
이 페이지들은 운영체제의 페이지 테이블 관리에서 다단계 페이지 테이블(Multi-level Page Table)의 개념을 다룹니다. 구체적으로 다단계 페이지 테이블의 아이디어, 메모리 공간 절약에 관한 예제, 그리고 주소 변환 절차에 대해 설명합니다.
### 2. 페이지 내용 번역 및 간단한 설명
### 첫 번째 슬라이드(p.27)
- **아이디어**: 선형 페이지 테이블과 다단계 페이지 테이블을 비교한 그림. 선형 페이지 테이블은 단일 레벨로, 모든 페이지 테이블 엔트리를 포함한다. 반면, 다단계 페이지 테이블은 페이지 디렉토리와 여러 페이지 테이블 레벨로 나누어져 있어 공간을 절약할 수 있다.
    
    - 선형 테이블 대신 구조적 페이지 테이블을 사용하여 다단계 테이블을 구성.
    - 페이지 디렉토리: 각 엔트리는 관련된 페이지 테이블을 나타냄.
    - 페이지 디렉토리의 유효 비트를 사용하여 할당되지 않은 많은 페이지 테이블을 줄일 수 있음.
    
    [![](https://www.notion.so1)](https://www.notion.so1)
    
### 두 번째 슬라이드
- **예제: PT를 위해 얼마나 많은 메모리 공간을 줄일 수 있습니까?**
    
    - 주소 공간: 16KB (14비트), 페이지 크기: 64B (6비트) -> 256 PTEs (8비트)
        - 코드, 힙, 스택에 사용되는 페이지들 (0, 1, 4, 5, 254, 255) 가정.
    - 페이지들이 각각 프레임 10, 23, 80, 59, 55, 45에 할당됨.
    - 선형 접근법에서는 총 256개의 PTE들 -> 16개의 프레임 필요.
    - 다단계 접근법에서는 1 디렉토리 + 2 마지막 레벨 PTs -> 3 프레임 필요.
    
    ![Diagram Explanation](Figure 20.4 and 20.5): 64-byte 페이지를 가진 16KB 주소 공간과 이를 위한 다단계 페이지 테이블 예제. 페이지 디렉토리와 페이지 테이블 조각의 구조를 보여줌.
    
### 세 번째 슬라이드
- **주소 변환**
    
    - 가상 주소는 세 부분으로 나뉨: 디렉토리 인덱스, PT 인덱스, 오프셋 (원래는 두 부분: VPN, 오프셋)
        - 가상 메모리 크기: 16KB -> 14비트 주소.
        - 페이지 크기: 64B -> 오프셋 비트: 6비트.
        - 프레임의 PTE들: 16개 -> PT 인덱스: 4비트.
        - 디렉토리의 PTE들: 16개 -> 디렉토리 인덱스: 4비트.
    
    ![Diagram Explanation](Figure 20.5): 페이지 디렉토리, 페이지 테이블 인덱스 그리고 예제 주소 변환 값들. 가상 주소를 물리 주소로 변환하는 과정의 예제들을 포함함.
    
### 3. 페이지 내용 요약
이 자료는 운영체제에서 다단계 페이지 테이블의 개념을 설명합니다. 선형 페이지 테이블과 비교하여 다단계 페이지 테이블이 어떻게 메모리 공간을 절약할 수 있는지 예를 들어 설명합니다. 또한, 가상 주소가 어떻게 디렉토리 인덱스, 페이지 테이블 인덱스 및 오프셋의 세 부분으로 나뉘며, 이것이 주소 변환에 어떻게 활용되는지 다룹니다.
  
### 1. 이 페이지에서 다루는 것은 무엇인지 짧게 요약
이 페이지들은 운영체제의 다단계 페이지 테이블의 심화와 반전 페이지 테이블(Inverted Page Table)에 대해 다룹니다. 다단계 페이지 테이블에서는 여러 레벨의 페이지 테이블 구성을 통해 메모리 사용을 최적화하는 방법을 설명합니다. 반전 페이지 테이블에서는 시스템 전반에서 페이지 테이블의 크기를 줄이는 방법을 다룹니다.
### 2. 페이지 내용 번역 및 간단한 설명
### 세 번째 슬라이드(p.30)
- **주소 변환**
    
    - 가상 주소는 세 부분으로 나뉨: 디렉토리 인덱스, PT 인덱스, 오프셋 (원래 두 부분: VPN, 오프셋 대신)
        - 가상 메모리 크기: 16KB -> 14비트 주소
        - 페이지 크기: 64B -> 오프셋 비트: 6비트
        - 프레임의 PTE들: 16개 -> PT 인덱스: 4비트
        - 디렉토리의 PTE들: 16개 -> 디렉토리 인덱스: 4비트
    
    ![Diagram Explanation](Figure 20.5): 페이지 디렉토리 인덱스, 페이지 테이블 인덱스 및 페이지 디렉토리의 PTE 구조를 나타내는 표와 다양한 가상 주소 예시가 물리 주소로 변환되는 과정을 보여줌
    
### 네 번째 슬라이드
- **두 개 이상의 레벨**: 2단계와 3단계 페이지 테이블 구성. 각각의 레벨을 통해 메모리 최적화 방법을 설명
    
    - 가상 주소: 30비트, 페이지 크기: 512B
        - 주소: 30비트, 오프셋: 9비트 -> VPN: 21비트, 페이지의 PTE들: 128 (512/4)
        - 2단계: 왼쪽 그림
            - PT 인덱스 = 7비트 (2^7 = 128), 페이지 디렉토리: 남은 14비트 커버 필요 -> 2^14 PTE들 -> 페이지 디렉토리당 128 페이지 필요
        - 3단계: 오른쪽 그림
            - PT 인덱스 = 7비트, PD 인덱스0 = 7비트 (상위 레벨), PD 인덱스1 = 7비트 -> PD 인덱스0와 PD 인덱스1은 유효한 PTE들만 필요 -> 메모리 절약
        - Intel: 32비트 -> 2단계, 64비트 -> 4단계
    
    [![](https://www.notion.soFigure)](https://www.notion.soFigure)
    
### 다섯 번째 슬라이드
- **페이지 테이블**
    - VPN -> PFN, 시스템 내 프로세스당 하나씩
- **반전 페이지 테이블**: 반전 페이지 테이블 구조와 주소 변환 절차. 물리 메모리와 관련된 검색 과정을 보여줌.
    
    - PFN -> VPN, 시스템 내 하나만 존재 (따라서 PT 메모리 절감)
        - 페이지 테이블 인덱스: 물리 프레임 번호 (물리 페이지당 하나의 엔트리)
        - PTE: 가상 페이지 번호, 물리 페이지를 매핑하는 프로세스 ID
    - **주소 변환**
        - 검색 필요:
            - 선형 스캔
            - 해시
    
    [![](https://www.notion.soFigure)](https://www.notion.soFigure)
    
### 3. 페이지 내용 요약
자료는 다단계 페이지 테이블의 구조와 주소 변환 방식, 그리고 반전 페이지 테이블을 다룹니다. 다단계 페이지 테이블에서는 더 많은 레벨을 사용하여 메모리를 최적화하고, 반전 페이지 테이블은 시스템 전체에서 페이지 테이블의 메모리 사용량을 줄입니다. 다양한 예제와 다이어그램을 통해 이를 시각적으로 설명합니다.
  
### 1. 이 페이지에서 다루는 것은 무엇인지 짧게 요약
이 페이지들은 물리적 메모리 이상의 메모리 사용 메커니즘을 설명합니다. 메모리 계층 구조, 스왑 공간, 프레젠트 비트와 페이지 폴트 처리에 대해 다루며, 다이어그램을 통해 시각적으로 설명합니다.
### 2. 페이지 내용 번역 및 간단한 설명
### 첫 번째 슬라이드(p. 33)
- **메모리 계층 구조**
    - 레지스터, 캐시, 메모리, 디스크 (또는 SSD), 서버 등
    - 가상 메모리(VM)는 메모리와 디스크에 중점을 둠
        - 메모리: 상대적으로 빠르지만 작음
        - 디스크: 상대적으로 느리지만 큼
    - 운영체제는 동시에 여러 프로세스를 실행하기를 원함
        - 자주 접근되는 데이터는 메모리에 배치
        - 드물게 접근되는 데이터는 디스크에 배치하고 필요 시 메모리로 가져옴 (수요 로딩 또는 수요 페이징)
![Diagram Explanation](Memory Hierarchy): 메모리 계층 구조와 가상 메모리, 물리적 메모리를 나타내는 다이어그램. 작은 비용 높은 계층에서 큰 비용 낮은 계층으로 메모리 계층을 나타냄.
### 두 번째 슬라이드
- **스왑 정의**
    
    - 페이지를 디스크로 옮기는 공간
        - 메모리 공간이 부족할 때 데이터를 메모리에서 디스크로 이동
        - 이동 단위: 페이지 vs. 프로세스
            - 메모리 여유 시: 페이지, 메모리 부족 시: 프로세스
            - 교체 정책: LRU 페이지, 낮은 우선순위 프로세스 등
    - 예: 4개의 프레임과 8-페이지 스왑 공간
        - Proc 0/1/2 -> 준비 또는 실행 중, Proc 3 -> 중단 (스왑 아웃)
    
    ![Diagram Explanation](Figure 21.1): 물리 메모리와 스왑 공간의 구조와 개별 페이지 또는 프로세스를 스왑 아웃하는 과정을 나타내는 그림.
    
- **혜택**
    - 큰 가상 메모리를 제공할 수 있음 (일반적으로 물리적 메모리보다 큼)
    - 프로그래머에게는 투명함 (vs. 메모리 오버레이)
### 세 번째 슬라이드
- **프레젠트 비트**
    - PTE에서 페이지가 메모리에 있는지 스왑 아웃되었는지 확인
        - 프레젠트 비트 == 1, 페이지에 접근 가능
        - 프레젠트 비트 == 0, 페이지 폴트 발생
- **페이지 폴트**: 페이지 폴트 처리 과정을 나타내는 그림. 페이지 폴트 발생 시 페이지 폴트 처리자가 작업을 어떻게 처리하는지 보여줌.
    
    - 페이지 폴트 처리자가 페이지를 디스크에서 메모리로 가져옴
        - 스왑 공간 또는 파일에서 (예: 수요 로딩)
    
    [![](https://www.notion.soFigure)](https://www.notion.soFigure)
    
### 3. 페이지 내용 요약
1. **메모리 계층 구조**:
    - 레지스터, 캐시, 메모리, 디스크 등의 계층 구조를 설명하며 메모리와 디스크가 가상 메모리에서 중요한 역할을 함.
2. **스왑 공간**:
    - 메모리 부족 시 데이터를 디스크로 이동하는 스왑 공간의 역할과 교체 정책을 설명.
3. **프레젠트 비트와 페이지 폴트**:
    - PTE에서 프레젠트 비트를 통해 페이지의 메모리 상태를 확인하고, 페이지 폴트 발생 시 처리 과정을 설명.
이 슬라이드 세트는 운영체제의 메모리 관리 기술을 설명하며, 메모리 계층 구조와 관련된 다양한 개념을 다룬다.
  
### 이미지 1: Page Fault Control Flow (페이지 폴트 제어 흐름) p.36
1. **이 페이지에서 다루는 것:**
    - 페이지 폴트 제어 흐름에 대한 하드웨어(HW) 및 소프트웨어(SW) 제어 흐름.
2. **페이지 내용 번역 및 간단한 설명:**
    - **HW 제어 흐름:**
        
        ```Plain
        VPN = (VirtualAddress & VPN_MASK) >> SHIFT
        if (Success == True)
            if (CanAccess(TlbEntry.ProtectBits) == True)
                Offset = (VirtualAddress & OFFSET_MASK)
                PhysAddr = (TlbEntry.PFN << SHIFT) | Offset
                Register = AccessMemory(PhysAddr)
            else
                RaiseException(PROTECTION_FAULT)
        else
            if (ValidEntry == True)
                PTEAddr = PTBR + (VPN * sizeof(PTE))
                PTE = AccessMemory(PTEAddr)
                if (PTE.Valid == False)
                    RaiseException(SEGMENTATION_FAULT)
                else
                    if (CanAccess(PTE.ProtectBits) == False)
                        RaiseException(PROTECTION_FAULT)
                    else
                        if (PTE.Present == True)
                            TLB_Insert(VPN, PTE.PFN, PTE.ProtectBits)
                            RetryInstruction()
                        else
                            RaiseException(PAGE_FAULT)
        ```
        
        - **TLB 조회(TLB Lookup):** 가상 주소를 매핑하는 과정.
        - **페이지 테이블 조회(Page Table Lookup):** TLB 미스 시 옵셋 계산과 페이지 테이블 항목액세스.
        - **예외 처리(Exception Handling):** 보호 오류와 세그먼테이션 오류 감지.
    - **SW 제어 흐름:**
        
        ```Plain
        PFN = FindFreePhysicalPage()
        if (PFN == -1)
            PFN = EvictPage()
            DiskRead(PTE.DiskAddr, pfn)
        PTE.Present = True
        PTE.PFN = PFN
        RetryInstruction()
        ```
        
        - **프레임 찾기(FindFreePhysicalPage):** 물리 페이지를 찾아 프레임을 할당.
        - **디스크 읽기(DiskRead):** 페이지를 디스크에서 메모리로 로드.
        - **페이지 테이블 업데이트(Page Table Update):** 페이지 테이블 항목 갱신 및 명령 재실행.
    - **다이어그램 설명:**
        - 하드웨어 및 소프트웨어 제어 흐름을 통해 페이지 폴트를 처리하는 과정을 설명한 코드 조각을 포함합니다.
3. **페이지 내용 요약:**
    - 페이지 폴트 제어 흐름의 하드웨어 및 소프트웨어 처리 방법 설명. 주요 단계로는 TLB 조회, 페이지 테이블 조회, 예외 처리 및 디스크에서 페이지를 읽어오는 과정이 있습니다.
### 이미지 2: Beyond Physical Memory: Policies (물리적 메모리를 넘어서: 정책들)
1. **이 페이지에서 다루는 것:**
    - 수요 페이징(Demand Paging)과 메모리 부족 시 대처 방안.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Demand Paging (수요 페이징):**
        - 실제 로딩 없이 매핑 정보를 생성하여 빠른 실행.
        - 실행 중 페이지 폴트 발생 시 필요한 페이지만 로드.
        - 많은 자유 프레임이 있을 때 유리.
    - **메모리 부족 시:**
        - 메모리 압박으로 인해 운영체제는 공간 확보를 위해 페이징을 강제.
        - 교체 정책: 어떤 페이지를 교체할지 결정.
    - **다이어그램 설명:**
        - MRU에서 LRU 사이를 이동하는 페이지 블록 및 데이터 블록을 보여주는 다이어그램 포함.
3. **페이지 내용 요약:**
    - 수요 페이징이란 필요한 페이지만 로드하여 효율성을 높이는 방법이며, 메모리가 부족할 때 운영체제는 교체 정책을 통해 페이지를 교체합니다.
### 이미지 3: Cache Management (캐시 관리)
1. **이 페이지에서 다루는 것:**
    - 캐시 관리의 목표와 모델.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Goal (목표):**
        - 캐시 히트를 극대화하고 캐시 미스를 최소화합니다.
    - **Model (모델):**
        
        - 평균 메모리 접근 시간(AMAT):
        
        ```Plain
        AMAT = (P_Hit * T_M) + (P_Miss * T_D)
        ```
        
        - P_Hit: 캐시에서 데이터 찾기의 확률.
        - T_M: 메모리 접근 시간.
        - T_D: 디스크 접근 시간.
    - **예시:**
        - T_M = 100ns, T_D = 10ms(10,000,000ns) 가정.
        - P_Hit 50%: AMAT = 0.5 * 100 + 0.5 * 10,000,000 = 5ms.
        - P_Hit 90%: AMAT = 0.9 * 100 + 0.1 * 10,000,000 = 1ms.
        - P_Hit 99%: AMAT = 0.99 * 100 + 0.01 * 10,000,000 = 0.1ms.
    - **Hit Ratio:** 중요 지표로서, 지역성을 기억해 높은 히트 비율 획득이 가능합니다.
3. **페이지 내용 요약:**
    
    - 캐시 관리의 목표는 캐시 히트를 극대화하고 미스를 최소화하는 것입니다. 평균 메모리 접근 시간(AMAT)을 통해 서비스 성능을 평가하며, 높은 히트 비율이 중요합니다.
    
      
    
### 이미지 4: Optimal Replacement Policy (최적 교체 정책)
1. **이 페이지에서 다루는 것:**
    - 최적 페이지 교체 정책의 개념과 예시.
2. **페이지 내용 번역 및 간단한 설명:**
    - **최적 교체 정책 (MIN):**
        - 미래에 가장 늦게 접근될 페이지를 교체합니다.
        - 가장 좋은 교체 정책이지만 구현이 불가능합니다 (비교 목적으로 유용).
    - **예시:**
        - 참조 문자열: `0 1 2 0 1 3 0 3 1 2 1`
        - 캐시 크기: 3 프레임
        - 히트 비율 = 6/11 = 54.5%
        - 유형별 미스:
            - 강제 미스 (Cold-start miss)
            - 용량 미스
            - 충돌 미스 (Direct mapping 또는 set-associative 경우)
    - **다이어그램 설명:**
        - 참조 문자열을 따라가며 히트/미스와 캐시 상태의 변화를 보여줍니다.
3. **페이지 내용 요약:**
    - 최적 교체 정책은 이론적으로 가장 좋은 페이지 교체 방법이지만, 구현이 불가능합니다. 예시를 통해 참조 문자열과 히트 비율을 설명합니다.
### 이미지 5: A Simple Policy: FIFO (단순 정책: FIFO)
1. **이 페이지에서 다루는 것:**
    - FIFO(First In First Out) 페이지 교체 정책의 개념과 예시.
2. **페이지 내용 번역 및 간단한 설명:**
    - **FIFO:**
        - 처음 메모리에 들어온 페이지를 먼저 교체합니다.
        - FCFS(First Come First Serve) 스케줄링 정책과 유사합니다.
    - **예시:**
        - 동일한 참조 문자열 (0 1 2 0 1 3 0 3 1 2 1) 사용.
        - 히트 비율 = 4/11 = 36.4%
    - **장점:**
        - 단순합니다.
    - **단점:**
        - 지역성을 고려하지 않으며, Belady's anomaly (캐시 크기가 클수록 히트 비율이 낮아짐) 발생 가능.
        - 예시 참고: 1, 2, 3, 4, 1, 2, 5, 1, 2, 3, 4, 5 (프레임 3 및 4개일 경우).
    - **다이어그램 설명:**
        - 참조 문자열을 따라가며 히트/미스와 캐시 상태의 변화를 보여줍니다.
3. **페이지 내용 요약:**
    - FIFO 페이지 교체 정책은 처음 들어온 페이지를 먼저 교체하는 간단한 방법이지만, 지역성을 고려하지 않기 때문에 효율성이 떨어질 수 있습니다.
### 이미지 6: Another Simple Policy: Random (또 다른 단순 정책: 랜덤)
1. **이 페이지에서 다루는 것:**
    - 랜덤(Random) 페이지 교체 정책의 개념과 예시.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Random:**
        - 무작위로 선택한 페이지를 교체합니다.
    - **예시:**
        - 동일한 참조 문자열 (0 1 2 0 1 3 0 3 1 2 1) 사용.
        - 히트 비율 = 5/11 = 45.4%
        - 각 시도마다 다른 결과 발생 가능 (다이어그램 참고).
    - **장점:**
        - 단순합니다.
    - **단점:**
        - 지역성을 고려하지 않으며 예측할 수 없습니다.
    - **다이어그램 설명:**
        - 참조 문자열을 따라가며 각 액세스 시 히트/미스와 캐시 상태 변화를 보여주고, 히트 빈도에 따른 그림 포함.
3. **페이지 내용 요약:**
    
    - 랜덤 페이지 교체 정책은 무작위로 교체할 페이지를 선택하는 간단한 방법이지만, 예측이 어렵고 지역성을 고려하지 않기 때문에 효율적인 방법은 아닙니다.
    
      
    
### 이미지 7: Using History: LRU (역사 사용: LRU)
1. **이 페이지에서 다루는 것:**
    - LRU(Least Recently Used) 페이지 교체 정책의 개념과 예시.
2. **페이지 내용 번역 및 간단한 설명:**
    - **LRU (Least Recently Used):**
        - 과거에 가장 오래된 페이지를 교체합니다.
        - 예시: 동일한 참조 문자열 (0 1 2 0 1 3 0 3 1 2 1) 사용.
        - 히트 비율 = 6/11 = 54.5%
    - **장점:**
        - 시간적 지역성(Temporal Locality)을 고려합니다.
    - **단점:**
        - 루프 참조에는 적합하지 않습니다.
    - **다이어그램 설명:**
        - 참조 문자열을 따라가며 히트/미스와 캐시 상태의 변화를 보여줍니다.
    - **History based policies:**
        - 역사 기반 정책 (다단계 피드백 큐와 같은) 사용.
        - LRU, LFU (Least Frequently Used), LRFU (Least Recently/Frequently Used), MRU (Most Recently Used), ARC (Adaptive Replacement Cache), 2Q 등 다양한 정책 포함.
3. **페이지 내용 요약:**
    - LRU 페이지 교체 정책은 시간적 지역성을 고려하여 과거에 가장 오래된 페이지를 교체하는 방법으로, 비교적 높은 히트 비율을 가집니다.
### 이미지 8: Workload Examples (작업 부하 예제)
1. **이 페이지에서 다루는 것:**
    - 다양한 작업 부하 사례와 각 페이지 교체 정책의 성능 분석.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Workload analysis (작업 부하 분석):**
        - 작업 부하: 작업의 양, 참조 특성
        - 세 가지 유형의 작업 부하:
            - **No-locality (비지역성):** LRU = FIFO = RAND
            - **80-20 작업 부하 (핫/콜드 비율:** LRU > FIFO = RAND
            - **루프 작업 부하:** LRU = FIFO < RAND
    - **일반적인 응용 프로그램:**
        - 강한 지역성을 보임 -> LRU가 일반적으로 사용됨.
        - 큰 캐시 크기: 최적에 가까운 성능.
    - **다이어그램 설명:**
        - No-locality, 80-20, Looping-Sequential 세 가지 작업 부하에 대한 히트율과 캐시 크기의 관계를 보여줍니다.
3. **페이지 내용 요약:**
    - 다양한 작업 부하에 따른 페이지 교체 정책의 성능을 분석한 결과, 대부분의 응용 프로그램은 강한 지역성을 보여 LRU가 효과적입니다.
### 이미지 9: Implementing Historical Algorithms (역사적 알고리즘 구현)
1. **이 페이지에서 다루는 것:**
    - LRU 구현 방법 및 관련 고려사항.
2. **페이지 내용 번역 및 간단한 설명:**
    - **LRU 구현 방법:**
        - 보통 링크드 리스트(linked list)를 사용합니다.
        - 페이지 액세스:
            - 리스트의 헤드(MRU 위치)에 삽입
            - 모든 페이지를 다음 위치로 이동
            - 필요 시 LRU 위치의 페이지 제거 (미스 발생 시)
    - **모든 메모리 접근을 모니터링 필요:**
        - 파일 캐시 또는 서버 캐시에서 사용 가능.
        - 메모리 캐시 성능 저하 가능:
            - 하드웨어 지원 이용: 참조 비트, 더티 비트 등.
    - **다이어그램 설명:**
        - 참조 비트와 더티 비트를 사용한 LRU 알고리즘의 링크드 리스트 구현 예시를 보여줌.
3. **페이지 내용 요약:**
    
    - LRU를 구현하는 방법은 일반적으로 링크드 리스트를 사용하며, 페이지 액세스를 모니터링하여 필요한 경우 가장 오래된 페이지를 교체하는 방식입니다. 하드웨어 지원을 활용할 수도 있습니다.
    
      
    
### 이미지 10: Approximating LRU (LRU 대체 알고리즘)
1. **이 페이지에서 다루는 것:**
    - LRU 대체 알고리즘을 근사하는 Clock 알고리즘의 개념과 작동 방식.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Clock algorithm (Clock 알고리즘):**
        - 참조 비트를 사용하는 FIFO 알고리즘 (액세스 비트라고도 함).
        - 하드웨어: 관련 페이지에 접근하면 참조 비트를 1로 설정합니다.
        - 운영체제: 다음 희생자 포인터를 관리합니다.
            - `ref_bit == 1`인 경우 초기화하고 다음 페이지에서 두 번째 기회를 제공합니다.
            - `ref_bit == 0`인 경우 교체하고 희생자 포인터를 다음 페이지로 이동시킵니다.
        - LRU를 근사합니다.
    - **고급 버전:**
        - 주기적으로 초기화.
        - 두 개의 하드웨어 비트 사용: 참조 비트와 더티 비트.
    - **다이어그램 설명:**
        - 다이얼 형태의 시계 그림을 통해 Clock 알고리즘의 작동 방식을 설명합니다.
        - 80-20 작업 부하에 대한 히트율 및 캐시 크기 비교 그래프도 포함됩니다.
3. **페이지 내용 요약:**
    - Clock 알고리즘은 참조 비트를 사용하는 FIFO 방식으로, LRU를 잘 근사하는 방법입니다. 이 알고리즘은 효율적이며, 주기적 초기화와 두 개의 하드웨어 비트를 활용하여 성능을 향상시킬 수 있습니다.
### 이미지 11: Thrashing (스래싱)
1. **이 페이지에서 다루는 것:**
    - 스래싱의 개념과 그로 인한 결과.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Thrashing (스래싱):**
        - 각 프로세스가 충분한 프레임을 가지지 못해 페이지 폴트 비율이 매우 높은 상황.
        - 페이지 폴트가 곧 참조될 페이지로 교체되며, 이는 또 다른 페이지 폴트를 유발합니다.
        - 프로세스가 실행 시간보다 페이징에 더 많은 시간을 소비합니다.
    - **다이어그램 설명:**
        - 멀티프로그래밍의 정도와 CPU 이용률 간의 관계 그래프. 스래싱 구간에서는 CPU 이용률 급락을 보여줌.
3. **페이지 내용 요약:**
    - 스래싱은 페이지 폴트 비율이 높아져 실행 시간이 급격히 줄어드는 현상으로, 프로세스가 대부분의 시간을 페이지 교체에 소비하게 됩니다.
### 이미지 12: Thrashing - Working Set (작업 집합)
1. **이 페이지에서 다루는 것:**
    - 작업 집합(Working Set)의 개념과 스래싱을 방지하는 방법.
2. **페이지 내용 번역 및 간단한 설명:**
    - **Working set (작업 집합):**
        - t-Δ와 t 사이에 참조된 페이지들의 집합.
        - 프로세스가 필요한 메모리 양을 추정하는 데 사용.
    - **작업 집합의 응용:**
        - 스래싱 감지 및 새로운 프로세스 시작 가능성 탐색.
        - 메커니즘: D > m 일 때 스래싱 발생.
            - WSSᵢ: 프로세스 Pᵢ의 작업 집합 크기.
            - D: 프로세스의 총 프레임 수 요구 (D = Σ WSSᵢ).
            - m: 시스템에서 사용 가능한 총 프레임 수.
    - **작업 집합 전략:**
        - D > m 일 때, 일부 프로세스 중단.
        - D < m 일 때, 다른 프로세스 시작 가능.
        - 멀티프로그래밍 수준을 최대한 유지하면서 스래싱을 방지.
    - **다이어그램 설명:**
        - 시간 t1과 t2 사이의 페이지 참조 양상을 보여 페이지 참조 테이블을 통해 작업 집합을 시각화.
3. **페이지 내용 요약:**
    - 작업 집합(Working Set)은 각 프로세스가 필요한 메모리 양을 추정하여 스래싱을 방지하는데 사용되며, 시스템의 멀티프로그래밍 수준을 유지할 수 있도록 돕습니다.