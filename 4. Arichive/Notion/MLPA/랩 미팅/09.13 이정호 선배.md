## 오늘 한 이야기💡
  
## 세미나☑️
#### 딥러닝&파이썬 용어 정리
|책 이름|챕터/날짜|이름|설명|
|---|---|---|---|
|세미나|07.25|[[제프리 힌튼]]|영국의 컴퓨터 과학자이다. 1986년의 다층 퍼셉트론과 (오차)역전파 [알고리즘](https://namu.wiki/w/%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)을 증명, 2006년의 심층신뢰 신경망 발표로 [딥러닝](https://namu.wiki/w/%EB%94%A5%EB%9F%AC%EB%8B%9D)을 [인공신경망](https://namu.wiki/w/%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D) 방법론의 대세로 굳히고 [GPU](https://namu.wiki/w/GPU)를 통한 병렬연산을 업계에 대중화시킨 선구자이다.|
|세미나|07.25|[[ResNet]]|Backbone 아키텍처 중 하나이다.|
|세미나|07.25|[[Attention 메커니즘]]|기존 인코더-디코더 구조에서 정보 손실이 발생할 수 있는 문제를 해결한 개선안.(자세한 내용은 설명 참고)|
|세미나|07.25|[[인코더-디코더 구조]]|설명 참고|
|세미나|07.25|[[Operation Study]]|Operations Study는 특정 시스템이나 프로세스의 효율성을 평가하고 향상시키기 위한 연구. 시뮬레이션, 최적화 기법, 보고서 작성을 포함하며 주로 논문 Operation Study 해봤어? 라고 물으면 수학적 근거가 부족한 논문 등에서 실제로 실험을 해봤냐는 의미로 쓰인다.|
|세미나|07.25|[[Context Vector]]|자연어 처리 모델의 구조 중 하나인 인코더-디코더 구조에서 인코더가 입력 시퀀스를 처리하여 생성하는 고정된 길이의 벡터이다. 이 벡터는 입력 시퀀스의 중요한 정보를 요약하여 디코더에 전달합니다.|
|세미나|07.25|[[Convolution]]|CNN에서 C. 합성곱이라는 뜻이다.|
|세미나|07.25|[[Backbone]]|신경망에서 주로 특징 추출을 담당하는 기본 네트워크 구조이다. 특징 추출과 전이 학습의 역할을 한다.|
|세미나|07.25|[[Interpolate]]|주어진 데이터 포인트들 사이의 빈 공간을 채워서 연속적인 값을 추정하는 과정이다.|
|세미나|08.01|[[Domain generalization]]|머신러닝 및 컴퓨터 비전 분야에서의 기법으로, 모델이 특정 학습 도메인에서 학습한 후, 보지 못한 새로운 도메인에서도 잘 일반화할 수 있도록 하는 접근입니다.|
|세미나|08.01|[[그래픽스 파이프라인]]|3D 장면을 렌더링하여 2D 이미지로 변환하는 과정에서 거치는 일련의 단계를 의미한다.|
|세미나|08.01|[[Adaptive Density Control(ADC)]]|3D 그래픽스와 비전 관련 분야에서 사용하는 기술로, 장면의 밀도를 동적으로 조절하여 렌더링 품질과 효율성을 개선하는 방법|
|세미나|08.01|[[Fast Differentiable Rasterization]]|컴퓨터 그래픽스와 인공지능 분야에서 사용되는 기법으로, 그래픽스 파이프라인의 라스터화 단계에서 미분 가능성을 제공하는 방법이다.|
|세미나|08.01|[[Volume density]]|파티클의 투명도. Ray가 오브젝트를 통과하는 중 파티클의 위치하는데 그 순간 파티클의 투명도를 의미한다. 예를 들어 통과하는 중인 파티클은 오브잭트 내부라서 투명도가 낮다.|
|세미나|08.01|[[SfM]]|Structure from Motion, 여러 장의 2D 이미지의 정보를 통해 전체적인 3D 구조와 카메라 pose를 추정하는 기법|
|세미나|08.01|[[NeRF]]|Neural Radiance Fields는 3D 장면을 효율적으로 표현하고 렌더링하기 위한 딥러닝 기술이다. NeRF는 주로 2D 이미지 시퀀스를 입력으로 받아들여, 장면의 3D 구조와 재질을 학습하여 새로운 시점에서 이미지를 생성하는 능력을 가지고 있다.|
|세미나|08.01|[[Plenoptic]]|진정한 의미의 홀로그램이 완성되기 전에 사람들이 홀로그램처럼 콘텐츠를 감상할 수 있도록 입체 영상을 촬영, 처리, 영사하는 기술이다.|
|세미나|08.22|[[Intrinsic dimension]]|데이터나 공간의 본질적인 차원 수를 나타내는 개념입니다. 이는 데이터가 본래 지니고 있는 정보의 구조를 반영하며, 데이터가 놓여 있는 고차원 공간에서 얼마나 적은 차원으로 이 데이터를 설명할 수 있는지를 나타냅니다.|
|세미나|08.22|[[lightweight decomposition model]]|가벼운 분할 분석 모델|
|세미나|24.08.28|[[ROI Pooling]]||
|세미나|24.08.28|[[DSA-LSTM]]||
|세미나|24.08.28|[[RPN]]|Region Proposal Network|
|세미나|24.08.28|[[sliding window]]||
|세미나|24.08.28|[[anchor box & bouding box]]|Detection에서 사용되는 기본 틀이 Anchor box이고 실제 디텍션해낸 결과가 바운딩 박스이다.|
|세미나|24.09.13|[[knowledge distillation]]||
|세미나|24.09.20|[[카메라 Calibration]]||
|세미나|24.09.20|[[HRnet]]||
|세미나|24.09.20|[[$psi$(프사이)]]||
|세미나|24.09.20|[[Multi-view NRSfM]]||
|세미나|24.09.20|[[LSTM]]||
|세미나|24.09.20|[[GRU]]||
|세미나|24.09.20|[[4D Correleation Volumes]]||
|세미나|24.09.20|[[RAFT]]||
|세미나|24.09.20|[[Triangulation]]||
|세미나|24.09.20|[[Landmark detection]]||
|세미나||[[MBW]]||
  
  
  
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0001.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0002.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0003.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0004.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0005.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0006.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0007.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0008.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0009.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0010.jpg]]
핑크색 도메인 분류기가 추가된 것이 핵심이다.
만약 피처 자체도 도메인을 구분할 수 없을 정도로 좁히면 도메인과 무관한 피처들이 뽑힐 것이다.
  
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0011.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0012.jpg]]
==마이너스를 붙여 도메인 분류를 힘들게 한다. (왜??)==
마이너스를 안 붙인 경우는 클래스로 로스가 나오는 것을 분류 성능이 오를 것이다.
DISCRIM에서도 똑같이 분류를 하는데, 0→100%
분류의 목적은 성능을 높이는 건데 마이너스를 붙여 성능을 낮추는 것이다
베스트는 Predictor에서는 분류 성능은 높고, DISCRIM에서는 도메인 분류를 못하게 하는 것이다.(근데 힘듦)
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0013.jpg]]
불안정성(GAN 모델의 불치병)이 문제점으로 꼽힌다.
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0014.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0015.jpg]]
도메인을 알아볼 수 없게 특징을 뽑아서 예를 들어 강아지 이미지면 강아지로, 고양이 이미지면 고양이로 분류되게 한다.
만약 도메인을 알아보게 된다면, 애니메이션 이미지는 애니메이션으로, 화풍 이미지는 화풍이미지끼리 분류될 것이다.
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0016.jpg]]
가까운 데이터 포인트는 웨이트를 크게, 먼 데이터는 웨이트를 작게하여 로스를 세팅한다.
CE는 크로스 엔트로피(이걸 높이면 분류 성능이 올라간다)
  
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0017.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0018.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0019.jpg]]
도메인이 달라도 같은 숫자끼리 모인다. (MNIST, USPS 도메인에서의 각 숫자끼리 매치되어 분류됨.)
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0020.jpg]]
![[24%EB%85%84_9%EC%9B%94_Domain_Generalization_%EC%84%B8%EB%AF%B8%EB%82%98_page-0021.jpg]]