## 정제 및 정규화
---
- 용도에 맞게 토큰을 분류하는 작업을 토큰화라고 한다
- 텍스트 데이터를 용도에 맞게 정제 및 정규화해야한다
    - **정제 cleaning**: 갖고 있는 코퍼스로부터 노이즈 데이터를 제거
    - **정규화 normalization**: 표현 방법이 다른 단어들을 통합시켜서 같은 단어로
  
## 정제 Cleansing
---
**텍스트를 피처로 만들기 전에 미리 클렌징**
- **대소문자 통합**: 소문자 변환 → 단어의 개수를 줄일 수 있다
- **특수 문자 삭제**: 정규 표현식을 사용하여 노이즈 데이터 제거 가능
  
**불용어 (Stop word) 제거**
- stop word는 분석이 큰 의미가 없는 단어  
    (보통 문법적으로는 필수지만 문맥적으로 큰 의미가 없다)  
    
  
### 불용어 Stop word 제거
- 큰 의미가 없는 단어 토큰을 제거하는 작업으로 언어별로 목록화 되어 있다
- NLTK에서는 100여개 이상의 영어 단어들을 불용어로 패키지 내에 미리 정의한다
- 개발자가 직접 정의할 수도 있다
  
**NLTK**
```Python
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
# 불용어 확인
stop_words_list = set(stopwords.words('english')) 
# 불용어 제거
word_tokens = word_tokenize(example)              
result = []
for word in word_tokens:
	if word not in stop_words:
		result.append(word)
```
  
**koNLPy**
```Python
from konlpy.tag import Okt
example = "고기를 아무렇게나 구우려고 하면 안 돼. 고기라고 다 같은 게 아니거든. 예컨대 삼겹살을 구울 때는 중요한 게 있지."
stop_words = "를 아무렇게나 구 우려 고 안 돼 같은 게 구울 때 는"
# 불용어 확인
stop_words = set(stop_words.split(' '))
# 불용어 제거
okt = Okt()
word_tokens = okt.morphs(example)
result = [word for word in word_tokens if not word in stop_words]
```
  
## 정규화 Normalization
---
**규칙에 기반한 표기가 다른 단어 통합**
- 표기가 다른 언어들을 하나의 단어로 정규화하는 방법을 사용
- **어간 추출 Stemming**과 **표제어 추출 Lemmatization** 등이 있다 (단어의 원형을 찾음)
- Stemming은 일반적인 방법이나 더 단순화된 방법을 사용한다
- Lemmatization이 Stemming보다 정교하여 의미론적인 기반에서 단어의 원형을 찾는다  
    (품사와 같은 문법적인 요소와 의미적인 부분을 감안한다)  
    
||**Stemming**|**Lemmatization**|
|---|---|---|
|am|am|be|
|the going|the go|the going|
|having|hav|have|
  
### 어간 추출 Stemming
- 형태소의 종류에는 어간과 접사가 존재한다
    - **어간 stem**: 단어의 의미를 담고 있는 단어의 핵심 부분
    - **접사 affix**: 단어에 추가적인 의미를 주는 방법
- 어간을 추출하는 작업을 어간추출이라고 한다
- 어간 추추의 결과로 나오는 단어로 사전에 존재하지 않는 단어가 나올 수 있다
- NLTK는 다양한 Stemmer를 제공  
    : Porter, Lancaster, Snowball Stemmer  
    
  
```Python
from nltk.stem import LancasterStemmer
stemmer = LancasterStemmer()
print(stemmer.stem('working'), stemmer.stem('works'), stemmer.stem('worked'))
print(stemmer.stem('amusing'), stemmer.stem('amuses'), stemmer.stem('amused'))
print(stemmer.stem('happier'), stemmer.stem('happiest'))
print(stemmer.stem('fancier'), stemmer.stem('fanciest'))
```
![[Source/Untitled 164.png|Untitled 164.png]]
  
### 표제어 추출 Lemmatization
- 단어들로부터 표제어를 찾아가는 과정
- 단어의 개수가 줄일 수 있는지 판단
- NLTK의 WordNetLemmatizer를 사용할 수 있다
  
```Python
from nltk.stem import WordNetLemmatizer
import nltk
nltk.download('wordnet')
lemma = WordNetLemmatizer()
print(lemma.lemmatize('amusing','v'),lemma.lemmatize('amuses','v'),lemma.lemmatize('amused','v'))
print(lemma.lemmatize('happier','a'),lemma.lemmatize('happiest','a'))
print(lemma.lemmatize('fancier','a'),lemma.lemmatize('fanciest','a'))
```
![[Source/Untitled 1 110.png|Untitled 1 110.png]]
  
### **한국어의 경우**
- 용언에 해당되는 동사와 형용사는 **어간 stem + 어미 ending**
|**언**|**품사**|
|---|---|
|체언|명사, 대명사, 수사|
|수식언|관형사, 부사|
|관계언|조사|
|독립언|감탄사|
|용언|동사, 형용사|
**활용 conjugation**
- 어간과 어미를 가진다
- **어간 stem**:  
    용언에서 모양이 변하지 않는 부분  
    
- **어미 ending**:  
    용  
    **언의 어간 뒤에 붙어 변하는 부분**
**규칙 활용**
- 어간이 어미를 취할 때 어간의 모습일 일정
- ex) 잡/어간 + 다/어미
  
**불규칙 활용**
- 어간이 어미를 취할 때 어간의 모습이 바뀌거나 취하는 어미가 특수한 어미일 경우
- 어간의 모습이 바뀌었으므로 단순한 분리만으로 어간 추출이 되지 않고 좀 더 복잡한 규칙을 필요로 한다
  
## 참고자료
---
- [정제(Cleaning) and 정규화(Normalization)](https://wikidocs.net/21693)
- [정규표현식과 텍스트 데이터의 전처리](https://wikidocs.net/171411)
- 파이썬 머신러닝 완벽 가이드