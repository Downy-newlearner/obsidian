## 1.1 LLM이란?
### 1.1.1 LLM 정의
- LLM과 트랜스포머가 해결하고있는 작업은 **언어 모델링 작업**이다.
	1. 자동 인코딩
	2. 자기회귀 언어 모델

![[Pasted image 20250112235952.png|400]]

- 자동 인코딩은 문장의 누락된 부분을 채우도록 모델에 요청한다.
- 자기회귀 언어 모델은 주어진 문장의 바로 다음에 가장 가능성 있는 토큰을 생성하도록 모델에 요청한다. (예시: BERT)

### 1.1.2 LLM 주요 특징
- 기존의 트랜스포머 아키텍처는 2017년에 고안된 **시퀀스-투-시퀀스**sequence-to-sequence (seq2 seq) 모델이었으며, 이는 두 가지 구성 요소를 주로 가지고 있었다.
	- ![[Pasted image 20250112235750.png|300]]
		- 인코더는 원시 텍스트를 받아들여 핵심 구성 요소로 분리하고, 해당 구성 요소를 벡터로 반환하는 업부를 담당한다. 또한 어텐션을 사용하여 텍스트의 맥락을 이해한다.
		- 디코더는 수정된 형식의 어텐션을 사용하여 다음에 올 토큰을 예측한다.

- LLM 예시
![[Pasted image 20250113000036.png]]
35
