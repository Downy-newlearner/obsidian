---
Lecture date: 2025-01-13
tags:
  - 한권으로끝내는실전LLM파인튜닝
Part of book:
  - 1. NLP의 과거와 오늘
reference: file:///C:/Users/user/Documents/%EC%B9%B4%EC%B9%B4%EC%98%A4%ED%86%A1%20%EB%B0%9B%EC%9D%80%20%ED%8C%8C%EC%9D%BC/%ED%95%9C%20%EA%B6%8C%EC%9C%BC%EB%A1%9C%20%EB%81%9D%EB%82%B4%EB%8A%94%20%EC%8B%A4%EC%A0%84%20LLM%20%ED%8C%8C%EC%9D%B8%ED%8A%9C%EB%8B%9D.pdf
---
![[Pasted image 20250113104839.png]]


## 1.4.2 퍼셉트론의 등장
![[Pasted image 20250113105633.png]]
- 퍼셉트론은 인공지능 학습의 첫걸음이 되었다.
- 퍼셉트론은 *연결주의 접근법*(전통적인 경험주의 방법론, empiricist tradition theorists)을 따른다.
	- 활성화된 뉴런들 사이의 새로운 경로를 통해 정보가 저장되며, 이는 뉴런 간의 연결 강도로 표현된다.
	- 특정 자극과 반응 사이의 확률적 관계를 학습한다.

- 이런 경험에 따라 변화하는 신경망을 구축하기 위해 *통계적인 방법*을 활용했다.
	- 이는 신경망의 확률적인 특성을 고려한 것이다.
	- 무작위로 연결된 신경망이 어떻게 신뢰성 있게 작동하는지를 설명한다.

- 활성화 함수를 사용했다.
	- 신경망의 효율을 높이고 자극들 간의 유사성을 처리하는데 중요한 역할을 했다.

- 자발적 조직화
	- 예를 들어, '밥을'이라는 입력이 들어오면 '짓다', '먹다', '시키다', '주문하다' 등이 활성화되괴, '깨다', '부수다'같은 무관한 단어들은 억제된다.
	- 이런 선택적 활성화 과정은 시스템이 자발적으로 조직화하는 능력의 기초가 된다.

- '선형적 분리'라는 개념을 발견하다.
	- 자발적 조직화를 증명하기 위해 퍼셉틀론 시스템에 두 가지 서로 다른 유형의 자극을 무작위로 주는 실험을 했는데, 퍼셉트론이 이를 스스로 구분했다.(선형적 분리)
	- 선형적 분리는 주어진 데이터를 직선이ㅏㄴ 평면 등의 단순한 기하학적 형태로 명확하게 나눌 수 있는 경우를 의미한다.


## 로젠블렛이 제시한 퍼셉트론의 한계
1. 기존 원칙에서 벗어난 완전히 다른 원칙이 필요하다.
2. 퍼셉트론은 시간적 요소를 고려하지 않았다. 그러므로 시간에 따른 패턴 인식과 같은 복잡한 자극에 대응하는 능력이 부족하다.
3. '분류'는 잘 하지만, '관계 파악'은 못한다.
4. 선형적인 문제만 풀 수 있다.


## 1.5 역전파 알고리즘
![[Pasted image 20250113112549.png]]
- XOR 문제같은 비선형 문제는 퍼셉트론이 풀지 못한다.

- 그래서 다층 퍼셉트론을 제안함
- >> 순방향 뿐만 아니라 역방향으로 조절해야한다는 것을 깨달음
- >> 그러나 미분을 함에 따라서 아무리 많은 층을 쌓아도 결국 하나의 선형 변환으로 축소되거나 0이 되어 학습되지 않음
- >> *비선형 함수 도입*
- >>