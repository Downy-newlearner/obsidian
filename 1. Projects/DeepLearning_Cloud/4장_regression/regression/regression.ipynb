{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 소프트웨어학과 32204041 정다훈 4장 과제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습1: Simple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iris 데이터셋에서 꽃잎의 길이(Petal.Length)로 꽃잎의 폭(Petal.Width)을 예측하는 회귀 모델을 만드세요.\n",
    "2. 회귀 모델의 mean_squared_error와 r2_score 값을 보이세요.\n",
    "3. 회귀 모델의 coefficients와 Intercept 값을 보이세요.\n",
    "4. 회귀 모델을 이용하여 꽃잎의 길이가 1.0, 1.2, 1.4일 때 꽃잎의 폭을 예측해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = pd.read_csv('./data/iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.038762659714382725\n",
      "R2: 0.9292817886035307\n",
      "Coefficient: [0.42133892]\n",
      "Intercept: -0.3732225694780913\n",
      "New Y: [0.04811635 0.13238413 0.21665191]\n"
     ]
    }
   ],
   "source": [
    "iris.columns\n",
    "iris_X = iris['Petal.Length']\n",
    "iris_Y = iris['Petal.Width']\n",
    "\n",
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris_X, iris_Y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train.values.reshape(-1, 1), Y_train.values)\n",
    "\n",
    "# predict\n",
    "Y_pred = reg.predict(X_test.values.reshape(-1, 1))\n",
    "\n",
    "# evaluate(mse, r2)\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "MSE = mean_squared_error(Y_test, Y_pred)\n",
    "print(f'MSE: {MSE}')\n",
    "\n",
    "r2 = r2_score(Y_test, Y_pred)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# coeeficient and intercept\n",
    "print(f'Coefficient: {reg.coef_}')\n",
    "print(f'Intercept: {reg.intercept_}')\n",
    "\n",
    "# using the model\n",
    "X_new = np.array([1.0, 1.2, 1.4]).reshape(-1, 1)\n",
    "Y_new = reg.predict(X_new)\n",
    "print(f'New Y: {Y_new}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습2: Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 실습용으로 제공한 BostonHousing 데이터셋은 보스턴 지역의 지역정보 및 평균주택 가격 (medv) 정보를 담고 있다. 다른 변수를 이용하여 medv를 예측하는 모델을 만드세요 (feature 중 chas는 제외).\n",
    "2. 회귀 모델의 mean_squared_error와 r2_score 값을 보이세요.\n",
    "3. 회귀 모델의 coefficients와 Intercept 값을 보이세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BostonHousing = pd.read_csv(\"./data/BostonHousing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 24.344456871929992\n",
      "R2: 0.7359029307280057\n",
      "Coefficient: [-9.79164542e-02  6.55190530e-02 -4.99609296e-03 -2.13172793e+01\n",
      "  2.59729736e+00  7.68150802e-03 -1.89395459e+00  3.88424213e-01\n",
      " -1.55433784e-02 -1.11296742e+00  9.60981706e-03 -5.78193786e-01]\n",
      "Intercept: 51.339602439179956\n"
     ]
    }
   ],
   "source": [
    "# 'medv' 컬럼이 타겟 컬럼, 나머지는 독립 변수\n",
    "BostonHousing_X = BostonHousing.drop(['medv', 'chas'], axis=1)\n",
    "BostonHousing_y= BostonHousing['medv']\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(BostonHousing_X, BostonHousing_y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# linear regression\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "# evaluate(mse, r2)\n",
    "MSE = mean_squared_error(y_test, y_pred)\n",
    "print(f'MSE: {MSE}')\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f'R2: {r2}')\n",
    "\n",
    "# coeeficient and intercept\n",
    "print(f'Coefficient: {reg.coef_}')\n",
    "print(f'Intercept: {reg.intercept_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습3: Rogistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. scikit-learn에 포함된 wine 데이터셋으로부터 wine의 등급을 분류하는 모델을 만드세요.\n",
    "2. 만들어진 모델의 예측 정확도를 보이세요.\n",
    "   - train set에 대한 예측 정확도\n",
    "   - test set에 대한 예측 정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy: 0.9838709677419355\n",
      "Test set accuracy: 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jdh25\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# prepare dataset\n",
    "from sklearn import datasets\n",
    "X, y = datasets.load_wine(return_X_y=True)\n",
    "\n",
    "X = pd.DataFrame(X)\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1234)\n",
    "\n",
    "# Rogistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = logreg.predict(X_test)\n",
    "# print(y_pred)\n",
    "\n",
    "# train set에 대한 예측 정확도 평가\n",
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_train = logreg.predict(X_train)\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "\n",
    "# test set에 대한 예측 정확도 평가\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Train set accuracy: {accuracy_train}')\n",
    "print(f'Test set accuracy: {accuracy}')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
