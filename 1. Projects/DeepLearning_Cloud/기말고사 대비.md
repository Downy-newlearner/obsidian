## Chap01
### 1. Deep learning
- 딥러닝은 인공 신경망에 기반을 둔다.
	- Perceptron -> Multi layer perceptron -> DNN(Deep neural network)
	- DNN은 MLP뿐만 아니라 CNN, RNN 등의 개념을 포괄하는 개념이다.
### 2. Cloud
- 데이터를 인터넷과 연결된 중앙컴퓨터에 저장해서 인터넷에 접속하기만 하면 언제 어디서든 데이터를 이용할 수 있는 환경
	- 데이터 뿐만 아니라 SW, 컴퓨팅 자원도 클라우드를 통해 이용가능하다.
- IaaS, Paas, Saas
![[Pasted image 20241216232221.png|400]]
	- 순서대로 Infrastructure, Platform, SW as a Service
	- IaaS: AWS
	- Paas: 앱 개발 및 배포 관련 지원. Google App Engine, Oracle Cloud Platform
	- SaaS: 서비스 제공처에서 인프라와 SW 모두 제공. 웹 메일, 구글 드라이브


## Chap03
### 1. AI scopes

### 2. Machine learning
- 머신러닝은 과거의 경험을 *미래의 결정에 활용(예측)* 하는 소프트웨어를 디자인하고 연구하는 분야이다.
	- 사용 예시: 주가 예측, 질병 진단, 이미지 분류, 번역 등
- 반응변수(y)와 설명변수(X) 간의 관계를 찾는 것이 *훈련*이다.

### 3. Machine learning areas
- 데이터 형태에 따른 분류: 지도학습, 비지도학습, 강화학습
- 타겟 형태에 따른 분류: Classification, Regression, Clustring

### 4. Development process of learning model
![[Pasted image 20241216233928.png|400]]

## Chap04_Regression
### 1. Simple linear regression
![[Pasted image 20241216234355.png|200]]
- 종속변수(y)와 독립변수(X) 사이의 선형 관계를 파악하고 이를 예측에 활용하는 방법
- 두 변수가 선형 관계에 있는지 알아보는 방법: 산점도, 상관계수
- 모델 평가
	- MSE
		![[Pasted image 20241216234632.png|200]]
		값이 작을 수록 정확한 모델이다.
	- [[R squre score]]($R^2$ Score)


### 2. Multiple linear regression
![[Pasted image 20241216235147.png|300]]
- 독립변수가 2개 이상인 경우이다.

### 3. Logistic regression
- 일반적인 회귀 문제에서 종속변수는 수치형 데이터지만, 로지스틱 회귀에서 종속변수는 범주형 데이터이다.
- 독립변수는 수치형이어야하므로 범주형 독립변수의 경우 인코딩하여 수치형 데이터로 변환한 후 훈련시켜야한다.(Scikit-learn에서는 자동으로 해줌)

## Chap05_DT, RF, SVM
### 1. Concept of decision tree
- 큰 문제를 작은 문제들의 조각으로 나누어 해결하는 기법이다.
- 이슈
	1. 트리의 노드를 선택할 때, 데이터셋에서 어떤 속성부터 선택할 것인가
		- Feature evaluation이 필요하다.(불순도([[impurity]])를 계산해야함)
		- ![[Pasted image 20241217001737.png|200]]
			- 몸무게의 불순도가 가장 낮다. 그러므로 몸무게를 기준으로 먼저 나누어야한다.
	2. 트리 split을 언제 중단할 것인가?
- 장점
	- 모든 문제에 적합하다.
	- 여러 속성들 중 중요한 속성들만을 사용하여 예측한다.
	- 단순한 이론적 근거에 비해 높은 효율성
- 단점
	- 모델이 쉽게 과대적합 및 과소적합됨
	- 훈련 데이터에 대한 약간의 변경이 결정 논리에 큰 변화를 준다.

### 3. Support Vector Machine(SVM)
- 기본적으로 선형 분류 방식이다.
- 기존의 분류 방법들은 '분류 오류율을 최소화'하려는 목적으로 설계되었지만, SVM은 *두 부류 사이에 존재하는 '여백을 최대화'* 하려는 목적으로 설계되었다.
- 장점
	- 범주형, 수치형 데이터 모두에 사용 가능하다.
	- 노이즈 데이터에 큰 영향을 받지 않고, overfitting이 잘 일어나지 않는다.
	- 높은 정확도를 보인다.
- 단점
	- 훈련 시간이 많이 소요된다.
	- 모델 해석이 어렵다.

### 4. Ensemble
- '다수 협의에 의한 결정'이라는 원리를 예측 문제 해결에 적용한 것이다.
- 배깅
	- ![[Pasted image 20241217003147.png|300]]
	- Bootstrap Aggregation의 약자이다.
	- RF가 배깅 방식을 사용한다.
- 부스팅
	- ![[Pasted image 20241217003250.png|350]]
	- 예측모델 1의 결과를 보고 오답에 가중치 부여해서 다음 예측모델에서 그 오답 부분을 집중적으로 학습하여 오답을 낮춘다. 이 과정을 반복
	- 배깅에 비해 성능이 더 좋으나 과적합이 더 쉽게 발생한다.
### 5. Random Forest

### 6. XGBoost
- Gradient Boosting framework 기반으로 구현됐다.
- 병렬 트리 부스팅을 제공한다.
	- 많은 데이터 사이언스 문제들을 빠르고 정확하게 푸는 방법으로 사용되고 있는 기법이다.

## Chap06_Cross Validation
### 1. Bias-Variance trade off
![[Pasted image 20241217005034.png]]
- Bias
	- 데이터 내의 *모든 정보를 고려하지 않음으로 인해*, 지속적으로 잘못된 것들을 학습하는 경향
	- 과소적합 유발
- Variance
	- 데이터의 *너무 세세한 부분까지 학습하여* 새로운 데이터가 추가되면 모델이 쉽게 바뀜
	- 과적합 유발
		- 이를 방지하기 위한 기능
			- tree 기반 알고리즘: 가지치기
			- regression, SVM: 정규화
			- neural network: dropout

### 2. K-fold Cross Validation
- 데이터셋은 랜덤 샘플링하여 train&validation&test data로 나뉜다. 
- 그런데 이렇게 '랜덤' 샘플링된 데이터셋으로 훈련 및 평가 사이클을 한 번만 실행하는 것이 충분한가?
	- 샘플링된 데이터셋의 구성에 따라 성능이 다르게 나올 수도 있다.

![[Pasted image 20241217005410.png|500]]
- 모델의 정확도는 각 fold의 정확도 평균으로 계산한다.
- sklearn의 cross_val_score 메서드를 사용하면 자동으로 폴드를 나누고 cv번의 훈련을 진행한 후 각 폴드의 성능을 검사하여 리턴한다.
- CV는 하이퍼 파라미터 튜닝에 사용한다.
- 또한 전처리시 feature selection에 사용한다.

### 3. Hyper parameter tuning
- 대부분의 분류 알고리즘은 모델 성능에 영향을 끼치는 하이퍼파라미터를 가지고있다.
- 모델 빌딩 과정
	1. 피처 셀렉션 등 전처리 된 데이터셋 준비
	2. cross validation을 이용하여 하이퍼파라미터 최적화
	3. 최적의 하이퍼파라미터로 튜닝된 알고리즘(모델)에 데이터를 학습시킨다.
	4. 테스트 데이터로 모델을 평가한다.
- Grid Search, Random Search

### 4. Model comparison
- 모든 데이터셋에 항상 최고인 분류기는 없다.
- 그러므로 '모델 비교'가 필요하다.

### 5. Performance metric
- 이진 분류 메트릭
![[Pasted image 20241217010518.png]]
- 정확도 
![[Pasted image 20241217011203.png|300]]

- 민감도(sensitivity, recall)
![[Pasted image 20241217011213.png|300]]
	-> 정답이 P인 것들 중 맞춘 비율(환자를 환자라고 예측한 비율)

- 특이도(specificity)
![[Pasted image 20241217011221.png|300]]
	-> 정답이 N인 것들 중 맞춘 비율(정상인을 정상인이라고 예측한 비율)

- 정밀도(Precision)
 ![[Pasted image 20241217011235.png|300]]
	 -> P라고 예측한 것들 중 맞춘 비율(환자라고 예측한 것 중에서 실제 환자의 비율)

- F1 score
- ![[Pasted image 20241217011607.png]]
	- 정밀도와 민감도의 조화평균
	- precision과 recall의 불균형에 대해 감점이 이루어진다.

- ROC-AUC
	- Accuracy는 불균형 데이터셋에 대해 올바로 평가하지 못한다.
		- 99%가 Positive인 데이터셋에 대해 전부 다 Positive라고 하면 장땡임
	- AUC는 이런 불균형 데이터셋 평가에 효과적이다.


## Chap07_Feature Selection_Stacking
### 1. Feature selection
![[Pasted image 20241217021543.png]]
- 성능에 더 많이 기여하는 중요한 피처를 찾는 것이 중요하다.
	- 명확한 클래스 바운더리를 갖는 피처가 좋은 피처다.
- 필터 방식, 임베디드 방식, 래퍼 방식
1. Voting classifier
2. Bagging meta-estimator
3. Model stacking