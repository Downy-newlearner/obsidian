## Chap01
### 1. Deep learning
- 딥러닝은 인공 신경망에 기반을 둔다.
	- Perceptron -> Multi layer perceptron -> DNN(Deep neural network)
	- DNN은 MLP뿐만 아니라 CNN, RNN 등의 개념을 포괄하는 개념이다.
### 2. Cloud
- 데이터를 인터넷과 연결된 중앙컴퓨터에 저장해서 인터넷에 접속하기만 하면 언제 어디서든 데이터를 이용할 수 있는 환경
	- 데이터 뿐만 아니라 SW, 컴퓨팅 자원도 클라우드를 통해 이용가능하다.
- IaaS, Paas, Saas
![[Pasted image 20241216232221.png|400]]
	- 순서대로 Infrastructure, Platform, SW as a Service
	- IaaS: AWS
	- Paas: 앱 개발 및 배포 관련 지원. Google App Engine, Oracle Cloud Platform
	- SaaS: 서비스 제공처에서 인프라와 SW 모두 제공. 웹 메일, 구글 드라이브


## Chap03
### 1. AI scopes

### 2. Machine learning
- 머신러닝은 과거의 경험을 *미래의 결정에 활용(예측)* 하는 소프트웨어를 디자인하고 연구하는 분야이다.
	- 사용 예시: 주가 예측, 질병 진단, 이미지 분류, 번역 등
- 반응변수(y)와 설명변수(X) 간의 관계를 찾는 것이 *훈련*이다.

### 3. Machine learning areas
- 데이터 형태에 따른 분류: 지도학습, 비지도학습, 강화학습
- 타겟 형태에 따른 분류: Classification, Regression, Clustring

### 4. Development process of learning model
![[Pasted image 20241216233928.png|400]]

## Chap04_Regression
### 1. Simple linear regression
![[Pasted image 20241216234355.png|200]]
- 종속변수(y)와 독립변수(X) 사이의 선형 관계를 파악하고 이를 예측에 활용하는 방법
- 두 변수가 선형 관계에 있는지 알아보는 방법: 산점도, 상관계수
- 모델 평가
	- MSE
		![[Pasted image 20241216234632.png|200]]
		값이 작을 수록 정확한 모델이다.
	- [[R squre score]]($R^2$ Score)


### 2. Multiple linear regression
![[Pasted image 20241216235147.png|300]]
- 독립변수가 2개 이상인 경우이다.

### 3. Logistic regression
- 일반적인 회귀 문제에서 종속변수는 수치형 데이터지만, 로지스틱 회귀에서 종속변수는 범주형 데이터이다.
- 독립변수는 수치형이어야하므로 범주형 독립변수의 경우 인코딩하여 수치형 데이터로 변환한 후 훈련시켜야한다.(Scikit-learn에서는 자동으로 해줌)

## Chap05_DT, RF, SVM
### 1. Concept of decision tree
- 큰 문제를 작은 문제들의 조각으로 나누어 해결하는 기법이다.
- 이슈
	1. 트리의 노드를 선택할 때, 데이터셋에서 어떤 속성부터 선택할 것인가
		- Feature evaluation이 필요하다.(불순도([[impurity]])를 계산해야함)
		- ![[Pasted image 20241217001737.png|200]]
			- 몸무게의 불순도가 가장 낮다. 그러므로 몸무게를 기준으로 먼저 나누어야한다.
	2. 트리 split을 언제 중단할 것인가?
- 장점
	- 모든 문제에 적합하다.
	- 여러 속성들 중 중요한 속성들만을 사용하여 예측한다.
	- 단순한 이론적 근거에 비해 높은 효율성
- 단점
	- 모델이 쉽게 과대적합 및 과소적합됨
	- 훈련 데이터에 대한 약간의 변경이 결정 논리에 큰 변화를 준다.

### 3. Support Vector Machine(SVM)
- 기본적으로 선형 분류 방식이다.
- 기존의 분류 방법들은 '분류 오류율을 최소화'하려는 목적으로 설계되었지만, SVM은 *두 부류 사이에 존재하는 '여백을 최대화'* 하려는 목적으로 설계되었다.
- 장점
	- 범주형, 수치형 데이터 모두에 사용 가능하다.
	- 노이즈 데이터에 큰 영향을 받지 않고, overfitting이 잘 일어나지 않는다.
	- 높은 정확도를 보인다.
- 단점
	- 훈련 시간이 많이 소요된다.
	- 모델 해석이 어렵다.
1. Random Forest
2. XGBoost