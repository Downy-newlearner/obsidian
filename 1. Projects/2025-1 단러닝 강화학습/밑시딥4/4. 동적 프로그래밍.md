## 동적 프로그래밍을 사용해야하는 이유
- 강화학습의 최종 목표인 '최적 정책 찾기'를 위해서는 기존 방법인 벨만 최적 방정식을 만족하는 연립방정식을 풀어야했다.
- 하지만 이 방법은 계산량이 너무 많다.(상태의 크기를 S, 행동의 크기를 A라고 한다면 $A^S$만큼의 계산이 필요함.)
- ==벨만 방정식을 이용하여 식정리를 한 다음 동적프로그램 적용의 실마리를 찾는 흐름 다시 잡기==


## 4.1.2 반복적 정책 평가_첫 번째 구현
**전제**
- 상태 전이는 deterministic하다.
	- 다음 상태 $s'$가 함수 $f(s,a)$에 의해 고유하게 결정된다.

![[Pasted image 20250323213333.png]]


## GridWorld
![[Pasted image 20250323215046.png]]